{
    "cells": [
        {
            "cell_type": "code",
            "execution_count": 1,
            "metadata": {},
            "outputs": [],
            "source": [
                "import copy\n",
                "import json\n",
                "from datetime import datetime\n",
                "from typing import TypedDict\n",
                "\n",
                "import matplotlib.pyplot as plt\n",
                "import numpy as np\n",
                "import seaborn as sns\n",
                "import torch\n",
                "import torch.nn as nn\n",
                "import torch.optim as optim\n",
                "from constants import DATA_DIR, MODELS_DIR\n",
                "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
                "from sklearn.model_selection import train_test_split\n",
                "from torch.nn.utils.rnn import (\n",
                "    PackedSequence,\n",
                "    pack_padded_sequence,\n",
                "    pad_packed_sequence,\n",
                "    pad_sequence,\n",
                ")\n",
                "from torch.utils.data import DataLoader, Dataset, TensorDataset\n",
                "\n",
                "from astrofit.utils import AsteroidLoader, LightcurveBinner\n",
                "\n",
                "sns.set_theme(style=\"darkgrid\")\n",
                "plt.rcParams[\"figure.figsize\"] = (14, 6)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 2,
            "metadata": {},
            "outputs": [],
            "source": [
                "assert torch.cuda.is_available(), \"CUDA is not available\""
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 3,
            "metadata": {},
            "outputs": [],
            "source": [
                "asteroid_loader = AsteroidLoader(DATA_DIR)\n",
                "lightcurve_binner = LightcurveBinner()\n",
                "\n",
                "ASTEROIDS_FREQ_DATA_PATH = DATA_DIR / \"asteroids_freq_data.json\"\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 4,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/plain": [
                            "2662"
                        ]
                    },
                    "execution_count": 4,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "with open(ASTEROIDS_FREQ_DATA_PATH, \"r\") as f_in:\n",
                "    asteroids_data = json.load(f_in)\n",
                "\n",
                "filtered_data = {name: data for name, data in asteroids_data[\"asteroids\"].items() if not data[\"is_failed\"]}\n",
                "len(filtered_data)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 16,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/plain": [
                            "{'max_hours_diff': 24,\n",
                            " 'min_no_points': 10,\n",
                            " 'top_k_bins': 4,\n",
                            " 'buffer_bins': 3,\n",
                            " 'select_bins_by': 'points',\n",
                            " 'max_time_diff': 45,\n",
                            " 'min_bin_size': 1,\n",
                            " 'max_freq': 12,\n",
                            " 'top_k_freqs': 50,\n",
                            " 'nterms': 3,\n",
                            " 'max_debug': False}"
                        ]
                    },
                    "execution_count": 16,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "asteroids_data[\"config\"]"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 5,
            "metadata": {},
            "outputs": [],
            "source": [
                "X_data = []\n",
                "y_data = []\n",
                "for data in filtered_data.values():\n",
                "    X_data.append(torch.tensor(data[\"freq_features\"]))\n",
                "    y_data.append(data[\"period\"])\n",
                "\n",
                "y_data = torch.tensor(y_data).unsqueeze(1)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 15,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "application/vnd.plotly.v1+json": {
                            "config": {
                                "plotlyServerURL": "https://plot.ly"
                            },
                            "data": [
                                {
                                    "histnorm": "probability",
                                    "type": "histogram",
                                    "x": [
                                        11.02558,
                                        2.557692,
                                        9.07938,
                                        10.70735,
                                        5.072053,
                                        7.68806,
                                        6.2614,
                                        4.219087,
                                        5.61479,
                                        16.7482,
                                        4.827828,
                                        6.84803,
                                        9.53676,
                                        26.8984,
                                        28.0609,
                                        15.75892,
                                        6.88334,
                                        32.815,
                                        8.24865,
                                        6.71315,
                                        10.79854,
                                        16.37638,
                                        16.08211,
                                        12.58423,
                                        5.90282,
                                        8.01733,
                                        5.74341,
                                        4.441968,
                                        9.4133,
                                        8.72121,
                                        5.84813,
                                        3.93899,
                                        10.65704,
                                        6.85828,
                                        2.891026,
                                        5.444449,
                                        2.985538,
                                        5.79981,
                                        5.326507,
                                        10.87231,
                                        10.83116,
                                        8.53306,
                                        5.073747,
                                        5.05227,
                                        10.06609,
                                        11.06752,
                                        5.06904,
                                        26.7044,
                                        3.124124,
                                        18.4825,
                                        9.47919,
                                        6.51669,
                                        3.898919,
                                        8.15607,
                                        17.20735,
                                        9.37487,
                                        13.48418,
                                        10.21531,
                                        5.34569,
                                        5.251977,
                                        3.844308,
                                        5.22705,
                                        7.95022,
                                        14.33958,
                                        4.255019,
                                        4.44221,
                                        3.690655,
                                        5.82416,
                                        16.0879,
                                        19.9941,
                                        8.48936,
                                        9.33026,
                                        8.56457,
                                        8.0861,
                                        23.0986,
                                        35.3866,
                                        8.90276,
                                        5.516059,
                                        5.57524,
                                        5.02116,
                                        7.32023,
                                        19.8022,
                                        5.93581,
                                        31.564,
                                        13.66012,
                                        13.45128,
                                        2.57386,
                                        11.99418,
                                        6.41374,
                                        23.9521,
                                        5.79336,
                                        3.652174,
                                        6.9571,
                                        3.308476,
                                        23.3599,
                                        4.97053,
                                        6.21275,
                                        9.79349,
                                        4.838531,
                                        4.96601,
                                        3.894523,
                                        5.400756,
                                        3.527846,
                                        13.57748,
                                        31.8661,
                                        8.38011,
                                        8.26,
                                        8.14756,
                                        4.321281,
                                        28.5797,
                                        11.56991,
                                        20.0636,
                                        22.8893,
                                        10.22553,
                                        7.81773,
                                        21.9336,
                                        17.17,
                                        5.1089,
                                        4.846351,
                                        13.466,
                                        9.25874,
                                        16.669,
                                        10.5778,
                                        12.66498,
                                        9.79732,
                                        6.23724,
                                        11.0517,
                                        19.2579,
                                        8.76239,
                                        5.15273,
                                        5.51386,
                                        10.9386,
                                        4.956151,
                                        3.988545,
                                        7.59631,
                                        4.020902,
                                        9.51356,
                                        15.58218,
                                        5.90702,
                                        5.196349,
                                        10.31539,
                                        15.3099,
                                        6.28129,
                                        12.01878,
                                        3.635352,
                                        11.52882,
                                        12.20052,
                                        27.0692,
                                        3.631377,
                                        9.98306,
                                        6.20219,
                                        7.03654,
                                        8.12048,
                                        6.17996,
                                        8.03364,
                                        6.34669,
                                        20.9093,
                                        16.45628,
                                        7.87741,
                                        7.66121,
                                        9.18961,
                                        8.92431,
                                        5.554462,
                                        8.43497,
                                        15.9701,
                                        15.74289,
                                        39.8999,
                                        7.333,
                                        17.68432,
                                        17.7285,
                                        12.43206,
                                        5.52303,
                                        22.2467,
                                        7.95769,
                                        11.87848,
                                        9.21507,
                                        6.852,
                                        39.0847,
                                        37.9172,
                                        11.421,
                                        9.46705,
                                        37.0183,
                                        7.06579,
                                        5.46417,
                                        5.902524,
                                        28.457,
                                        6.97621,
                                        6.18811,
                                        12.66397,
                                        12.70795,
                                        15.968,
                                        6.39942,
                                        11.19841,
                                        3.824313,
                                        5.363025,
                                        12.49328,
                                        12.83303,
                                        7.89728,
                                        8.93853,
                                        5.43391,
                                        14.73528,
                                        2.134122,
                                        7.05232,
                                        7.7374,
                                        6.33477,
                                        6.23602,
                                        4.126133,
                                        8.06473,
                                        10.22794,
                                        4.129105,
                                        6.97656,
                                        10.95476,
                                        7.63346,
                                        11.00092,
                                        6.17653,
                                        9.54707,
                                        3.657467,
                                        5.406296,
                                        7.65777,
                                        6.97151,
                                        17.75487,
                                        5.113765,
                                        7.29819,
                                        5.616087,
                                        3.9959,
                                        12.82437,
                                        5.857617,
                                        4.16817,
                                        38.8741,
                                        10.64534,
                                        15.7017,
                                        10.69334,
                                        5.4748,
                                        7.03142,
                                        10.54229,
                                        16.484,
                                        10.5573,
                                        5.46337,
                                        4.370848,
                                        3.627266,
                                        5.61731,
                                        7.0151,
                                        4.641375,
                                        9.18433,
                                        19.4894,
                                        17.50657,
                                        11.21794,
                                        5.31832,
                                        5.091713,
                                        8.70168,
                                        19.3146,
                                        24.2936,
                                        10.00445,
                                        12.8041,
                                        14.29704,
                                        7.39678,
                                        3.85386,
                                        4.95707,
                                        23.2724,
                                        7.74681,
                                        16.64034,
                                        3.239488,
                                        11.20395,
                                        10.28761,
                                        9.01624,
                                        4.109863,
                                        17.8604,
                                        3.51171,
                                        9.26738,
                                        5.19324,
                                        11.82659,
                                        8.89847,
                                        14.6636,
                                        13.51289,
                                        11.27964,
                                        5.72924,
                                        4.89224,
                                        12.62024,
                                        15.80193,
                                        9.74308,
                                        5.79239,
                                        20.5136,
                                        5.261552,
                                        6.53679,
                                        5.30554,
                                        9.18995,
                                        14.01785,
                                        4.192195,
                                        7.30607,
                                        25.4988,
                                        31.5184,
                                        4.95927,
                                        10.08457,
                                        5.349068,
                                        4.889866,
                                        16.51007,
                                        4.90706,
                                        3.604133,
                                        14.44923,
                                        3.886734,
                                        6.2113,
                                        5.74448,
                                        7.40863,
                                        5.49916,
                                        10.67939,
                                        5.1472,
                                        4.786875,
                                        9.45886,
                                        32.4029,
                                        19.4841,
                                        13.11459,
                                        14.92466,
                                        9.43945,
                                        5.327765,
                                        6.415,
                                        13.46912,
                                        13.88359,
                                        20.3544,
                                        17.095,
                                        10.37715,
                                        10.27744,
                                        9.50472,
                                        7.14783,
                                        8.51475,
                                        26.0375,
                                        3.466569,
                                        12.05126,
                                        15.4956,
                                        22.6588,
                                        6.31015,
                                        8.56094,
                                        5.35191,
                                        5.74917,
                                        5.86981,
                                        5.348299,
                                        9.9433,
                                        7.72131,
                                        5.120185,
                                        17.0575,
                                        14.69052,
                                        3.601297,
                                        5.323909,
                                        12.08091,
                                        5.265557,
                                        5.109547,
                                        7.80234,
                                        6.19344,
                                        11.13159,
                                        4.447894,
                                        8.32669,
                                        27.0759,
                                        5.20006,
                                        3.463796,
                                        9.12704,
                                        7.65363,
                                        6.05342,
                                        27.2394,
                                        17.4163,
                                        5.500334,
                                        4.896566,
                                        3.652413,
                                        7.51225,
                                        6.31632,
                                        5.57192,
                                        21.6658,
                                        11.85036,
                                        5.77219,
                                        15.20464,
                                        9.47426,
                                        18.8183,
                                        12.90255,
                                        5.05522,
                                        6.46524,
                                        13.57929,
                                        5.89505,
                                        7.23044,
                                        5.7691,
                                        5.77761,
                                        25.02,
                                        7.98649,
                                        4.618905,
                                        5.45444,
                                        5.59006,
                                        5.50432,
                                        20.5272,
                                        9.36834,
                                        13.10971,
                                        20.7316,
                                        5.4621,
                                        7.4872,
                                        4.854173,
                                        7.55509,
                                        3.969847,
                                        5.405492,
                                        12.05897,
                                        6.72473,
                                        10.36816,
                                        10.75109,
                                        3.557035,
                                        16.97036,
                                        9.49995,
                                        17.0111,
                                        7.4234,
                                        3.648047,
                                        15.12862,
                                        6.08136,
                                        11.64349,
                                        12.15173,
                                        16.7993,
                                        9.71054,
                                        4.65443,
                                        12.38311,
                                        5.34008,
                                        16.874,
                                        25.7624,
                                        12.73777,
                                        4.423486,
                                        10.836,
                                        5.2846,
                                        9.84392,
                                        20.8605,
                                        8.69747,
                                        4.96536,
                                        17.40129,
                                        8.22493,
                                        6.84316,
                                        7.50562,
                                        6.71136,
                                        5.48461,
                                        4.67868,
                                        5.97426,
                                        5.21692,
                                        6.95481,
                                        14.10579,
                                        3.902763,
                                        4.78077,
                                        15.5635,
                                        5.39877,
                                        4.91912,
                                        4.994138,
                                        3.984432,
                                        8.14982,
                                        19.0587,
                                        4.170327,
                                        5.55075,
                                        7.01203,
                                        8.30145,
                                        5.15212,
                                        8.84693,
                                        19.485,
                                        7.17943,
                                        5.21891,
                                        11.89945,
                                        5.83391,
                                        6.09677,
                                        4.240956,
                                        5.36627,
                                        10.82206,
                                        6.70434,
                                        6.08292,
                                        6.19044,
                                        21.8916,
                                        13.9859,
                                        5.12355,
                                        2.28689,
                                        3.40919,
                                        10.15655,
                                        5.13544,
                                        7.87737,
                                        4.70822,
                                        5.69347,
                                        4.794707,
                                        5.41642,
                                        14.2605,
                                        7.41107,
                                        5.44099,
                                        4.099002,
                                        8.14028,
                                        11.72224,
                                        5.947051,
                                        39.848,
                                        8.27099,
                                        18.9606,
                                        4.192907,
                                        4.32475,
                                        14.0486,
                                        4.877866,
                                        22.4031,
                                        5.54469,
                                        3.113827,
                                        16.40749,
                                        3.418971,
                                        8.26802,
                                        5.30472,
                                        10.62366,
                                        5.87719,
                                        4.313479,
                                        4.6713,
                                        20.893,
                                        26.3277,
                                        6.8107,
                                        5.52726,
                                        30.8546,
                                        3.79346,
                                        4.535495,
                                        7.59212,
                                        6.71991,
                                        5.88242,
                                        18.3911,
                                        9.28811,
                                        4.276122,
                                        13.87758,
                                        5.0637,
                                        33.6457,
                                        4.493437,
                                        6.93437,
                                        5.10626,
                                        15.4326,
                                        3.931115,
                                        5.76099,
                                        6.49717,
                                        4.337107,
                                        7.7741,
                                        5.73569,
                                        8.18273,
                                        7.39955,
                                        18.103,
                                        4.250543,
                                        12.3715,
                                        3.845491,
                                        6.771,
                                        6.72333,
                                        5.4935,
                                        11.77161,
                                        5.09932,
                                        8.86036,
                                        8.245,
                                        9.0158,
                                        23.5376,
                                        3.246051,
                                        17.4497,
                                        4.218604,
                                        13.6398,
                                        25.087,
                                        28.0544,
                                        6.05565,
                                        10.21178,
                                        6.58527,
                                        23.4153,
                                        31.0271,
                                        4.74608,
                                        18.165,
                                        6.90319,
                                        6.14583,
                                        7.59222,
                                        7.00036,
                                        8.69305,
                                        12.2176,
                                        10.02321,
                                        6.64289,
                                        3.405264,
                                        23.8135,
                                        7.56003,
                                        9.21707,
                                        9.15196,
                                        7.93897,
                                        3.2905,
                                        6.89214,
                                        8.61268,
                                        6.09104,
                                        4.67726,
                                        15.9268,
                                        13.09424,
                                        4.56275,
                                        9.27815,
                                        3.677733,
                                        5.31117,
                                        13.46081,
                                        14.87196,
                                        5.74701,
                                        7.38092,
                                        8.9483,
                                        36.88,
                                        13.16483,
                                        11.0202,
                                        7.8997,
                                        18.2791,
                                        8.5036,
                                        3.27674,
                                        9.864,
                                        7.89321,
                                        25.933,
                                        7.69424,
                                        10.8857,
                                        6.9578,
                                        10.91,
                                        5.85745,
                                        6.3192,
                                        8.34489,
                                        18.4717,
                                        12.4063,
                                        6.02817,
                                        24.47866,
                                        15.7374,
                                        5.168274,
                                        8.6127,
                                        10.7326,
                                        14.06992,
                                        13.17707,
                                        14.82471,
                                        6.32233,
                                        7.88033,
                                        9.7245,
                                        2.953347,
                                        4.57386,
                                        6.343,
                                        11.2458,
                                        5.81463,
                                        4.289118,
                                        17.8889,
                                        27.2491,
                                        6.21409,
                                        4.38237,
                                        2.85954,
                                        7.1844,
                                        19.9376,
                                        14.46056,
                                        7.03117,
                                        5.73458,
                                        4.67211,
                                        20.4222,
                                        4.78649,
                                        5.91818,
                                        7.02264,
                                        4.405511,
                                        16.3639,
                                        4.316011,
                                        16.20158,
                                        9.70944,
                                        9.907,
                                        13.00079,
                                        6.549,
                                        3.741167,
                                        5.511619,
                                        3.75192,
                                        7.87754,
                                        8.0934,
                                        11.46514,
                                        2.92751,
                                        8.2053,
                                        16.57586,
                                        34.5606,
                                        3.743112,
                                        18.1426,
                                        13.0339,
                                        6.58167,
                                        23.134,
                                        9.51856,
                                        7.48431,
                                        5.055021,
                                        5.39012,
                                        13.1735,
                                        3.255633,
                                        5.49632,
                                        5.91032,
                                        5.81029,
                                        38.9111,
                                        22.5355,
                                        10.65895,
                                        19.3825,
                                        11.31962,
                                        8.328,
                                        14.89562,
                                        8.7024,
                                        19.4239,
                                        5.65126,
                                        10.3268,
                                        5.15235,
                                        3.52686,
                                        8.75033,
                                        11.5307,
                                        11.16954,
                                        4.8415,
                                        35.6896,
                                        10.46091,
                                        10.5625,
                                        4.524803,
                                        4.95716,
                                        4.213444,
                                        3.854798,
                                        8.7186,
                                        9.3304,
                                        4.628733,
                                        11.9439,
                                        3.065448,
                                        5.79172,
                                        24.14011,
                                        4.116391,
                                        11.5473,
                                        5.795,
                                        22.6263,
                                        7.5188,
                                        3.53024,
                                        16.62174,
                                        32.974,
                                        8.70221,
                                        4.058351,
                                        5.12989,
                                        14.68003,
                                        7.9112,
                                        24.86,
                                        19.8846,
                                        7.46699,
                                        25.155,
                                        8.88766,
                                        11.57934,
                                        8.29639,
                                        4.91725,
                                        16.5271,
                                        3.96975,
                                        2.830304,
                                        6.9171,
                                        15.8515,
                                        9.02145,
                                        25.305,
                                        16.2522,
                                        3.158093,
                                        16.80059,
                                        10.2341,
                                        18.1202,
                                        15.0656,
                                        7.9231,
                                        6.24472,
                                        3.754043,
                                        4.90206,
                                        5.73498,
                                        7.280086,
                                        23.928,
                                        3.97935,
                                        4.47588,
                                        5.895048,
                                        6.07489,
                                        16.7809,
                                        3.981581,
                                        7.226189,
                                        9.29759,
                                        11.49662,
                                        8.61462,
                                        5.313079,
                                        15.0276,
                                        15.4012,
                                        8.17154,
                                        3.43155,
                                        2.8561,
                                        6.45276,
                                        9.3275,
                                        10.85281,
                                        10.55574,
                                        12.6639,
                                        16.2405,
                                        4.17543,
                                        7.7934,
                                        2.804917,
                                        5.81894,
                                        14.7396,
                                        8.896,
                                        3.22936,
                                        4.83446,
                                        5.82345,
                                        7.6646,
                                        6.21677,
                                        7.32396,
                                        26.478,
                                        3.254853,
                                        8.35928,
                                        6.6046,
                                        2.80384,
                                        3.296333,
                                        8.4713,
                                        10.44313,
                                        7.747,
                                        4.012032,
                                        27.413,
                                        21.6704,
                                        12.2409,
                                        7.0331,
                                        5.46233,
                                        12.73012,
                                        11.24437,
                                        15.6873,
                                        30.9111,
                                        15.65932,
                                        11.2433,
                                        5.304418,
                                        6.5913,
                                        12.32142,
                                        15.70785,
                                        5.56878,
                                        8.39039,
                                        7.1055,
                                        11.7573,
                                        3.67082,
                                        7.66701,
                                        7.96967,
                                        12.48357,
                                        14.60114,
                                        17.38239,
                                        25.471,
                                        10.75954,
                                        16.5191,
                                        5.860635,
                                        5.38262,
                                        4.88892,
                                        26.308,
                                        8.96318,
                                        3.369671,
                                        16.3299,
                                        18.1655,
                                        27.365,
                                        6.337172,
                                        26.581,
                                        4.06173,
                                        5.24998,
                                        8.5753,
                                        3.331652,
                                        38.7804,
                                        6.7509,
                                        10.38264,
                                        18.6719,
                                        8.6764,
                                        4.67966,
                                        4.44398,
                                        12.1256,
                                        11.6542,
                                        4.97141,
                                        6.46038,
                                        5.30006,
                                        7.52269,
                                        11.0143,
                                        3.856356,
                                        11.5292,
                                        8.0143,
                                        10.73965,
                                        24.8935,
                                        5.86428,
                                        11.4441,
                                        8.75402,
                                        11.5619,
                                        8.33758,
                                        6.0952,
                                        4.72459,
                                        5.4346,
                                        7.5566,
                                        7.77844,
                                        14.3735,
                                        22.1759,
                                        12.8266,
                                        3.77883,
                                        11.5649,
                                        5.311871,
                                        5.53922,
                                        5.81589,
                                        7.7701,
                                        19.2923,
                                        8.1741,
                                        29.8489,
                                        19.7856,
                                        4.53611,
                                        5.74145,
                                        13.6486,
                                        22.527,
                                        15.3306,
                                        6.5496,
                                        12.253,
                                        10.7176,
                                        10.76437,
                                        5.575567,
                                        28.484,
                                        9.532,
                                        5.91297,
                                        10.77337,
                                        19.7254,
                                        5.93124,
                                        9.25483,
                                        16.4084,
                                        28.164,
                                        6.18751,
                                        13.80554,
                                        9.8734,
                                        5.88693,
                                        17.5686,
                                        28.027,
                                        15.5608,
                                        14.57504,
                                        15.896,
                                        4.60783,
                                        11.74096,
                                        6.96397,
                                        7.4825,
                                        13.87593,
                                        5.323631,
                                        7.76965,
                                        39.0902,
                                        8.64468,
                                        5.22063,
                                        5.31071,
                                        3.755067,
                                        7.50099,
                                        12.9943,
                                        4.85148,
                                        4.843928,
                                        11.6644,
                                        4.495845,
                                        6.15161,
                                        16.1844,
                                        6.189593,
                                        11.39319,
                                        17.6126,
                                        13.66719,
                                        19.7726,
                                        4.25311,
                                        8.18005,
                                        4.95415,
                                        2.72893,
                                        7.339,
                                        13.98636,
                                        3.92458,
                                        10.89065,
                                        5.32399,
                                        6.803286,
                                        9.074173,
                                        15.4401,
                                        27.3967,
                                        4.87932,
                                        4.758,
                                        25.465,
                                        5.06631,
                                        7.05692,
                                        12.0142,
                                        16.3823,
                                        11.52888,
                                        8.34981,
                                        15.9844,
                                        10.71844,
                                        9.51122,
                                        9.0231,
                                        4.023753,
                                        3.40731,
                                        8.33205,
                                        13.20869,
                                        3.94556,
                                        7.36014,
                                        5.83275,
                                        7.03218,
                                        7.8117,
                                        6.59064,
                                        3.96051,
                                        15.1705,
                                        13.5607,
                                        18.7936,
                                        10.66844,
                                        4.41947,
                                        16.3133,
                                        16.1729,
                                        23.6703,
                                        7.6534,
                                        6.35582,
                                        5.65454,
                                        12.17458,
                                        15.7286,
                                        14.4767,
                                        7.53138,
                                        4.94529,
                                        10.86189,
                                        30.825,
                                        8.9165,
                                        29.1758,
                                        5.79237,
                                        6.38563,
                                        5.93183,
                                        14.463,
                                        5.22042,
                                        6.32154,
                                        5.34749,
                                        17.5557,
                                        7.04108,
                                        7.55709,
                                        10.76897,
                                        5.05027,
                                        7.910362,
                                        9.78694,
                                        24.9388,
                                        12.62463,
                                        6.29005,
                                        5.53176,
                                        7.7424,
                                        2.689764,
                                        12.27,
                                        6.081435,
                                        10.0262,
                                        31.2783,
                                        22.5465,
                                        4.37183,
                                        12.23815,
                                        7.4253,
                                        6.1871,
                                        4.234083,
                                        17.7103,
                                        5.2576,
                                        8.11957,
                                        5.987981,
                                        30.3876,
                                        9.2662,
                                        3.358101,
                                        10.5623,
                                        4.51254,
                                        9.95798,
                                        5.129365,
                                        5.802854,
                                        5.295743,
                                        29.599,
                                        3.81934,
                                        20.582,
                                        4.25016,
                                        13.51698,
                                        6.16229,
                                        5.56515,
                                        26.5814,
                                        22.2459,
                                        15.8287,
                                        6.44111,
                                        19.6802,
                                        29.92,
                                        3.639114,
                                        16.62869,
                                        4.701204,
                                        9.8342,
                                        12.68499,
                                        31.5617,
                                        14.31031,
                                        21.7369,
                                        9.37509,
                                        14.60796,
                                        4.65265,
                                        17.1066,
                                        3.62827,
                                        6.57887,
                                        13.32997,
                                        3.273103,
                                        18.11914,
                                        24.4987,
                                        4.775377,
                                        3.98719,
                                        17.1502,
                                        8.2997,
                                        4.811096,
                                        6.9622,
                                        9.8989,
                                        12.67842,
                                        4.70448,
                                        4.7979,
                                        7.2316,
                                        23.059,
                                        17.8245,
                                        4.73456,
                                        16.81384,
                                        34.892,
                                        6.86789,
                                        13.84864,
                                        8.88502,
                                        20.2095,
                                        9.3652,
                                        8.7079,
                                        6.3267,
                                        6.15444,
                                        6.41089,
                                        8.6074,
                                        4.856336,
                                        3.56461,
                                        4.46562,
                                        25.2285,
                                        15.77149,
                                        22.3341,
                                        18.5832,
                                        9.2744,
                                        19.9764,
                                        8.00613,
                                        5.29077,
                                        5.710151,
                                        11.8764,
                                        8.8116,
                                        7.77239,
                                        5.48503,
                                        6.5084,
                                        5.92193,
                                        5.224663,
                                        4.277184,
                                        7.71743,
                                        14.79565,
                                        16.4986,
                                        19.65617,
                                        4.76386,
                                        4.622802,
                                        5.297704,
                                        4.75449,
                                        6.9231,
                                        29.6922,
                                        20.3684,
                                        3.60405,
                                        11.13002,
                                        6.895226,
                                        11.67828,
                                        10.44213,
                                        6.30029,
                                        4.390117,
                                        11.28291,
                                        12.05207,
                                        4.9116,
                                        17.4462,
                                        16.14033,
                                        14.60774,
                                        7.99649,
                                        8.6589,
                                        8.79078,
                                        5.270255,
                                        21.9917,
                                        20.7506,
                                        25.315,
                                        9.84425,
                                        6.51686,
                                        25.2626,
                                        5.699152,
                                        28.9659,
                                        5.99265,
                                        6.082754,
                                        5.529594,
                                        16.52179,
                                        10.40828,
                                        13.6638,
                                        6.21361,
                                        38.779,
                                        8.0714,
                                        6.88905,
                                        13.1348,
                                        5.06419,
                                        23.673,
                                        3.244843,
                                        7.67345,
                                        3.72743,
                                        12.16569,
                                        13.19055,
                                        7.62031,
                                        5.19522,
                                        21.96,
                                        14.17103,
                                        7.332527,
                                        13.7172,
                                        12.3462,
                                        12.86667,
                                        2.8708658,
                                        14.0729,
                                        11.71538,
                                        7.443224,
                                        5.431464,
                                        8.3288,
                                        4.02005,
                                        2.9783,
                                        16.50449,
                                        38.036,
                                        9.1167,
                                        13.31,
                                        9.97306,
                                        16.7187,
                                        15.1533,
                                        7.102,
                                        6.00058,
                                        17.123,
                                        7.19074,
                                        14.8865,
                                        7.4579,
                                        7.00669,
                                        35.379,
                                        3.91015,
                                        3.94831,
                                        4.828994,
                                        4.91316,
                                        3.706036,
                                        8.2472,
                                        5.99494,
                                        4.429487,
                                        7.31445,
                                        20.6636,
                                        3.089817,
                                        10.31304,
                                        10.55227,
                                        11.62654,
                                        5.755957,
                                        23.8592,
                                        25.739,
                                        7.04203,
                                        20.8872,
                                        5.88567,
                                        6.6807,
                                        5.50921,
                                        24.6981,
                                        5.09976,
                                        11.0906,
                                        17.6191,
                                        4.333473,
                                        5.223336,
                                        7.71098,
                                        4.78247,
                                        17.2683,
                                        12.47036,
                                        5.2234,
                                        10.2536,
                                        17.7108,
                                        3.081545,
                                        8.288,
                                        4.91175,
                                        7.7282,
                                        20.5987,
                                        2.94252,
                                        4.23127,
                                        7.0871,
                                        7.480076,
                                        6.48741,
                                        8.20757,
                                        5.184647,
                                        5.797863,
                                        8.45178,
                                        11.61502,
                                        12.6635,
                                        29.087,
                                        3.220524,
                                        7.1326,
                                        4.473585,
                                        8.803,
                                        3.980175,
                                        8.753,
                                        17.10265,
                                        13.2832,
                                        12.89356,
                                        6.46063,
                                        4.50814,
                                        3.49182,
                                        6.4574,
                                        4.83452,
                                        14.1886,
                                        6.51668,
                                        3.42301,
                                        20.06,
                                        5.778025,
                                        10.5778,
                                        3.94988,
                                        3.23707,
                                        6.86015,
                                        26.3926,
                                        2.91146,
                                        3.63759,
                                        7.43566,
                                        4.540231,
                                        21.6837,
                                        16.46837,
                                        21.0768,
                                        6.40939,
                                        5.304065,
                                        3.88264,
                                        14.73081,
                                        15.92872,
                                        21.3639,
                                        16.8569,
                                        8.41554,
                                        6.21513,
                                        3.40379,
                                        4.850424,
                                        3.10358,
                                        9.8215,
                                        7.14117,
                                        6.9737,
                                        18.0386,
                                        5.112264,
                                        13.09803,
                                        7.42756,
                                        5.97805,
                                        4.93247,
                                        16.18943,
                                        25.3079,
                                        8.4623,
                                        10.06448,
                                        10.9589,
                                        5.425895,
                                        18.4172,
                                        2.79415,
                                        8.908485,
                                        12.484,
                                        3.74936,
                                        16.59992,
                                        6.7433,
                                        12.08227,
                                        6.3808,
                                        36.5372,
                                        16.92668,
                                        17.8223,
                                        2.83425,
                                        2.76144,
                                        4.91707,
                                        7.274467,
                                        14.8927,
                                        14.25662,
                                        30.104,
                                        19.902,
                                        27.2404,
                                        10.8168,
                                        10.74718,
                                        4.963349,
                                        6.56391,
                                        15.7332,
                                        27.0703,
                                        3.396233,
                                        5.33131,
                                        16.3085,
                                        4.71679,
                                        5.77911,
                                        5.5101,
                                        8.0026,
                                        7.3561,
                                        31.464,
                                        9.404937,
                                        21.8135,
                                        16.3071,
                                        3.93993,
                                        29.7283,
                                        5.550877,
                                        10.15172,
                                        19.4283,
                                        4.709381,
                                        10.75425,
                                        9.6795,
                                        8.84225,
                                        5.65534,
                                        21.0401,
                                        6.66881,
                                        16.301,
                                        5.62338,
                                        10.05822,
                                        9.01547,
                                        13.11,
                                        10.05155,
                                        11.9214,
                                        24.8544,
                                        6.04327,
                                        8.9969,
                                        4.75014,
                                        15.62385,
                                        6.04484,
                                        6.82885,
                                        4.633602,
                                        22.0161,
                                        14.29164,
                                        14.848,
                                        3.18483,
                                        4.391241,
                                        6.68322,
                                        9.08566,
                                        9.01945,
                                        8.7823,
                                        6.14518,
                                        6.75887,
                                        5.94052,
                                        9.8114,
                                        4.453817,
                                        10.47837,
                                        6.54245,
                                        4.440427,
                                        2.86684,
                                        8.4585,
                                        11.15569,
                                        12.3397,
                                        4.267015,
                                        17.8666,
                                        13.6266,
                                        4.73446,
                                        12.5126,
                                        25.4135,
                                        10.86318,
                                        8.29055,
                                        4.475115,
                                        6.92837,
                                        6.14986,
                                        3.491214,
                                        26.4879,
                                        4.749057,
                                        13.82559,
                                        13.872,
                                        2.88946,
                                        7.0888,
                                        16.48013,
                                        15.36114,
                                        4.633632,
                                        5.45924,
                                        3.03407,
                                        11.28783,
                                        3.98727,
                                        13.42631,
                                        7.53271,
                                        11.57729,
                                        6.42523,
                                        14.73572,
                                        29.8754,
                                        5.03349,
                                        18.6498,
                                        25.977,
                                        6.17081,
                                        17.7779,
                                        6.79534,
                                        26.4146,
                                        12.01173,
                                        6.110939,
                                        3.53322,
                                        8.712337,
                                        4.83248,
                                        5.05594,
                                        9.7385,
                                        12.29088,
                                        31.4625,
                                        29.7739,
                                        15.02987,
                                        33.269,
                                        3.05561,
                                        7.138844,
                                        33.1039,
                                        7.3451,
                                        5.42686,
                                        13.91478,
                                        9.15751,
                                        7.5994,
                                        6.2222,
                                        6.71574,
                                        13.58364,
                                        3.88357,
                                        11.76897,
                                        5.9464,
                                        3.473808,
                                        5.236732,
                                        4.62085,
                                        8.03312,
                                        6.7709,
                                        4.79517,
                                        36.694,
                                        7.33198,
                                        4.75528,
                                        7.87149,
                                        7.6434,
                                        11.0858,
                                        13.2337,
                                        5.0652,
                                        6.42941,
                                        4.35664,
                                        5.146447,
                                        9.42533,
                                        8.7603,
                                        8.5318,
                                        7.4278,
                                        4.40217,
                                        8.02054,
                                        8.2788,
                                        3.9848,
                                        11.87655,
                                        6.51152,
                                        8.52236,
                                        5.87016,
                                        5.81109,
                                        13.3979,
                                        7.74528,
                                        5.36309,
                                        5.65533,
                                        25.2751,
                                        6.82071,
                                        2.908459,
                                        6.00651,
                                        16.97876,
                                        9.2749,
                                        5.72752,
                                        12.79954,
                                        9.49817,
                                        11.2681,
                                        13.9648,
                                        5.48411,
                                        3.55534,
                                        4.2534,
                                        17.5418,
                                        5.22126,
                                        12.499,
                                        5.36719,
                                        20.918,
                                        19.3007,
                                        6.45669,
                                        10.59622,
                                        11.388336,
                                        10.56272,
                                        33.129,
                                        3.6405,
                                        15.84182,
                                        4.801067,
                                        5.33756,
                                        4.86996,
                                        8.8001,
                                        2.92784,
                                        4.1482015,
                                        19.4862,
                                        11.51175,
                                        9.03506,
                                        3.831183,
                                        24.731,
                                        36.457,
                                        11.91435,
                                        18.17686,
                                        3.80248,
                                        24.737,
                                        4.22158,
                                        9.2641,
                                        32.94,
                                        12.8056,
                                        5.727546,
                                        6.07087,
                                        6.3224,
                                        9.4595,
                                        14.0056,
                                        7.72328,
                                        3.167338,
                                        18.35121,
                                        5.21131,
                                        14.4229,
                                        38.9366,
                                        12.50105,
                                        19.0425,
                                        10.74359,
                                        5.02107,
                                        6.89205,
                                        18.4192,
                                        14.2668,
                                        5.38992,
                                        6.11992,
                                        5.76537,
                                        4.857162,
                                        9.19182,
                                        4.756504,
                                        9.4661,
                                        4.17102,
                                        6.08011,
                                        8.22976,
                                        2.84695,
                                        8.5399,
                                        5.151729,
                                        15.1391,
                                        6.54858,
                                        10.9554,
                                        4.44889,
                                        4.94204,
                                        4.03334,
                                        26.728,
                                        4.82257,
                                        10.1281,
                                        8.76306,
                                        4.742878,
                                        7.3093,
                                        6.256098,
                                        5.385282,
                                        28.3492,
                                        23.575,
                                        5.83972,
                                        9.2135,
                                        11.17342,
                                        8.28307,
                                        9.8032,
                                        32.3276,
                                        3.79642,
                                        3.18274,
                                        15.579,
                                        4.14169,
                                        17.2236,
                                        6.10549,
                                        14.81312,
                                        10.8301,
                                        3.67514,
                                        10.7091,
                                        17.6039,
                                        17.6568,
                                        6.35983,
                                        8.07992,
                                        9.88466,
                                        3.105289,
                                        32.1957,
                                        3.27491,
                                        9.6289,
                                        7.5969,
                                        6.6809,
                                        9.1118,
                                        4.45186,
                                        15.5638,
                                        29.497,
                                        14.6753,
                                        16.7289,
                                        5.48469,
                                        6.32571,
                                        4.192908,
                                        7.1889,
                                        18.18671,
                                        8.5412,
                                        10.2626,
                                        4.460962,
                                        12.0246,
                                        8.76901,
                                        4.545174,
                                        7.2835,
                                        3.830791,
                                        12.60247,
                                        4.28963,
                                        12.37051,
                                        6.3485,
                                        3.62417,
                                        5.67526,
                                        5.46285,
                                        21.9213,
                                        14.27885,
                                        7.1715,
                                        8.998,
                                        15.3107,
                                        11.8454,
                                        14.08574,
                                        5.21747,
                                        8.3602,
                                        5.138238,
                                        5.626646,
                                        3.346506,
                                        5.42848,
                                        10.66703,
                                        35.3979,
                                        3.98604,
                                        11.2298,
                                        8.62926,
                                        4.70656,
                                        5.59803,
                                        9.0083,
                                        9.05326,
                                        6.65682,
                                        4.09148,
                                        6.191268,
                                        9.5506,
                                        18.8532,
                                        11.86918,
                                        7.3011,
                                        3.93261,
                                        12.96039,
                                        3.85864,
                                        8.13631,
                                        27.8899,
                                        12.83613,
                                        8.1772,
                                        8.3113,
                                        3.20602,
                                        6.08502,
                                        5.62277,
                                        10.10068,
                                        5.57811,
                                        12.5993,
                                        3.07733,
                                        12.0746,
                                        8.01533,
                                        10.8683,
                                        3.50848,
                                        10.7035,
                                        5.890423,
                                        3.968199,
                                        7.57192,
                                        9.22795,
                                        8.56115,
                                        16.8073,
                                        12.58595,
                                        12.0395,
                                        15.0356,
                                        24.55,
                                        4.57212,
                                        6.65164,
                                        16.47838,
                                        6.45432,
                                        9.2511,
                                        3.12579,
                                        22.2178,
                                        4.736283,
                                        7.54667,
                                        3.808352,
                                        14.04493,
                                        16.42952,
                                        9.12418,
                                        8.8736,
                                        7.22439,
                                        4.937945,
                                        10.5721,
                                        9.7688,
                                        4.135935,
                                        6.95412,
                                        7.311,
                                        7.83671,
                                        9.31556,
                                        13.0536,
                                        18.5538,
                                        4.349711,
                                        12.10054,
                                        7.715487,
                                        8.926,
                                        6.4422,
                                        13.3314,
                                        6.103004,
                                        3.607456,
                                        6.25033,
                                        14.2492,
                                        4.71654,
                                        9.9125,
                                        8.168271,
                                        8.324,
                                        3.05459,
                                        7.2344,
                                        18.1093,
                                        10.9258,
                                        11.6784,
                                        15.99201,
                                        4.87093,
                                        11.06211,
                                        22.9925,
                                        3.341929,
                                        30.3835,
                                        11.37433,
                                        5.220312,
                                        21.786,
                                        7.59195,
                                        11.7372,
                                        7.5498,
                                        16.986,
                                        4.202622,
                                        5.92748,
                                        5.388645,
                                        12.7201,
                                        10.1494,
                                        8.80725,
                                        27.459,
                                        9.2987,
                                        15.8948,
                                        3.759427,
                                        4.587818,
                                        3.836544,
                                        10.58389,
                                        32.12,
                                        7.7296,
                                        12.07095,
                                        6.01375,
                                        8.2282,
                                        2.68212,
                                        5.48852,
                                        4.566946,
                                        9.4583,
                                        17.26956,
                                        8.34626,
                                        9.6237,
                                        5.43106,
                                        8.9619,
                                        10.5077,
                                        31.0651,
                                        7.78887,
                                        9.4948,
                                        4.42408,
                                        12.3767,
                                        11.6484,
                                        7.54301,
                                        9.7395,
                                        19.702,
                                        7.6896,
                                        8.09902,
                                        4.07546,
                                        10.7609,
                                        4.588139,
                                        8.3778,
                                        6.0561,
                                        4.76878,
                                        5.024756,
                                        11.3098,
                                        9.2736,
                                        9.8953,
                                        3.950409,
                                        6.72984,
                                        6.14775,
                                        19.8698,
                                        3.01958,
                                        3.9918,
                                        12.9971,
                                        8.0264,
                                        32.752,
                                        6.06151,
                                        10.05633,
                                        10.198,
                                        5.57472,
                                        14.2444,
                                        11.00641,
                                        26.0454,
                                        12.87857,
                                        7.2957,
                                        18.14818,
                                        16.7412,
                                        6.51414,
                                        11.57031,
                                        12.98629,
                                        17.7466,
                                        11.97648,
                                        4.502262,
                                        2.834752,
                                        8.7905,
                                        24.66,
                                        4.97691,
                                        30.6296,
                                        7.4013,
                                        6.14188,
                                        9.17821,
                                        2.98117,
                                        2.82123,
                                        4.201889,
                                        32.843,
                                        6.7119,
                                        6.00455,
                                        6.14149,
                                        10.19942,
                                        33.598,
                                        3.39211,
                                        20.7197,
                                        17.2347,
                                        6.81819,
                                        7.8378,
                                        38.4856,
                                        32.485,
                                        6.12464,
                                        12.6609,
                                        7.22117,
                                        3.957489,
                                        3.29724,
                                        12.74557,
                                        5.51867,
                                        5.981768,
                                        12.9852,
                                        4.96929,
                                        12.3008,
                                        5.85558,
                                        5.4872,
                                        18.6976,
                                        4.03291,
                                        5.1449,
                                        5.93845,
                                        4.58461,
                                        11.3762,
                                        6.7658,
                                        6.4913,
                                        9.8747,
                                        6.22901,
                                        4.132005,
                                        25.629,
                                        4.18297,
                                        17.3382,
                                        4.07275,
                                        8.1864,
                                        2.65109,
                                        3.34473,
                                        5.29566,
                                        19.4547,
                                        3.6821,
                                        6.26116,
                                        15.26088,
                                        6.19295,
                                        6.0558,
                                        3.82419,
                                        15.57445,
                                        6.72089,
                                        13.6283,
                                        5.34628,
                                        8.70543,
                                        5.80471,
                                        21.702,
                                        5.886381,
                                        5.35529,
                                        4.59487,
                                        14.30444,
                                        7.43019,
                                        5.47369,
                                        11.00818,
                                        19.7784,
                                        6.82198,
                                        13.8549,
                                        3.872921,
                                        5.60616,
                                        7.1652,
                                        3.02466,
                                        5.41192,
                                        7.93161,
                                        9.46888,
                                        8.0661,
                                        3.58491,
                                        10.12647,
                                        5.65496,
                                        7.82401,
                                        25.03,
                                        7.09741,
                                        5.50661,
                                        7.78484,
                                        5.0291,
                                        6.91599,
                                        15.97894,
                                        5.08397,
                                        3.00368,
                                        21.1061,
                                        11.3452,
                                        4.11882,
                                        35.457,
                                        14.7784,
                                        9.4977,
                                        5.15354,
                                        4.729881,
                                        8.8309,
                                        5.8944,
                                        11.178,
                                        35.984,
                                        11.0335,
                                        9.58191,
                                        5.86069,
                                        3.07843,
                                        15.11168,
                                        5.91899,
                                        5.60414,
                                        6.96856,
                                        6.41388,
                                        6.65168,
                                        8.84684,
                                        4.366448,
                                        4.77529,
                                        12.41064,
                                        7.35225,
                                        12.62133,
                                        5.88943,
                                        5.62439,
                                        12.6442,
                                        3.754939,
                                        10.8912,
                                        8.24444,
                                        7.56049,
                                        27.908,
                                        5.35352,
                                        17.3032,
                                        37.4673,
                                        31.999,
                                        5.30684,
                                        11.40654,
                                        12.02068,
                                        4.54695,
                                        2.38144,
                                        12.60236,
                                        18.2012,
                                        6.9969,
                                        36.3634,
                                        3.833596,
                                        4.29605,
                                        4.334986,
                                        7.7854,
                                        6.664541,
                                        19.4973,
                                        16.0657,
                                        3.69248,
                                        9.18041,
                                        17.385,
                                        11.39848,
                                        17.4192,
                                        7.7477,
                                        3.3384,
                                        3.818803,
                                        6.25826,
                                        8.39995,
                                        9.07129,
                                        6.50916,
                                        3.648004,
                                        4.87242,
                                        4.170135,
                                        5.94819,
                                        6.04832,
                                        14.6192,
                                        4.43848,
                                        3.081748,
                                        3.56397,
                                        7.31866,
                                        5.08681,
                                        7.9971,
                                        8.8438,
                                        24.882,
                                        3.13567,
                                        7.81322,
                                        11.33218,
                                        5.46872,
                                        6.95407,
                                        15.80439,
                                        10.223,
                                        7.11539,
                                        6.09829,
                                        9.80729,
                                        5.782348,
                                        12.3905,
                                        4.052456,
                                        13.72205,
                                        5.93334,
                                        2.6608,
                                        13.6509,
                                        16.132,
                                        19.8367,
                                        5.34192,
                                        4.48752,
                                        7.8764,
                                        6.49387,
                                        16.29597,
                                        8.45602,
                                        4.41931,
                                        3.33957,
                                        8.151,
                                        7.8066,
                                        3.268278,
                                        4.538,
                                        18.7874,
                                        14.70063,
                                        3.42625,
                                        4.780779,
                                        7.22386,
                                        4.01625,
                                        5.08688,
                                        16.341,
                                        3.78711,
                                        11.51721,
                                        27.45,
                                        11.7921,
                                        4.080361,
                                        7.9357,
                                        5.43215,
                                        7.34295,
                                        5.750249,
                                        17.5728,
                                        3.603957,
                                        4.53809,
                                        17.94072,
                                        14.92631,
                                        15.4043,
                                        8.332827,
                                        26.4613,
                                        19.7976,
                                        5.584139,
                                        22.34156,
                                        4.292622,
                                        4.578719,
                                        5.37616,
                                        9.47747,
                                        16.18338,
                                        10.20765,
                                        12.9889,
                                        11.2767,
                                        39.632,
                                        7.79859,
                                        9.26327,
                                        11.54203,
                                        15.854,
                                        10.64977,
                                        4.085744,
                                        5.16491,
                                        6.19296,
                                        5.3934,
                                        6.11446,
                                        10.4336,
                                        30.766,
                                        4.82756,
                                        9.47069,
                                        9.4072,
                                        8.1917,
                                        18.60888,
                                        11.79416,
                                        35.408,
                                        11.3333,
                                        4.00366,
                                        3.35213,
                                        2.96559,
                                        6.58112,
                                        8.56077,
                                        8.04945,
                                        12.18978,
                                        11.4181,
                                        27.0492,
                                        17.574,
                                        5.32875,
                                        5.52237,
                                        6.558359,
                                        13.10977,
                                        18.1855,
                                        5.58892,
                                        7.85232,
                                        8.57227,
                                        24.5466,
                                        4.195948,
                                        5.83977,
                                        5.01327,
                                        35.7064,
                                        8.71636,
                                        17.7553,
                                        4.116857,
                                        6.26556,
                                        4.552043,
                                        19.8201,
                                        5.87356,
                                        30.975,
                                        4.79351,
                                        8.75121,
                                        5.177082,
                                        9.6361,
                                        18.1847,
                                        4.80563,
                                        5.94201,
                                        20.8894,
                                        6.54448,
                                        4.416246,
                                        4.30101,
                                        4.775587,
                                        4.82945,
                                        20.652,
                                        5.65009,
                                        7.16585,
                                        35.536,
                                        8.03953,
                                        2.946471,
                                        5.5386,
                                        3.218279,
                                        4.007347,
                                        5.99686,
                                        10.99156,
                                        3.83701,
                                        15.94121,
                                        4.3639,
                                        7.88694,
                                        5.11904,
                                        4.430338,
                                        10.81765,
                                        7.33797,
                                        12.25583,
                                        4.27371,
                                        4.414545,
                                        16.0558,
                                        4.714793,
                                        4.67828,
                                        9.86689,
                                        10.42468,
                                        8.25352,
                                        4.95361,
                                        4.55861,
                                        14.8974,
                                        5.79973,
                                        4.354959,
                                        12.1281,
                                        7.36207,
                                        12.02713,
                                        4.05181,
                                        7.0655,
                                        5.679,
                                        10.0886,
                                        9.7965,
                                        20.2769,
                                        10.21938,
                                        20.4672,
                                        16.68678,
                                        9.34779,
                                        3.76288,
                                        5.376914,
                                        8.14008,
                                        20.1407,
                                        3.46239,
                                        14.30065,
                                        6.53058,
                                        5.25047,
                                        4.00934,
                                        8.16961,
                                        8.654,
                                        2.900652,
                                        8.57603,
                                        7.4146,
                                        3.25584,
                                        20.1514,
                                        2.738963,
                                        4.30827,
                                        3.53078,
                                        12.5858,
                                        21.907,
                                        11.00463,
                                        8.14533,
                                        8.55068,
                                        3.93494,
                                        18.2183,
                                        18.4916,
                                        9.3857,
                                        8.57173,
                                        26.3269,
                                        6.71683,
                                        5.72336,
                                        8.6286,
                                        11.0087,
                                        3.42015,
                                        5.21185,
                                        5.25638,
                                        4.97347,
                                        7.11754,
                                        6.99531,
                                        38.418,
                                        5.90613,
                                        10.5245,
                                        6.350319,
                                        8.86987,
                                        19.5838,
                                        16.5206,
                                        33.5996,
                                        14.4428,
                                        3.387872,
                                        21.5678,
                                        8.18438,
                                        7.6251,
                                        3.392044,
                                        5.98599,
                                        14.93046,
                                        14.03086,
                                        11.65376,
                                        7.4537,
                                        2.68555,
                                        7.3469,
                                        5.35059,
                                        22.6973,
                                        6.37023,
                                        7.51541,
                                        6.11176,
                                        2.98389,
                                        14.15783,
                                        15.8666,
                                        5.80678,
                                        9.9129,
                                        2.88024,
                                        7.859,
                                        17.4599,
                                        4.477648,
                                        3.293677,
                                        6.5118,
                                        11.81807,
                                        5.23784,
                                        7.95879,
                                        7.5238,
                                        4.66274,
                                        11.03204,
                                        5.12487,
                                        4.328158,
                                        10.63095,
                                        5.40586,
                                        9.49285,
                                        8.0117,
                                        16.642,
                                        5.96389,
                                        12.23696,
                                        5.06893,
                                        5.30526,
                                        7.3122,
                                        12.72097,
                                        3.037976,
                                        11.72446,
                                        17.52464,
                                        6.05815,
                                        5.94639,
                                        8.2777,
                                        11.47995,
                                        6.31376,
                                        9.8382,
                                        4.98791,
                                        12.10795,
                                        5.206276,
                                        23.856,
                                        6.3775,
                                        3.838241,
                                        10.0633,
                                        5.56318,
                                        4.91645,
                                        7.4585,
                                        21.15,
                                        3.97542,
                                        16.2804,
                                        9.76503,
                                        17.14962,
                                        10.92666,
                                        15.7097,
                                        9.65855,
                                        7.067965,
                                        9.29614,
                                        5.35191,
                                        4.62852,
                                        8.0062,
                                        15.92947,
                                        2.89442,
                                        4.80764,
                                        2.9175,
                                        6.98132,
                                        4.72681,
                                        33.751,
                                        6.63467,
                                        4.754885,
                                        11.5871,
                                        8.10428,
                                        9.2723,
                                        19.2892,
                                        6.90907,
                                        9.226,
                                        5.338032,
                                        5.52983,
                                        2.828681,
                                        34.9672,
                                        20.222,
                                        8.18632,
                                        3.998344,
                                        5.38711,
                                        12.95203,
                                        12.40882,
                                        9.6257,
                                        10.38692,
                                        16.54064,
                                        10.6157,
                                        5.66079,
                                        5.19936,
                                        5.43521,
                                        8.99832,
                                        4.74194,
                                        14.4841,
                                        6.11236,
                                        18.2088,
                                        12.08464,
                                        11.19512,
                                        3.68745,
                                        3.491177,
                                        8.51639,
                                        2.74295,
                                        5.61757,
                                        8.0957,
                                        8.67795,
                                        10.51693,
                                        12.19702,
                                        6.16556,
                                        9.4198,
                                        3.504623,
                                        10.0079,
                                        2.97563,
                                        7.18007,
                                        7.01849,
                                        7.10002,
                                        27.383,
                                        5.62998,
                                        12.0123,
                                        6.21128,
                                        4.887228,
                                        4.30708,
                                        4.62239,
                                        5.83793,
                                        8.16154,
                                        10.1185,
                                        4.888081,
                                        22.76703,
                                        20.9926,
                                        16.20582,
                                        29.8482,
                                        10.26957,
                                        5.183641,
                                        11.2555,
                                        11.56835,
                                        4.504947,
                                        8.3915,
                                        6.00235,
                                        5.23095,
                                        18.5518,
                                        5.370888,
                                        2.78291,
                                        7.31071,
                                        19.4516,
                                        22.3733,
                                        16.4461,
                                        14.46136,
                                        5.46874,
                                        4.04358,
                                        9.44712,
                                        4.263215,
                                        7.4702,
                                        5.628254,
                                        17.2595,
                                        5.30387,
                                        6.93981,
                                        2.39006,
                                        7.8514,
                                        32.5831,
                                        25.5438,
                                        8.86606,
                                        6.36489,
                                        35.0639,
                                        6.82038,
                                        5.582028,
                                        9.2512,
                                        6.81025,
                                        19.7912,
                                        5.55925,
                                        10.90225,
                                        7.45073,
                                        10.853,
                                        6.51989,
                                        12.37082,
                                        10.20367,
                                        16.10312,
                                        5.94894,
                                        15.23217,
                                        5.05209,
                                        9.99177,
                                        7.25225,
                                        12.31241,
                                        6.3543,
                                        13.68156,
                                        8.37419,
                                        4.49177,
                                        9.9648,
                                        6.041319,
                                        17.561,
                                        2.85839,
                                        4.244033,
                                        6.9029,
                                        9.45271,
                                        31.2708,
                                        8.65814,
                                        4.74927,
                                        4.87182,
                                        4.121569,
                                        10.9309,
                                        7.3971,
                                        13.35386,
                                        7.6529,
                                        9.8978,
                                        6.12588,
                                        12.3411,
                                        25.892,
                                        3.66329,
                                        39.782,
                                        4.76522,
                                        5.10887,
                                        6.7185,
                                        6.05018,
                                        5.552478,
                                        3.57401,
                                        19.4383,
                                        36.8936,
                                        10.19782,
                                        8.9668,
                                        10.84695,
                                        14.86664,
                                        12.3602,
                                        15.6246,
                                        8.3259,
                                        12.42541,
                                        8.65271,
                                        8.47252,
                                        9.7279,
                                        30.9475,
                                        29.4351,
                                        8.2905,
                                        29.366,
                                        6.56307,
                                        12.58745,
                                        6.729,
                                        22.0448,
                                        8.82,
                                        4.115592,
                                        16.07601,
                                        6.2263,
                                        9.0292,
                                        6.07018,
                                        2.787152,
                                        9.725,
                                        15.5763,
                                        34.94,
                                        7.7482,
                                        19.9524,
                                        6.47375,
                                        12.08505,
                                        8.8814,
                                        20.035,
                                        4.2665,
                                        5.36852,
                                        10.04007,
                                        5.77595,
                                        5.9468,
                                        16.09371,
                                        17.4991,
                                        4.90747,
                                        25.191,
                                        25.4807,
                                        6.99838,
                                        11.03316,
                                        12.7993,
                                        6.59007,
                                        31.316,
                                        13.68717,
                                        5.56712,
                                        13.06133,
                                        9.3019,
                                        5.92586,
                                        13.17203,
                                        5.0907,
                                        9.3023,
                                        12.862,
                                        12.8287,
                                        13.6221,
                                        5.180809,
                                        17.3855,
                                        4.096681,
                                        6.97888,
                                        16.43192,
                                        2.454632,
                                        7.16495,
                                        7.9319,
                                        5.371597,
                                        13.5953,
                                        4.81307,
                                        13.34135,
                                        13.48707,
                                        8.1572,
                                        7.92812,
                                        3.687842,
                                        13.2432,
                                        5.56386,
                                        12.20043,
                                        5.342124,
                                        9.9935,
                                        8.2332,
                                        6.21486,
                                        8.66034,
                                        10.5103,
                                        25.7385,
                                        10.37278,
                                        7.83002,
                                        14.31233,
                                        30.5006,
                                        4.61829,
                                        7.27529,
                                        32.124,
                                        12.5679,
                                        4.89949,
                                        8.10353,
                                        7.98098,
                                        5.89482,
                                        18.8455,
                                        11.579,
                                        7.63392,
                                        17.1464,
                                        11.7874,
                                        3.201264,
                                        4.919184,
                                        17.42175,
                                        4.080523,
                                        7.5657,
                                        16.66014,
                                        7.4622,
                                        6.26685,
                                        12.58309,
                                        3.140321,
                                        7.1063,
                                        4.516737,
                                        3.625554,
                                        4.84341,
                                        25.196,
                                        16.9543,
                                        4.536366,
                                        3.46903,
                                        8.6308,
                                        14.664,
                                        21.0966,
                                        7.51324,
                                        4.40902,
                                        11.77457,
                                        11.14849,
                                        3.547456,
                                        6.59536,
                                        14.3015,
                                        9.78271,
                                        5.85703,
                                        10.6915,
                                        15.0043,
                                        13.5555,
                                        3.89795,
                                        16.371,
                                        9.4148,
                                        13.4256,
                                        4.613301,
                                        15.59431,
                                        3.14325,
                                        2.702449,
                                        8.0551,
                                        3.269339,
                                        15.44664,
                                        22.1157,
                                        21.0122,
                                        6.9218,
                                        13.56669,
                                        4.2977,
                                        7.5786,
                                        5.198732,
                                        4.032947,
                                        3.8416,
                                        4.99166,
                                        6.63157,
                                        8.6142,
                                        12.53142,
                                        4.374596,
                                        7.55718,
                                        34.029,
                                        11.0453,
                                        6.01805,
                                        8.9454,
                                        7.02732,
                                        6.53146,
                                        7.47706,
                                        6.31334,
                                        6.39014,
                                        13.31195,
                                        4.95735,
                                        3.887664,
                                        2.79936,
                                        5.79715,
                                        4.81951,
                                        10.03807,
                                        5.87897,
                                        22.837,
                                        9.7671,
                                        25.503,
                                        3.810595,
                                        4.92838,
                                        12.5285,
                                        7.585,
                                        9.4074,
                                        15.60196,
                                        9.3316,
                                        16.7073,
                                        4.82676,
                                        3.3557,
                                        5.26367,
                                        6.12607,
                                        6.4239,
                                        5.751871,
                                        8.8867,
                                        13.7285,
                                        9.67075,
                                        4.165792,
                                        30.608
                                    ]
                                }
                            ],
                            "layout": {
                                "template": {
                                    "data": {
                                        "bar": [
                                            {
                                                "error_x": {
                                                    "color": "#2a3f5f"
                                                },
                                                "error_y": {
                                                    "color": "#2a3f5f"
                                                },
                                                "marker": {
                                                    "line": {
                                                        "color": "#E5ECF6",
                                                        "width": 0.5
                                                    },
                                                    "pattern": {
                                                        "fillmode": "overlay",
                                                        "size": 10,
                                                        "solidity": 0.2
                                                    }
                                                },
                                                "type": "bar"
                                            }
                                        ],
                                        "barpolar": [
                                            {
                                                "marker": {
                                                    "line": {
                                                        "color": "#E5ECF6",
                                                        "width": 0.5
                                                    },
                                                    "pattern": {
                                                        "fillmode": "overlay",
                                                        "size": 10,
                                                        "solidity": 0.2
                                                    }
                                                },
                                                "type": "barpolar"
                                            }
                                        ],
                                        "carpet": [
                                            {
                                                "aaxis": {
                                                    "endlinecolor": "#2a3f5f",
                                                    "gridcolor": "white",
                                                    "linecolor": "white",
                                                    "minorgridcolor": "white",
                                                    "startlinecolor": "#2a3f5f"
                                                },
                                                "baxis": {
                                                    "endlinecolor": "#2a3f5f",
                                                    "gridcolor": "white",
                                                    "linecolor": "white",
                                                    "minorgridcolor": "white",
                                                    "startlinecolor": "#2a3f5f"
                                                },
                                                "type": "carpet"
                                            }
                                        ],
                                        "choropleth": [
                                            {
                                                "colorbar": {
                                                    "outlinewidth": 0,
                                                    "ticks": ""
                                                },
                                                "type": "choropleth"
                                            }
                                        ],
                                        "contour": [
                                            {
                                                "colorbar": {
                                                    "outlinewidth": 0,
                                                    "ticks": ""
                                                },
                                                "colorscale": [
                                                    [
                                                        0,
                                                        "#0d0887"
                                                    ],
                                                    [
                                                        0.1111111111111111,
                                                        "#46039f"
                                                    ],
                                                    [
                                                        0.2222222222222222,
                                                        "#7201a8"
                                                    ],
                                                    [
                                                        0.3333333333333333,
                                                        "#9c179e"
                                                    ],
                                                    [
                                                        0.4444444444444444,
                                                        "#bd3786"
                                                    ],
                                                    [
                                                        0.5555555555555556,
                                                        "#d8576b"
                                                    ],
                                                    [
                                                        0.6666666666666666,
                                                        "#ed7953"
                                                    ],
                                                    [
                                                        0.7777777777777778,
                                                        "#fb9f3a"
                                                    ],
                                                    [
                                                        0.8888888888888888,
                                                        "#fdca26"
                                                    ],
                                                    [
                                                        1,
                                                        "#f0f921"
                                                    ]
                                                ],
                                                "type": "contour"
                                            }
                                        ],
                                        "contourcarpet": [
                                            {
                                                "colorbar": {
                                                    "outlinewidth": 0,
                                                    "ticks": ""
                                                },
                                                "type": "contourcarpet"
                                            }
                                        ],
                                        "heatmap": [
                                            {
                                                "colorbar": {
                                                    "outlinewidth": 0,
                                                    "ticks": ""
                                                },
                                                "colorscale": [
                                                    [
                                                        0,
                                                        "#0d0887"
                                                    ],
                                                    [
                                                        0.1111111111111111,
                                                        "#46039f"
                                                    ],
                                                    [
                                                        0.2222222222222222,
                                                        "#7201a8"
                                                    ],
                                                    [
                                                        0.3333333333333333,
                                                        "#9c179e"
                                                    ],
                                                    [
                                                        0.4444444444444444,
                                                        "#bd3786"
                                                    ],
                                                    [
                                                        0.5555555555555556,
                                                        "#d8576b"
                                                    ],
                                                    [
                                                        0.6666666666666666,
                                                        "#ed7953"
                                                    ],
                                                    [
                                                        0.7777777777777778,
                                                        "#fb9f3a"
                                                    ],
                                                    [
                                                        0.8888888888888888,
                                                        "#fdca26"
                                                    ],
                                                    [
                                                        1,
                                                        "#f0f921"
                                                    ]
                                                ],
                                                "type": "heatmap"
                                            }
                                        ],
                                        "heatmapgl": [
                                            {
                                                "colorbar": {
                                                    "outlinewidth": 0,
                                                    "ticks": ""
                                                },
                                                "colorscale": [
                                                    [
                                                        0,
                                                        "#0d0887"
                                                    ],
                                                    [
                                                        0.1111111111111111,
                                                        "#46039f"
                                                    ],
                                                    [
                                                        0.2222222222222222,
                                                        "#7201a8"
                                                    ],
                                                    [
                                                        0.3333333333333333,
                                                        "#9c179e"
                                                    ],
                                                    [
                                                        0.4444444444444444,
                                                        "#bd3786"
                                                    ],
                                                    [
                                                        0.5555555555555556,
                                                        "#d8576b"
                                                    ],
                                                    [
                                                        0.6666666666666666,
                                                        "#ed7953"
                                                    ],
                                                    [
                                                        0.7777777777777778,
                                                        "#fb9f3a"
                                                    ],
                                                    [
                                                        0.8888888888888888,
                                                        "#fdca26"
                                                    ],
                                                    [
                                                        1,
                                                        "#f0f921"
                                                    ]
                                                ],
                                                "type": "heatmapgl"
                                            }
                                        ],
                                        "histogram": [
                                            {
                                                "marker": {
                                                    "pattern": {
                                                        "fillmode": "overlay",
                                                        "size": 10,
                                                        "solidity": 0.2
                                                    }
                                                },
                                                "type": "histogram"
                                            }
                                        ],
                                        "histogram2d": [
                                            {
                                                "colorbar": {
                                                    "outlinewidth": 0,
                                                    "ticks": ""
                                                },
                                                "colorscale": [
                                                    [
                                                        0,
                                                        "#0d0887"
                                                    ],
                                                    [
                                                        0.1111111111111111,
                                                        "#46039f"
                                                    ],
                                                    [
                                                        0.2222222222222222,
                                                        "#7201a8"
                                                    ],
                                                    [
                                                        0.3333333333333333,
                                                        "#9c179e"
                                                    ],
                                                    [
                                                        0.4444444444444444,
                                                        "#bd3786"
                                                    ],
                                                    [
                                                        0.5555555555555556,
                                                        "#d8576b"
                                                    ],
                                                    [
                                                        0.6666666666666666,
                                                        "#ed7953"
                                                    ],
                                                    [
                                                        0.7777777777777778,
                                                        "#fb9f3a"
                                                    ],
                                                    [
                                                        0.8888888888888888,
                                                        "#fdca26"
                                                    ],
                                                    [
                                                        1,
                                                        "#f0f921"
                                                    ]
                                                ],
                                                "type": "histogram2d"
                                            }
                                        ],
                                        "histogram2dcontour": [
                                            {
                                                "colorbar": {
                                                    "outlinewidth": 0,
                                                    "ticks": ""
                                                },
                                                "colorscale": [
                                                    [
                                                        0,
                                                        "#0d0887"
                                                    ],
                                                    [
                                                        0.1111111111111111,
                                                        "#46039f"
                                                    ],
                                                    [
                                                        0.2222222222222222,
                                                        "#7201a8"
                                                    ],
                                                    [
                                                        0.3333333333333333,
                                                        "#9c179e"
                                                    ],
                                                    [
                                                        0.4444444444444444,
                                                        "#bd3786"
                                                    ],
                                                    [
                                                        0.5555555555555556,
                                                        "#d8576b"
                                                    ],
                                                    [
                                                        0.6666666666666666,
                                                        "#ed7953"
                                                    ],
                                                    [
                                                        0.7777777777777778,
                                                        "#fb9f3a"
                                                    ],
                                                    [
                                                        0.8888888888888888,
                                                        "#fdca26"
                                                    ],
                                                    [
                                                        1,
                                                        "#f0f921"
                                                    ]
                                                ],
                                                "type": "histogram2dcontour"
                                            }
                                        ],
                                        "mesh3d": [
                                            {
                                                "colorbar": {
                                                    "outlinewidth": 0,
                                                    "ticks": ""
                                                },
                                                "type": "mesh3d"
                                            }
                                        ],
                                        "parcoords": [
                                            {
                                                "line": {
                                                    "colorbar": {
                                                        "outlinewidth": 0,
                                                        "ticks": ""
                                                    }
                                                },
                                                "type": "parcoords"
                                            }
                                        ],
                                        "pie": [
                                            {
                                                "automargin": true,
                                                "type": "pie"
                                            }
                                        ],
                                        "scatter": [
                                            {
                                                "fillpattern": {
                                                    "fillmode": "overlay",
                                                    "size": 10,
                                                    "solidity": 0.2
                                                },
                                                "type": "scatter"
                                            }
                                        ],
                                        "scatter3d": [
                                            {
                                                "line": {
                                                    "colorbar": {
                                                        "outlinewidth": 0,
                                                        "ticks": ""
                                                    }
                                                },
                                                "marker": {
                                                    "colorbar": {
                                                        "outlinewidth": 0,
                                                        "ticks": ""
                                                    }
                                                },
                                                "type": "scatter3d"
                                            }
                                        ],
                                        "scattercarpet": [
                                            {
                                                "marker": {
                                                    "colorbar": {
                                                        "outlinewidth": 0,
                                                        "ticks": ""
                                                    }
                                                },
                                                "type": "scattercarpet"
                                            }
                                        ],
                                        "scattergeo": [
                                            {
                                                "marker": {
                                                    "colorbar": {
                                                        "outlinewidth": 0,
                                                        "ticks": ""
                                                    }
                                                },
                                                "type": "scattergeo"
                                            }
                                        ],
                                        "scattergl": [
                                            {
                                                "marker": {
                                                    "colorbar": {
                                                        "outlinewidth": 0,
                                                        "ticks": ""
                                                    }
                                                },
                                                "type": "scattergl"
                                            }
                                        ],
                                        "scattermapbox": [
                                            {
                                                "marker": {
                                                    "colorbar": {
                                                        "outlinewidth": 0,
                                                        "ticks": ""
                                                    }
                                                },
                                                "type": "scattermapbox"
                                            }
                                        ],
                                        "scatterpolar": [
                                            {
                                                "marker": {
                                                    "colorbar": {
                                                        "outlinewidth": 0,
                                                        "ticks": ""
                                                    }
                                                },
                                                "type": "scatterpolar"
                                            }
                                        ],
                                        "scatterpolargl": [
                                            {
                                                "marker": {
                                                    "colorbar": {
                                                        "outlinewidth": 0,
                                                        "ticks": ""
                                                    }
                                                },
                                                "type": "scatterpolargl"
                                            }
                                        ],
                                        "scatterternary": [
                                            {
                                                "marker": {
                                                    "colorbar": {
                                                        "outlinewidth": 0,
                                                        "ticks": ""
                                                    }
                                                },
                                                "type": "scatterternary"
                                            }
                                        ],
                                        "surface": [
                                            {
                                                "colorbar": {
                                                    "outlinewidth": 0,
                                                    "ticks": ""
                                                },
                                                "colorscale": [
                                                    [
                                                        0,
                                                        "#0d0887"
                                                    ],
                                                    [
                                                        0.1111111111111111,
                                                        "#46039f"
                                                    ],
                                                    [
                                                        0.2222222222222222,
                                                        "#7201a8"
                                                    ],
                                                    [
                                                        0.3333333333333333,
                                                        "#9c179e"
                                                    ],
                                                    [
                                                        0.4444444444444444,
                                                        "#bd3786"
                                                    ],
                                                    [
                                                        0.5555555555555556,
                                                        "#d8576b"
                                                    ],
                                                    [
                                                        0.6666666666666666,
                                                        "#ed7953"
                                                    ],
                                                    [
                                                        0.7777777777777778,
                                                        "#fb9f3a"
                                                    ],
                                                    [
                                                        0.8888888888888888,
                                                        "#fdca26"
                                                    ],
                                                    [
                                                        1,
                                                        "#f0f921"
                                                    ]
                                                ],
                                                "type": "surface"
                                            }
                                        ],
                                        "table": [
                                            {
                                                "cells": {
                                                    "fill": {
                                                        "color": "#EBF0F8"
                                                    },
                                                    "line": {
                                                        "color": "white"
                                                    }
                                                },
                                                "header": {
                                                    "fill": {
                                                        "color": "#C8D4E3"
                                                    },
                                                    "line": {
                                                        "color": "white"
                                                    }
                                                },
                                                "type": "table"
                                            }
                                        ]
                                    },
                                    "layout": {
                                        "annotationdefaults": {
                                            "arrowcolor": "#2a3f5f",
                                            "arrowhead": 0,
                                            "arrowwidth": 1
                                        },
                                        "autotypenumbers": "strict",
                                        "coloraxis": {
                                            "colorbar": {
                                                "outlinewidth": 0,
                                                "ticks": ""
                                            }
                                        },
                                        "colorscale": {
                                            "diverging": [
                                                [
                                                    0,
                                                    "#8e0152"
                                                ],
                                                [
                                                    0.1,
                                                    "#c51b7d"
                                                ],
                                                [
                                                    0.2,
                                                    "#de77ae"
                                                ],
                                                [
                                                    0.3,
                                                    "#f1b6da"
                                                ],
                                                [
                                                    0.4,
                                                    "#fde0ef"
                                                ],
                                                [
                                                    0.5,
                                                    "#f7f7f7"
                                                ],
                                                [
                                                    0.6,
                                                    "#e6f5d0"
                                                ],
                                                [
                                                    0.7,
                                                    "#b8e186"
                                                ],
                                                [
                                                    0.8,
                                                    "#7fbc41"
                                                ],
                                                [
                                                    0.9,
                                                    "#4d9221"
                                                ],
                                                [
                                                    1,
                                                    "#276419"
                                                ]
                                            ],
                                            "sequential": [
                                                [
                                                    0,
                                                    "#0d0887"
                                                ],
                                                [
                                                    0.1111111111111111,
                                                    "#46039f"
                                                ],
                                                [
                                                    0.2222222222222222,
                                                    "#7201a8"
                                                ],
                                                [
                                                    0.3333333333333333,
                                                    "#9c179e"
                                                ],
                                                [
                                                    0.4444444444444444,
                                                    "#bd3786"
                                                ],
                                                [
                                                    0.5555555555555556,
                                                    "#d8576b"
                                                ],
                                                [
                                                    0.6666666666666666,
                                                    "#ed7953"
                                                ],
                                                [
                                                    0.7777777777777778,
                                                    "#fb9f3a"
                                                ],
                                                [
                                                    0.8888888888888888,
                                                    "#fdca26"
                                                ],
                                                [
                                                    1,
                                                    "#f0f921"
                                                ]
                                            ],
                                            "sequentialminus": [
                                                [
                                                    0,
                                                    "#0d0887"
                                                ],
                                                [
                                                    0.1111111111111111,
                                                    "#46039f"
                                                ],
                                                [
                                                    0.2222222222222222,
                                                    "#7201a8"
                                                ],
                                                [
                                                    0.3333333333333333,
                                                    "#9c179e"
                                                ],
                                                [
                                                    0.4444444444444444,
                                                    "#bd3786"
                                                ],
                                                [
                                                    0.5555555555555556,
                                                    "#d8576b"
                                                ],
                                                [
                                                    0.6666666666666666,
                                                    "#ed7953"
                                                ],
                                                [
                                                    0.7777777777777778,
                                                    "#fb9f3a"
                                                ],
                                                [
                                                    0.8888888888888888,
                                                    "#fdca26"
                                                ],
                                                [
                                                    1,
                                                    "#f0f921"
                                                ]
                                            ]
                                        },
                                        "colorway": [
                                            "#636efa",
                                            "#EF553B",
                                            "#00cc96",
                                            "#ab63fa",
                                            "#FFA15A",
                                            "#19d3f3",
                                            "#FF6692",
                                            "#B6E880",
                                            "#FF97FF",
                                            "#FECB52"
                                        ],
                                        "font": {
                                            "color": "#2a3f5f"
                                        },
                                        "geo": {
                                            "bgcolor": "white",
                                            "lakecolor": "white",
                                            "landcolor": "#E5ECF6",
                                            "showlakes": true,
                                            "showland": true,
                                            "subunitcolor": "white"
                                        },
                                        "hoverlabel": {
                                            "align": "left"
                                        },
                                        "hovermode": "closest",
                                        "mapbox": {
                                            "style": "light"
                                        },
                                        "paper_bgcolor": "white",
                                        "plot_bgcolor": "#E5ECF6",
                                        "polar": {
                                            "angularaxis": {
                                                "gridcolor": "white",
                                                "linecolor": "white",
                                                "ticks": ""
                                            },
                                            "bgcolor": "#E5ECF6",
                                            "radialaxis": {
                                                "gridcolor": "white",
                                                "linecolor": "white",
                                                "ticks": ""
                                            }
                                        },
                                        "scene": {
                                            "xaxis": {
                                                "backgroundcolor": "#E5ECF6",
                                                "gridcolor": "white",
                                                "gridwidth": 2,
                                                "linecolor": "white",
                                                "showbackground": true,
                                                "ticks": "",
                                                "zerolinecolor": "white"
                                            },
                                            "yaxis": {
                                                "backgroundcolor": "#E5ECF6",
                                                "gridcolor": "white",
                                                "gridwidth": 2,
                                                "linecolor": "white",
                                                "showbackground": true,
                                                "ticks": "",
                                                "zerolinecolor": "white"
                                            },
                                            "zaxis": {
                                                "backgroundcolor": "#E5ECF6",
                                                "gridcolor": "white",
                                                "gridwidth": 2,
                                                "linecolor": "white",
                                                "showbackground": true,
                                                "ticks": "",
                                                "zerolinecolor": "white"
                                            }
                                        },
                                        "shapedefaults": {
                                            "line": {
                                                "color": "#2a3f5f"
                                            }
                                        },
                                        "ternary": {
                                            "aaxis": {
                                                "gridcolor": "white",
                                                "linecolor": "white",
                                                "ticks": ""
                                            },
                                            "baxis": {
                                                "gridcolor": "white",
                                                "linecolor": "white",
                                                "ticks": ""
                                            },
                                            "bgcolor": "#E5ECF6",
                                            "caxis": {
                                                "gridcolor": "white",
                                                "linecolor": "white",
                                                "ticks": ""
                                            }
                                        },
                                        "title": {
                                            "x": 0.05
                                        },
                                        "xaxis": {
                                            "automargin": true,
                                            "gridcolor": "white",
                                            "linecolor": "white",
                                            "ticks": "",
                                            "title": {
                                                "standoff": 15
                                            },
                                            "zerolinecolor": "white",
                                            "zerolinewidth": 2
                                        },
                                        "yaxis": {
                                            "automargin": true,
                                            "gridcolor": "white",
                                            "linecolor": "white",
                                            "ticks": "",
                                            "title": {
                                                "standoff": 15
                                            },
                                            "zerolinecolor": "white",
                                            "zerolinewidth": 2
                                        }
                                    }
                                },
                                "title": {
                                    "text": "Histogram of periods"
                                }
                            }
                        }
                    },
                    "metadata": {},
                    "output_type": "display_data"
                }
            ],
            "source": [
                "# Histogram of periods using plotly\n",
                "import plotly.graph_objects as go\n",
                "\n",
                "fig = go.Figure()\n",
                "fig.add_trace(go.Histogram(x=y_data.flatten(), histnorm=\"probability\"))\n",
                "fig.update_layout(title_text=\"Histogram of periods\")\n",
                "\n",
                "fig.show()\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 6,
            "metadata": {},
            "outputs": [],
            "source": [
                "def get_packed_padded_data(data: list[torch.Tensor]):\n",
                "    seq_len = torch.tensor([len(x) for x in data])\n",
                "    \n",
                "    padded = pad_sequence(data, batch_first=True)\n",
                "    print(f\"Padded shape: {padded.shape}\")\n",
                "    \n",
                "    packed =  pack_padded_sequence(padded, seq_len, batch_first=True, enforce_sorted=False)\n",
                "    print(f\"Packed data shape: {packed.data.shape}\")\n",
                "\n",
                "    return packed"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 7,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Train size: 1863\n",
                        "Validation size: 559\n",
                        "Test size: 240\n"
                    ]
                }
            ],
            "source": [
                "X_train, X_tmp, y_train, y_tmp = train_test_split(X_data, y_data, test_size=0.3, random_state=42)\n",
                "X_val, X_test, y_val, y_test = train_test_split(X_tmp, y_tmp, test_size=0.3, random_state=42)\n",
                "print(f\"Train size: {len(X_train)}\")\n",
                "print(f\"Validation size: {len(X_val)}\")\n",
                "print(f\"Test size: {len(X_test)}\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 8,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/plain": [
                            "torch.Size([1863, 1])"
                        ]
                    },
                    "execution_count": 8,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "y_train.shape"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 9,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Padded shape: torch.Size([1863, 4, 50])\n",
                        "Packed data shape: torch.Size([4235, 50])\n",
                        "Padded shape: torch.Size([559, 4, 50])\n",
                        "Packed data shape: torch.Size([1276, 50])\n",
                        "Padded shape: torch.Size([240, 4, 50])\n",
                        "Packed data shape: torch.Size([530, 50])\n"
                    ]
                }
            ],
            "source": [
                "X_train = get_packed_padded_data(X_train)\n",
                "X_val = get_packed_padded_data(X_val)\n",
                "X_test = get_packed_padded_data(X_test)\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 10,
            "metadata": {},
            "outputs": [],
            "source": [
                "class ModelConfig(TypedDict):\n",
                "    input_size: int\n",
                "    hidden_size: int\n",
                "    num_layers: int\n",
                "    fc1_size: int\n",
                "    fc2_size: int\n",
                "    bidirectional: bool\n",
                "    dropout: float"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 11,
            "metadata": {},
            "outputs": [],
            "source": [
                "class AsteroidLSTM(nn.Module):\n",
                "    def __init__(self, config: ModelConfig):\n",
                "        super(AsteroidLSTM, self).__init__()\n",
                "        self.hidden_size = config[\"hidden_size\"]\n",
                "        self.num_layers = config[\"num_layers\"]\n",
                "        self.bidirectional = config[\"bidirectional\"]\n",
                "        self.lstm = nn.LSTM(\n",
                "            config[\"input_size\"],\n",
                "            config[\"hidden_size\"],\n",
                "            config[\"num_layers\"],\n",
                "            batch_first=True,\n",
                "            bidirectional=config[\"bidirectional\"],\n",
                "            dropout=config[\"dropout\"],\n",
                "        )\n",
                "\n",
                "        fc_input_size = config[\"hidden_size\"] * 2 if config[\"bidirectional\"] else config[\"hidden_size\"]\n",
                "        self.fc1 = nn.Linear(fc_input_size, config[\"fc1_size\"])\n",
                "        self.fc2 = nn.Linear(config[\"fc1_size\"], config[\"fc2_size\"])\n",
                "        self.fc3 = nn.Linear(config[\"fc2_size\"], 1)\n",
                "        self.relu = nn.ReLU()\n",
                "        self.dropout = nn.Dropout(config[\"dropout\"])\n",
                "\n",
                "    def forward(self, x: torch.Tensor):\n",
                "        # Process the packed sequence through the LSTM\n",
                "        output, _ = self.lstm(x)\n",
                "\n",
                "        # Unpack the sequence\n",
                "        output, lengths = pad_packed_sequence(output, batch_first=True)\n",
                "\n",
                "        # Get the last output for each sequence\n",
                "        batch_size = output.size(0)\n",
                "        last_output = output[torch.arange(batch_size), lengths - 1]\n",
                "\n",
                "        # If bidirectional, concatenate forward and backward last outputs\n",
                "        if self.bidirectional:\n",
                "            last_output = torch.cat((last_output[:, : self.hidden_size], last_output[:, self.hidden_size :]), dim=1)\n",
                "\n",
                "        x = self.relu(self.fc1(last_output))\n",
                "        x = self.dropout(x)\n",
                "        x = self.relu(self.fc2(x))\n",
                "        x = self.dropout(x)\n",
                "        x = self.fc3(x)\n",
                "        return x"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 12,
            "metadata": {},
            "outputs": [],
            "source": [
                "class PackedSequenceDataset(Dataset):\n",
                "    def __init__(self, packed_sequence, targets):\n",
                "        self.data = packed_sequence\n",
                "        self.targets = targets\n",
                "\n",
                "    def __len__(self):\n",
                "        return len(self.targets)\n",
                "\n",
                "    def __getitem__(self, idx):\n",
                "        return idx, self.targets[idx]\n",
                "\n",
                "\n",
                "def custom_collate_fn(batch):\n",
                "    indices, targets = zip(*batch)\n",
                "    return torch.LongTensor(indices), torch.tensor(targets).float()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 13,
            "metadata": {},
            "outputs": [],
            "source": [
                "def train_model(\n",
                "    model,\n",
                "    X_train,\n",
                "    y_train,\n",
                "    X_val,\n",
                "    y_val,\n",
                "    batch_size,\n",
                "    num_epochs,\n",
                "    learning_rate,\n",
                "    model_suffix: str | None = None,\n",
                "    patience=100,\n",
                "):\n",
                "    if model_suffix is not None:\n",
                "        print(f\"Training model with suffix: {model_suffix}\")\n",
                "\n",
                "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
                "    model.to(device)\n",
                "\n",
                "    criterion = nn.MSELoss()\n",
                "    optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
                "\n",
                "    # Create DataLoaders\n",
                "    train_dataset = PackedSequenceDataset(X_train, y_train)\n",
                "    val_dataset = PackedSequenceDataset(X_val, y_val)\n",
                "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, collate_fn=custom_collate_fn)\n",
                "    val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False, collate_fn=custom_collate_fn)\n",
                "\n",
                "    best_val_loss = float(\"inf\")\n",
                "    best_model = None\n",
                "    patience_counter = 0\n",
                "\n",
                "    for epoch in range(num_epochs):\n",
                "        model.train()\n",
                "        train_loss = 0.0\n",
                "        for indices, y_batch in train_loader:\n",
                "            y_batch = y_batch.to(device)\n",
                "\n",
                "            optimizer.zero_grad()\n",
                "            # Create a new PackedSequence for this batch\n",
                "            X_batch = PackedSequence(\n",
                "                X_train.data[\n",
                "                    X_train.batch_sizes[: indices.max() + 1].sum()\n",
                "                    - X_train.batch_sizes[: indices.max() + 1].sum() : X_train.batch_sizes[: indices.max() + 1].sum()\n",
                "                ],\n",
                "                X_train.batch_sizes[: indices.max() + 1],\n",
                "                X_train.sorted_indices[indices],\n",
                "                X_train.unsorted_indices[indices],\n",
                "            )\n",
                "            X_batch = X_batch.to(device)\n",
                "\n",
                "            outputs = model(X_batch)\n",
                "            loss = criterion(outputs.squeeze(), y_batch)\n",
                "            loss.backward()\n",
                "            optimizer.step()\n",
                "\n",
                "            train_loss += loss.item() * y_batch.size(0)\n",
                "\n",
                "        train_loss /= len(train_loader.dataset)\n",
                "\n",
                "        # Validation\n",
                "        model.eval()\n",
                "        val_loss = 0.0\n",
                "        with torch.no_grad():\n",
                "            for indices, y_batch in val_loader:\n",
                "                y_batch = y_batch.to(device)\n",
                "                # Create a new PackedSequence for this batch\n",
                "                X_batch = PackedSequence(\n",
                "                    X_val.data[\n",
                "                        X_val.batch_sizes[: indices.max() + 1].sum()\n",
                "                        - X_val.batch_sizes[: indices.max() + 1].sum() : X_val.batch_sizes[: indices.max() + 1].sum()\n",
                "                    ],\n",
                "                    X_val.batch_sizes[: indices.max() + 1],\n",
                "                    X_val.sorted_indices[indices],\n",
                "                    X_val.unsorted_indices[indices],\n",
                "                )\n",
                "                X_batch = X_batch.to(device)\n",
                "\n",
                "                outputs = model(X_batch)\n",
                "                loss = criterion(outputs.squeeze(), y_batch)\n",
                "                val_loss += loss.item() * y_batch.size(0)\n",
                "\n",
                "        val_loss /= len(val_loader.dataset)\n",
                "\n",
                "        if model_suffix is not None:\n",
                "            print(f\"\\rEpoch {epoch+1}/{num_epochs}, Train Loss: {train_loss:.4f}, Val Loss: {val_loss:.4f}\", end=\"\")\n",
                "\n",
                "        # Check if this is the best model\n",
                "        if val_loss < best_val_loss:\n",
                "            best_val_loss = val_loss\n",
                "            best_model = copy.deepcopy(model)\n",
                "            patience_counter = 0\n",
                "\n",
                "            if model_suffix is not None:\n",
                "                torch.save(best_model.state_dict(), MODELS_DIR / f\"asteroid_lstm_{model_suffix}.pt\")\n",
                "                print(f\"\\nNew best model saved with validation loss: {best_val_loss:.4f}\")\n",
                "        else:\n",
                "            patience_counter += 1\n",
                "\n",
                "        # Early stopping\n",
                "        if patience_counter >= patience:\n",
                "            print(f\"Early stopping triggered after {epoch+1} epochs\")\n",
                "            break\n",
                "\n",
                "    return best_model"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 50,
            "metadata": {},
            "outputs": [],
            "source": [
                "def evaluate_model(model, X_test, y_test, batch_size):\n",
                "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
                "    model.to(device)\n",
                "\n",
                "    test_dataset = PackedSequenceDataset(X_test, y_test)\n",
                "    test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False, collate_fn=custom_collate_fn)\n",
                "\n",
                "    model.eval()\n",
                "    all_outputs = []\n",
                "    all_targets = []\n",
                "\n",
                "    with torch.no_grad():\n",
                "        for indices, y_batch in test_loader:\n",
                "            y_batch = y_batch.to(device)\n",
                "\n",
                "            # Create a new PackedSequence for this batch\n",
                "            X_batch = PackedSequence(\n",
                "                X_test.data[\n",
                "                    X_test.batch_sizes[: indices.max() + 1].sum()\n",
                "                    - X_test.batch_sizes[: indices.max() + 1].sum() : X_test.batch_sizes[: indices.max() + 1].sum()\n",
                "                ],\n",
                "                X_test.batch_sizes[: indices.max() + 1],\n",
                "                X_test.sorted_indices[indices],\n",
                "                X_test.unsorted_indices[indices],\n",
                "            )\n",
                "            X_batch = X_batch.to(device)\n",
                "\n",
                "            outputs = model(X_batch)\n",
                "\n",
                "            all_outputs.extend(outputs.cpu().numpy().squeeze())\n",
                "            all_targets.extend(y_batch.cpu().numpy())\n",
                "\n",
                "    all_outputs = np.array(all_outputs)\n",
                "    all_targets = np.array(all_targets)\n",
                "\n",
                "    # Calculate metrics\n",
                "    mse = mean_squared_error(all_targets, all_outputs)\n",
                "    rmse = np.sqrt(mse)\n",
                "    mae = mean_absolute_error(all_targets, all_outputs)\n",
                "    r2 = r2_score(all_targets, all_outputs)\n",
                "\n",
                "    print(f\"Test MSE: {mse:.4f}\")\n",
                "    print(f\"Test RMSE: {rmse:.4f}\")\n",
                "    print(f\"Test MAE: {mae:.4f}\")\n",
                "    print(f\"Test R2 Score: {r2:.4f}\")\n",
                "\n",
                "    return mse, rmse, mae, r2, all_outputs, all_targets"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 51,
            "metadata": {},
            "outputs": [],
            "source": [
                "config = ModelConfig(\n",
                "    input_size=X_train.data.size(-1),\n",
                "    hidden_size=64,\n",
                "    num_layers=2,\n",
                "    fc1_size=64,\n",
                "    fc2_size=32,\n",
                "    bidirectional=False,\n",
                "    dropout=0.1,\n",
                ")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 52,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/plain": [
                            "AsteroidLSTM(\n",
                            "  (lstm): LSTM(50, 64, num_layers=2, batch_first=True, dropout=0.1)\n",
                            "  (fc1): Linear(in_features=64, out_features=64, bias=True)\n",
                            "  (fc2): Linear(in_features=64, out_features=32, bias=True)\n",
                            "  (fc3): Linear(in_features=32, out_features=1, bias=True)\n",
                            "  (relu): ReLU()\n",
                            "  (dropout): Dropout(p=0.1, inplace=False)\n",
                            ")"
                        ]
                    },
                    "execution_count": 52,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "model = AsteroidLSTM(config).cuda()\n",
                "model"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 53,
            "metadata": {},
            "outputs": [],
            "source": [
                "batch_size = 16\n",
                "num_epochs = 1000\n",
                "learning_rate = 0.001"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 54,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Training model with suffix: 20240824_222238\n",
                        "Epoch 1/1000, Train Loss: 92.0420, Val Loss: 51.0980\n",
                        "New best model saved with validation loss: 51.0980\n",
                        "Epoch 2/1000, Train Loss: 52.4723, Val Loss: 50.4042\n",
                        "New best model saved with validation loss: 50.4042\n",
                        "Epoch 3/1000, Train Loss: 52.1494, Val Loss: 50.1605\n",
                        "New best model saved with validation loss: 50.1605\n",
                        "Epoch 6/1000, Train Loss: 50.7528, Val Loss: 49.1443\n",
                        "New best model saved with validation loss: 49.1443\n",
                        "Epoch 7/1000, Train Loss: 51.1704, Val Loss: 48.7787\n",
                        "New best model saved with validation loss: 48.7787\n",
                        "Epoch 8/1000, Train Loss: 50.2029, Val Loss: 48.6727\n",
                        "New best model saved with validation loss: 48.6727\n",
                        "Epoch 9/1000, Train Loss: 49.5482, Val Loss: 48.2426\n",
                        "New best model saved with validation loss: 48.2426\n",
                        "Epoch 11/1000, Train Loss: 49.3673, Val Loss: 48.2391\n",
                        "New best model saved with validation loss: 48.2391\n",
                        "Epoch 12/1000, Train Loss: 50.1587, Val Loss: 48.1131\n",
                        "New best model saved with validation loss: 48.1131\n",
                        "Epoch 13/1000, Train Loss: 49.1334, Val Loss: 47.9333\n",
                        "New best model saved with validation loss: 47.9333\n",
                        "Epoch 15/1000, Train Loss: 48.6041, Val Loss: 47.7469\n",
                        "New best model saved with validation loss: 47.7469\n",
                        "Epoch 16/1000, Train Loss: 48.6152, Val Loss: 47.7133\n",
                        "New best model saved with validation loss: 47.7133\n",
                        "Epoch 18/1000, Train Loss: 47.9358, Val Loss: 47.0989\n",
                        "New best model saved with validation loss: 47.0989\n",
                        "Epoch 19/1000, Train Loss: 46.2346, Val Loss: 46.6090\n",
                        "New best model saved with validation loss: 46.6090\n",
                        "Epoch 22/1000, Train Loss: 44.1024, Val Loss: 45.6288\n",
                        "New best model saved with validation loss: 45.6288\n",
                        "Epoch 105/1000, Train Loss: 8.6323, Val Loss: 58.3391"
                    ]
                },
                {
                    "ename": "KeyboardInterrupt",
                    "evalue": "",
                    "output_type": "error",
                    "traceback": [
                        "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
                        "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
                        "Cell \u001b[0;32mIn[54], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m train_start \u001b[38;5;241m=\u001b[39m datetime\u001b[38;5;241m.\u001b[39mnow()\u001b[38;5;241m.\u001b[39mstrftime(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mY\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mm\u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m_\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mH\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mM\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mS\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m----> 2\u001b[0m best_model \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_model\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m    \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX_val\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[43m    \u001b[49m\u001b[43my_val\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      9\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnum_epochs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     10\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlearning_rate\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     11\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel_suffix\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain_start\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     12\u001b[0m \u001b[43m)\u001b[49m\n",
                        "Cell \u001b[0;32mIn[49], line 49\u001b[0m, in \u001b[0;36mtrain_model\u001b[0;34m(model, X_train, y_train, X_val, y_val, batch_size, num_epochs, learning_rate, model_suffix, patience)\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[38;5;66;03m# Create a new PackedSequence for this batch\u001b[39;00m\n\u001b[1;32m     40\u001b[0m X_batch \u001b[38;5;241m=\u001b[39m PackedSequence(\n\u001b[1;32m     41\u001b[0m     X_train\u001b[38;5;241m.\u001b[39mdata[\n\u001b[1;32m     42\u001b[0m         X_train\u001b[38;5;241m.\u001b[39mbatch_sizes[: indices\u001b[38;5;241m.\u001b[39mmax() \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m]\u001b[38;5;241m.\u001b[39msum()\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     47\u001b[0m     X_train\u001b[38;5;241m.\u001b[39munsorted_indices[indices],\n\u001b[1;32m     48\u001b[0m )\n\u001b[0;32m---> 49\u001b[0m X_batch \u001b[38;5;241m=\u001b[39m \u001b[43mX_batch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     51\u001b[0m outputs \u001b[38;5;241m=\u001b[39m model(X_batch)\n\u001b[1;32m     52\u001b[0m loss \u001b[38;5;241m=\u001b[39m criterion(outputs\u001b[38;5;241m.\u001b[39msqueeze(), y_batch)\n",
                        "File \u001b[0;32m~/miniforge3/envs/mgr/lib/python3.11/site-packages/torch/nn/utils/rnn.py:134\u001b[0m, in \u001b[0;36mPackedSequence.to\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    120\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"Perform dtype and/or device conversion on `self.data`.\u001b[39;00m\n\u001b[1;32m    121\u001b[0m \n\u001b[1;32m    122\u001b[0m \u001b[38;5;124;03mIt has similar signature as :meth:`torch.Tensor.to`, except optional\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    130\u001b[0m \u001b[38;5;124;03m    Otherwise, returns a copy with the desired configuration.\u001b[39;00m\n\u001b[1;32m    131\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    132\u001b[0m \u001b[38;5;66;03m# Why not convert `batch_sizes`?\u001b[39;00m\n\u001b[1;32m    133\u001b[0m \u001b[38;5;66;03m# See NOTE [ device and dtype of a PackedSequence ]\u001b[39;00m\n\u001b[0;32m--> 134\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    135\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m data \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata:\n\u001b[1;32m    136\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
                        "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
                    ]
                }
            ],
            "source": [
                "train_start = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
                "best_model = train_model(\n",
                "    model,\n",
                "    X_train,\n",
                "    y_train,\n",
                "    X_val,\n",
                "    y_val,\n",
                "    batch_size,\n",
                "    num_epochs,\n",
                "    learning_rate,\n",
                "    model_suffix=train_start,\n",
                ")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 55,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Test MSE: 64.1712\n",
                        "Test RMSE: 8.0107\n",
                        "Test MAE: 5.5498\n",
                        "Test R2 Score: -0.0144\n"
                    ]
                }
            ],
            "source": [
                "model.load_state_dict(torch.load(MODELS_DIR / f\"asteroid_lstm_{train_start}.pt\"))\n",
                "model.eval()\n",
                "\n",
                "mse, rmse, mae, r2, predictions, true_values = evaluate_model(model, X_test, y_test, batch_size)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 56,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "True:  17.5418, Predicted:  10.6509\n",
                        "True:  13.8256, Predicted:  16.6600\n",
                        "True:  16.2058, Predicted:   8.2566\n",
                        "True:  20.6520, Predicted:  10.3694\n",
                        "True:   4.6544, Predicted:   8.8766\n",
                        "True:   5.5296, Predicted:   9.1660\n",
                        "True:   6.0483, Predicted:  17.1141\n",
                        "True:   8.8422, Predicted:   9.8479\n",
                        "True:   9.7250, Predicted:  10.1459\n",
                        "True:   3.8382, Predicted:   9.8626\n",
                        "True:  13.4842, Predicted:   7.9328\n",
                        "True:   7.6203, Predicted:   8.9874\n",
                        "True:   3.2556, Predicted:   7.9838\n",
                        "True:  12.7301, Predicted:   8.2046\n",
                        "True:  15.1533, Predicted:   9.3400\n",
                        "True:  18.1482, Predicted:  17.1302\n",
                        "True:   4.0120, Predicted:   8.0972\n",
                        "True:   3.5740, Predicted:  10.4504\n",
                        "True:  16.4461, Predicted:  13.9109\n",
                        "True:  19.9941, Predicted:  10.0037\n",
                        "True:  14.7956, Predicted:  16.7504\n",
                        "True:   3.7788, Predicted:   9.6778\n",
                        "True:  11.4065, Predicted:  11.0462\n",
                        "True:  39.0847, Predicted:   9.0827\n",
                        "True:   6.4109, Predicted:  16.4830\n",
                        "True:   3.5646, Predicted:  10.7740\n",
                        "True:   5.8869, Predicted:   7.9869\n",
                        "True:  12.1657, Predicted:   9.9646\n",
                        "True:  32.8430, Predicted:  11.6356\n",
                        "True:   8.0173, Predicted:   8.1878\n"
                    ]
                }
            ],
            "source": [
                "for i in range(30):\n",
                "    print(f\"True: {true_values[i]:8.4f}, Predicted: {predictions[i]:8.4f}\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 57,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "image/png": "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",
                        "text/plain": [
                            "<Figure size 1000x600 with 1 Axes>"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                }
            ],
            "source": [
                "plt.figure(figsize=(10, 6))\n",
                "plt.scatter(true_values, predictions, alpha=0.5)\n",
                "plt.plot([true_values.min(), true_values.max()], [true_values.min(), true_values.max()], 'r--', lw=2)\n",
                "plt.xlabel('True Values')\n",
                "plt.ylabel('Predictions')\n",
                "plt.title('True Values vs Predictions')\n",
                "plt.tight_layout()\n",
                "plt.show()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 58,
            "metadata": {},
            "outputs": [
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "/home/marek/miniforge3/envs/mgr/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
                        "  from .autonotebook import tqdm as notebook_tqdm\n"
                    ]
                }
            ],
            "source": [
                "import optuna\n",
                "from optuna.trial import TrialState"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 59,
            "metadata": {},
            "outputs": [],
            "source": [
                "def objective(trial):\n",
                "    # Define the hyperparameters to tune\n",
                "    config = ModelConfig(\n",
                "        input_size=50,  # Assuming this is fixed\n",
                "        hidden_size=trial.suggest_int('hidden_size', 32, 256),\n",
                "        num_layers=trial.suggest_int('num_layers', 1, 3),\n",
                "        fc1_size=trial.suggest_int('fc1_size', 32, 256),\n",
                "        fc2_size=trial.suggest_int('fc2_size', 16, 128),\n",
                "        bidirectional=trial.suggest_categorical('bidirectional', [True, False]),\n",
                "        dropout=trial.suggest_float('dropout', 0.1, 0.5)\n",
                "    )\n",
                "    \n",
                "    learning_rate = trial.suggest_float('learning_rate', 1e-5, 1e-1, log=True)\n",
                "    batch_size = trial.suggest_categorical('batch_size', [16, 32, 64, 128])\n",
                "\n",
                "    # Create model with the suggested hyperparameters\n",
                "    model = AsteroidLSTM(config)\n",
                "\n",
                "    # Train the model\n",
                "    best_model = train_model(model, X_train, y_train, X_val, y_val, batch_size, num_epochs=200, learning_rate=learning_rate)\n",
                "\n",
                "    # Evaluate the model\n",
                "    _, rmse, mae, _, _, _ = evaluate_model(best_model, X_val, y_val, batch_size)\n",
                "\n",
                "    return rmse\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 60,
            "metadata": {},
            "outputs": [
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "[I 2024-08-24 22:24:00,810] A new study created in memory with name: no-name-1a81bf31-0acd-4b52-bf0b-ebe4ab2a061e\n",
                        "/home/marek/miniforge3/envs/mgr/lib/python3.11/site-packages/torch/nn/modules/rnn.py:83: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.1822535198925436 and num_layers=1\n",
                        "  warnings.warn(\"dropout option adds dropout after all but last \"\n",
                        "[I 2024-08-24 22:25:25,421] Trial 0 finished with value: 4.942243576049805 and parameters: {'hidden_size': 186, 'num_layers': 1, 'fc1_size': 168, 'fc2_size': 64, 'bidirectional': True, 'dropout': 0.1822535198925436, 'learning_rate': 0.00048324390639883485, 'batch_size': 16}. Best is trial 0 with value: 4.942243576049805.\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Early stopping triggered after 109 epochs\n",
                        "Test MSE: 46.6503\n",
                        "Test RMSE: 6.8301\n",
                        "Test MAE: 4.9422\n",
                        "Test R2 Score: 0.0551\n"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "[I 2024-08-24 22:26:45,200] Trial 1 finished with value: 5.256509304046631 and parameters: {'hidden_size': 230, 'num_layers': 3, 'fc1_size': 253, 'fc2_size': 63, 'bidirectional': True, 'dropout': 0.1981351464570539, 'learning_rate': 0.07724841204841282, 'batch_size': 64}. Best is trial 0 with value: 4.942243576049805.\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Early stopping triggered after 103 epochs\n",
                        "Test MSE: 49.3459\n",
                        "Test RMSE: 7.0247\n",
                        "Test MAE: 5.2565\n",
                        "Test R2 Score: 0.0005\n"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "/home/marek/miniforge3/envs/mgr/lib/python3.11/site-packages/torch/nn/modules/rnn.py:83: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.40450533328532245 and num_layers=1\n",
                        "  warnings.warn(\"dropout option adds dropout after all but last \"\n",
                        "[I 2024-08-24 22:27:55,337] Trial 2 finished with value: 5.297974586486816 and parameters: {'hidden_size': 202, 'num_layers': 1, 'fc1_size': 160, 'fc2_size': 90, 'bidirectional': False, 'dropout': 0.40450533328532245, 'learning_rate': 0.07190885355708505, 'batch_size': 16}. Best is trial 0 with value: 4.942243576049805.\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Early stopping triggered after 129 epochs\n",
                        "Test MSE: 49.3707\n",
                        "Test RMSE: 7.0264\n",
                        "Test MAE: 5.2980\n",
                        "Test R2 Score: -0.0000\n"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "[I 2024-08-24 22:30:20,543] Trial 3 finished with value: 5.29923677444458 and parameters: {'hidden_size': 236, 'num_layers': 2, 'fc1_size': 128, 'fc2_size': 117, 'bidirectional': True, 'dropout': 0.49530585234634317, 'learning_rate': 0.03764470125163319, 'batch_size': 32}. Best is trial 0 with value: 4.942243576049805.\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Early stopping triggered after 143 epochs\n",
                        "Test MSE: 49.3707\n",
                        "Test RMSE: 7.0264\n",
                        "Test MAE: 5.2992\n",
                        "Test R2 Score: 0.0000\n"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "/home/marek/miniforge3/envs/mgr/lib/python3.11/site-packages/torch/nn/modules/rnn.py:83: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.10521231893082206 and num_layers=1\n",
                        "  warnings.warn(\"dropout option adds dropout after all but last \"\n",
                        "[I 2024-08-24 22:31:33,401] Trial 4 finished with value: 5.142693042755127 and parameters: {'hidden_size': 120, 'num_layers': 1, 'fc1_size': 86, 'fc2_size': 87, 'bidirectional': True, 'dropout': 0.10521231893082206, 'learning_rate': 0.015337781369983537, 'batch_size': 16}. Best is trial 0 with value: 4.942243576049805.\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Early stopping triggered after 131 epochs\n",
                        "Test MSE: 47.6706\n",
                        "Test RMSE: 6.9044\n",
                        "Test MAE: 5.1427\n",
                        "Test R2 Score: 0.0344\n"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "/home/marek/miniforge3/envs/mgr/lib/python3.11/site-packages/torch/nn/modules/rnn.py:83: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.47599928515306356 and num_layers=1\n",
                        "  warnings.warn(\"dropout option adds dropout after all but last \"\n",
                        "[I 2024-08-24 22:32:01,648] Trial 5 finished with value: 4.943375110626221 and parameters: {'hidden_size': 117, 'num_layers': 1, 'fc1_size': 103, 'fc2_size': 61, 'bidirectional': False, 'dropout': 0.47599928515306356, 'learning_rate': 0.00018309338513670953, 'batch_size': 32}. Best is trial 0 with value: 4.942243576049805.\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Early stopping triggered after 155 epochs\n",
                        "Test MSE: 46.4030\n",
                        "Test RMSE: 6.8120\n",
                        "Test MAE: 4.9434\n",
                        "Test R2 Score: 0.0601\n"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "[I 2024-08-24 22:32:22,830] Trial 6 finished with value: 4.96355676651001 and parameters: {'hidden_size': 81, 'num_layers': 2, 'fc1_size': 65, 'fc2_size': 72, 'bidirectional': False, 'dropout': 0.3016989870386404, 'learning_rate': 0.00023702171939355072, 'batch_size': 64}. Best is trial 0 with value: 4.942243576049805.\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Early stopping triggered after 192 epochs\n",
                        "Test MSE: 45.7562\n",
                        "Test RMSE: 6.7643\n",
                        "Test MAE: 4.9636\n",
                        "Test R2 Score: 0.0732\n"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "/home/marek/miniforge3/envs/mgr/lib/python3.11/site-packages/torch/nn/modules/rnn.py:83: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.23172632581439784 and num_layers=1\n",
                        "  warnings.warn(\"dropout option adds dropout after all but last \"\n",
                        "[I 2024-08-24 22:33:54,916] Trial 7 finished with value: 5.299153804779053 and parameters: {'hidden_size': 98, 'num_layers': 1, 'fc1_size': 228, 'fc2_size': 89, 'bidirectional': True, 'dropout': 0.23172632581439784, 'learning_rate': 0.05561111029508259, 'batch_size': 16}. Best is trial 0 with value: 4.942243576049805.\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Early stopping triggered after 187 epochs\n",
                        "Test MSE: 49.3707\n",
                        "Test RMSE: 7.0264\n",
                        "Test MAE: 5.2992\n",
                        "Test R2 Score: 0.0000\n"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "[I 2024-08-24 22:35:03,923] Trial 8 finished with value: 5.299142360687256 and parameters: {'hidden_size': 165, 'num_layers': 2, 'fc1_size': 77, 'fc2_size': 120, 'bidirectional': True, 'dropout': 0.2932458103258573, 'learning_rate': 0.07608270703351003, 'batch_size': 64}. Best is trial 0 with value: 4.942243576049805.\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Test MSE: 49.3707\n",
                        "Test RMSE: 7.0264\n",
                        "Test MAE: 5.2991\n",
                        "Test R2 Score: 0.0000\n"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "[I 2024-08-24 22:36:04,956] Trial 9 finished with value: 4.887510299682617 and parameters: {'hidden_size': 129, 'num_layers': 2, 'fc1_size': 137, 'fc2_size': 59, 'bidirectional': True, 'dropout': 0.20641148472074164, 'learning_rate': 0.00030441175568820985, 'batch_size': 32}. Best is trial 9 with value: 4.887510299682617.\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Early stopping triggered after 116 epochs\n",
                        "Test MSE: 46.7223\n",
                        "Test RMSE: 6.8354\n",
                        "Test MAE: 4.8875\n",
                        "Test R2 Score: 0.0536\n"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "[I 2024-08-24 22:36:18,934] Trial 10 finished with value: 5.542545795440674 and parameters: {'hidden_size': 34, 'num_layers': 3, 'fc1_size': 194, 'fc2_size': 26, 'bidirectional': False, 'dropout': 0.10896397680901149, 'learning_rate': 1.0452534305388571e-05, 'batch_size': 128}. Best is trial 9 with value: 4.887510299682617.\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Test MSE: 61.3690\n",
                        "Test RMSE: 7.8338\n",
                        "Test MAE: 5.5425\n",
                        "Test R2 Score: -0.2430\n"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "[I 2024-08-24 22:37:30,756] Trial 11 finished with value: 5.051861763000488 and parameters: {'hidden_size': 166, 'num_layers': 2, 'fc1_size': 164, 'fc2_size': 39, 'bidirectional': True, 'dropout': 0.18778860284647997, 'learning_rate': 0.0015396219080465014, 'batch_size': 32}. Best is trial 9 with value: 4.887510299682617.\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Early stopping triggered after 106 epochs\n",
                        "Test MSE: 46.5860\n",
                        "Test RMSE: 6.8254\n",
                        "Test MAE: 5.0519\n",
                        "Test R2 Score: 0.0564\n"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "[I 2024-08-24 22:38:06,054] Trial 12 finished with value: 5.014342784881592 and parameters: {'hidden_size': 190, 'num_layers': 3, 'fc1_size': 195, 'fc2_size': 44, 'bidirectional': True, 'dropout': 0.2720619507601304, 'learning_rate': 0.0011348225884693446, 'batch_size': 128}. Best is trial 9 with value: 4.887510299682617.\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Early stopping triggered after 124 epochs\n",
                        "Test MSE: 46.5144\n",
                        "Test RMSE: 6.8201\n",
                        "Test MAE: 5.0143\n",
                        "Test R2 Score: 0.0579\n"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "/home/marek/miniforge3/envs/mgr/lib/python3.11/site-packages/torch/nn/modules/rnn.py:83: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.17920065319216416 and num_layers=1\n",
                        "  warnings.warn(\"dropout option adds dropout after all but last \"\n",
                        "[I 2024-08-24 22:39:24,672] Trial 13 finished with value: 4.996846675872803 and parameters: {'hidden_size': 146, 'num_layers': 1, 'fc1_size': 32, 'fc2_size': 48, 'bidirectional': True, 'dropout': 0.17920065319216416, 'learning_rate': 0.00015074061751877246, 'batch_size': 16}. Best is trial 9 with value: 4.887510299682617.\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Early stopping triggered after 127 epochs\n",
                        "Test MSE: 46.9222\n",
                        "Test RMSE: 6.8500\n",
                        "Test MAE: 4.9968\n",
                        "Test R2 Score: 0.0496\n"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "[I 2024-08-24 22:39:58,192] Trial 14 finished with value: 4.848199367523193 and parameters: {'hidden_size': 62, 'num_layers': 2, 'fc1_size': 127, 'fc2_size': 19, 'bidirectional': True, 'dropout': 0.3707801524890563, 'learning_rate': 0.004831629250028658, 'batch_size': 32}. Best is trial 14 with value: 4.848199367523193.\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Early stopping triggered after 118 epochs\n",
                        "Test MSE: 46.4885\n",
                        "Test RMSE: 6.8182\n",
                        "Test MAE: 4.8482\n",
                        "Test R2 Score: 0.0584\n"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "[I 2024-08-24 22:40:29,366] Trial 15 finished with value: 5.00185489654541 and parameters: {'hidden_size': 48, 'num_layers': 2, 'fc1_size': 127, 'fc2_size': 23, 'bidirectional': True, 'dropout': 0.37009719483688996, 'learning_rate': 0.005685180635147564, 'batch_size': 32}. Best is trial 14 with value: 4.848199367523193.\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Early stopping triggered after 114 epochs\n",
                        "Test MSE: 46.5000\n",
                        "Test RMSE: 6.8191\n",
                        "Test MAE: 5.0019\n",
                        "Test R2 Score: 0.0581\n"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "[I 2024-08-24 22:41:25,369] Trial 16 finished with value: 4.987729072570801 and parameters: {'hidden_size': 61, 'num_layers': 2, 'fc1_size': 111, 'fc2_size': 33, 'bidirectional': True, 'dropout': 0.3596868867610109, 'learning_rate': 2.119794914900442e-05, 'batch_size': 32}. Best is trial 14 with value: 4.848199367523193.\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Test MSE: 46.4380\n",
                        "Test RMSE: 6.8145\n",
                        "Test MAE: 4.9877\n",
                        "Test R2 Score: 0.0594\n"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "[I 2024-08-24 22:42:12,029] Trial 17 finished with value: 4.9597978591918945 and parameters: {'hidden_size': 77, 'num_layers': 3, 'fc1_size': 141, 'fc2_size': 19, 'bidirectional': True, 'dropout': 0.4225736709573562, 'learning_rate': 0.004670548306040671, 'batch_size': 32}. Best is trial 14 with value: 4.848199367523193.\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Early stopping triggered after 116 epochs\n",
                        "Test MSE: 45.9934\n",
                        "Test RMSE: 6.7818\n",
                        "Test MAE: 4.9598\n",
                        "Test R2 Score: 0.0684\n"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "[I 2024-08-24 22:42:58,283] Trial 18 finished with value: 4.935848236083984 and parameters: {'hidden_size': 112, 'num_layers': 2, 'fc1_size': 191, 'fc2_size': 50, 'bidirectional': False, 'dropout': 0.23749696433511547, 'learning_rate': 7.335386651571407e-05, 'batch_size': 32}. Best is trial 14 with value: 4.848199367523193.\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Test MSE: 46.0203\n",
                        "Test RMSE: 6.7838\n",
                        "Test MAE: 4.9358\n",
                        "Test R2 Score: 0.0679\n"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "[I 2024-08-24 22:43:37,440] Trial 19 finished with value: 4.909971714019775 and parameters: {'hidden_size': 90, 'num_layers': 2, 'fc1_size': 47, 'fc2_size': 100, 'bidirectional': True, 'dropout': 0.36963360816109875, 'learning_rate': 0.0032401619415223302, 'batch_size': 32}. Best is trial 14 with value: 4.848199367523193.\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Early stopping triggered after 120 epochs\n",
                        "Test MSE: 46.2095\n",
                        "Test RMSE: 6.7978\n",
                        "Test MAE: 4.9100\n",
                        "Test R2 Score: 0.0640\n"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "[I 2024-08-24 22:44:14,484] Trial 20 finished with value: 5.011153697967529 and parameters: {'hidden_size': 129, 'num_layers': 3, 'fc1_size': 102, 'fc2_size': 33, 'bidirectional': True, 'dropout': 0.3035190895347676, 'learning_rate': 0.011949799700372956, 'batch_size': 128}. Best is trial 14 with value: 4.848199367523193.\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Test MSE: 46.6461\n",
                        "Test RMSE: 6.8298\n",
                        "Test MAE: 5.0112\n",
                        "Test R2 Score: 0.0552\n"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "[I 2024-08-24 22:44:49,502] Trial 21 finished with value: 4.884944915771484 and parameters: {'hidden_size': 92, 'num_layers': 2, 'fc1_size': 34, 'fc2_size': 105, 'bidirectional': True, 'dropout': 0.3611529748144024, 'learning_rate': 0.002619709015342106, 'batch_size': 32}. Best is trial 14 with value: 4.848199367523193.\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Early stopping triggered after 109 epochs\n",
                        "Test MSE: 46.4083\n",
                        "Test RMSE: 6.8124\n",
                        "Test MAE: 4.8849\n",
                        "Test R2 Score: 0.0600\n"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "[I 2024-08-24 22:45:21,348] Trial 22 finished with value: 4.942366600036621 and parameters: {'hidden_size': 67, 'num_layers': 2, 'fc1_size': 58, 'fc2_size': 104, 'bidirectional': True, 'dropout': 0.33396910639801963, 'learning_rate': 0.0006305174772686736, 'batch_size': 32}. Best is trial 14 with value: 4.848199367523193.\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Early stopping triggered after 112 epochs\n",
                        "Test MSE: 45.7262\n",
                        "Test RMSE: 6.7621\n",
                        "Test MAE: 4.9424\n",
                        "Test R2 Score: 0.0738\n"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "[I 2024-08-24 22:46:17,090] Trial 23 finished with value: 5.259329795837402 and parameters: {'hidden_size': 143, 'num_layers': 2, 'fc1_size': 138, 'fc2_size': 127, 'bidirectional': True, 'dropout': 0.43297489334092004, 'learning_rate': 0.0019618028785834494, 'batch_size': 32}. Best is trial 14 with value: 4.848199367523193.\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Early stopping triggered after 106 epochs\n",
                        "Test MSE: 46.9663\n",
                        "Test RMSE: 6.8532\n",
                        "Test MAE: 5.2593\n",
                        "Test R2 Score: 0.0487\n"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "[I 2024-08-24 22:47:19,750] Trial 24 finished with value: 5.042994022369385 and parameters: {'hidden_size': 97, 'num_layers': 2, 'fc1_size': 87, 'fc2_size': 82, 'bidirectional': True, 'dropout': 0.3392338382335349, 'learning_rate': 0.010981577011726373, 'batch_size': 32}. Best is trial 14 with value: 4.848199367523193.\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Early stopping triggered after 168 epochs\n",
                        "Test MSE: 46.2220\n",
                        "Test RMSE: 6.7987\n",
                        "Test MAE: 5.0430\n",
                        "Test R2 Score: 0.0638\n"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "[I 2024-08-24 22:47:53,291] Trial 25 finished with value: 4.9986443519592285 and parameters: {'hidden_size': 53, 'num_layers': 2, 'fc1_size': 116, 'fc2_size': 105, 'bidirectional': True, 'dropout': 0.3998629559728909, 'learning_rate': 0.0004054680103543739, 'batch_size': 32}. Best is trial 14 with value: 4.848199367523193.\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Early stopping triggered after 118 epochs\n",
                        "Test MSE: 46.7825\n",
                        "Test RMSE: 6.8398\n",
                        "Test MAE: 4.9986\n",
                        "Test R2 Score: 0.0524\n"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "[I 2024-08-24 22:48:39,729] Trial 26 finished with value: 5.147819995880127 and parameters: {'hidden_size': 35, 'num_layers': 3, 'fc1_size': 33, 'fc2_size': 55, 'bidirectional': False, 'dropout': 0.4477199575858718, 'learning_rate': 4.950619965800139e-05, 'batch_size': 32}. Best is trial 14 with value: 4.848199367523193.\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Test MSE: 49.5985\n",
                        "Test RMSE: 7.0426\n",
                        "Test MAE: 5.1478\n",
                        "Test R2 Score: -0.0046\n"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "[I 2024-08-24 22:49:19,049] Trial 27 finished with value: 4.988982200622559 and parameters: {'hidden_size': 102, 'num_layers': 2, 'fc1_size': 181, 'fc2_size': 74, 'bidirectional': True, 'dropout': 0.14470679742163625, 'learning_rate': 0.0029414336819338764, 'batch_size': 32}. Best is trial 14 with value: 4.848199367523193.\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Early stopping triggered after 107 epochs\n",
                        "Test MSE: 47.0511\n",
                        "Test RMSE: 6.8594\n",
                        "Test MAE: 4.9890\n",
                        "Test R2 Score: 0.0470\n"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "[I 2024-08-24 22:49:51,402] Trial 28 finished with value: 5.105520725250244 and parameters: {'hidden_size': 144, 'num_layers': 2, 'fc1_size': 216, 'fc2_size': 115, 'bidirectional': True, 'dropout': 0.2616802146016552, 'learning_rate': 0.02502542960113371, 'batch_size': 64}. Best is trial 14 with value: 4.848199367523193.\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Early stopping triggered after 117 epochs\n",
                        "Test MSE: 48.1179\n",
                        "Test RMSE: 6.9367\n",
                        "Test MAE: 5.1055\n",
                        "Test R2 Score: 0.0254\n"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "/home/marek/miniforge3/envs/mgr/lib/python3.11/site-packages/torch/nn/modules/rnn.py:83: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.33407738218231725 and num_layers=1\n",
                        "  warnings.warn(\"dropout option adds dropout after all but last \"\n",
                        "[I 2024-08-24 22:49:58,502] Trial 29 finished with value: 4.970368385314941 and parameters: {'hidden_size': 72, 'num_layers': 1, 'fc1_size': 151, 'fc2_size': 97, 'bidirectional': True, 'dropout': 0.33407738218231725, 'learning_rate': 0.0006548545176070101, 'batch_size': 128}. Best is trial 14 with value: 4.848199367523193.\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Early stopping triggered after 120 epochs\n",
                        "Test MSE: 46.7186\n",
                        "Test RMSE: 6.8351\n",
                        "Test MAE: 4.9704\n",
                        "Test R2 Score: 0.0537\n"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "[I 2024-08-24 22:51:14,602] Trial 30 finished with value: 5.065745830535889 and parameters: {'hidden_size': 165, 'num_layers': 2, 'fc1_size': 170, 'fc2_size': 81, 'bidirectional': True, 'dropout': 0.22070176479722392, 'learning_rate': 0.006209870039602328, 'batch_size': 32}. Best is trial 14 with value: 4.848199367523193.\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Early stopping triggered after 122 epochs\n",
                        "Test MSE: 46.8172\n",
                        "Test RMSE: 6.8423\n",
                        "Test MAE: 5.0657\n",
                        "Test R2 Score: 0.0517\n"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "[I 2024-08-24 22:51:52,278] Trial 31 finished with value: 4.879350185394287 and parameters: {'hidden_size': 83, 'num_layers': 2, 'fc1_size': 55, 'fc2_size': 101, 'bidirectional': True, 'dropout': 0.379813844561702, 'learning_rate': 0.002754301212841557, 'batch_size': 32}. Best is trial 14 with value: 4.848199367523193.\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Early stopping triggered after 119 epochs\n",
                        "Test MSE: 46.7834\n",
                        "Test RMSE: 6.8398\n",
                        "Test MAE: 4.8794\n",
                        "Test R2 Score: 0.0524\n"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "[I 2024-08-24 22:52:26,430] Trial 32 finished with value: 4.86000919342041 and parameters: {'hidden_size': 85, 'num_layers': 2, 'fc1_size': 48, 'fc2_size': 111, 'bidirectional': True, 'dropout': 0.3926653571914628, 'learning_rate': 0.0023937634815381654, 'batch_size': 32}. Best is trial 14 with value: 4.848199367523193.\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Early stopping triggered after 112 epochs\n",
                        "Test MSE: 46.5546\n",
                        "Test RMSE: 6.8231\n",
                        "Test MAE: 4.8600\n",
                        "Test R2 Score: 0.0570\n"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "[I 2024-08-24 22:52:59,747] Trial 33 finished with value: 4.8187947273254395 and parameters: {'hidden_size': 84, 'num_layers': 2, 'fc1_size': 52, 'fc2_size': 110, 'bidirectional': True, 'dropout': 0.3994148001688793, 'learning_rate': 0.0021325235320931984, 'batch_size': 32}. Best is trial 33 with value: 4.8187947273254395.\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Early stopping triggered after 110 epochs\n",
                        "Test MSE: 46.5285\n",
                        "Test RMSE: 6.8212\n",
                        "Test MAE: 4.8188\n",
                        "Test R2 Score: 0.0576\n"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "[I 2024-08-24 22:53:28,057] Trial 34 finished with value: 4.998140335083008 and parameters: {'hidden_size': 48, 'num_layers': 2, 'fc1_size': 58, 'fc2_size': 112, 'bidirectional': True, 'dropout': 0.39646336320018594, 'learning_rate': 0.0009213982303281057, 'batch_size': 32}. Best is trial 33 with value: 4.8187947273254395.\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Early stopping triggered after 110 epochs\n",
                        "Test MSE: 46.9781\n",
                        "Test RMSE: 6.8541\n",
                        "Test MAE: 4.9981\n",
                        "Test R2 Score: 0.0485\n"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "[I 2024-08-24 22:53:47,152] Trial 35 finished with value: 4.92236852645874 and parameters: {'hidden_size': 82, 'num_layers': 2, 'fc1_size': 73, 'fc2_size': 96, 'bidirectional': True, 'dropout': 0.46401869197832923, 'learning_rate': 0.0074059116385648115, 'batch_size': 64}. Best is trial 33 with value: 4.8187947273254395.\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Early stopping triggered after 123 epochs\n",
                        "Test MSE: 46.2849\n",
                        "Test RMSE: 6.8033\n",
                        "Test MAE: 4.9224\n",
                        "Test R2 Score: 0.0625\n"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "/home/marek/miniforge3/envs/mgr/lib/python3.11/site-packages/torch/nn/modules/rnn.py:83: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.39234612069035485 and num_layers=1\n",
                        "  warnings.warn(\"dropout option adds dropout after all but last \"\n",
                        "[I 2024-08-24 22:55:10,460] Trial 36 finished with value: 5.298125743865967 and parameters: {'hidden_size': 254, 'num_layers': 1, 'fc1_size': 48, 'fc2_size': 125, 'bidirectional': False, 'dropout': 0.39234612069035485, 'learning_rate': 0.017844763524562705, 'batch_size': 16}. Best is trial 33 with value: 4.8187947273254395.\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Early stopping triggered after 149 epochs\n",
                        "Test MSE: 49.3707\n",
                        "Test RMSE: 7.0264\n",
                        "Test MAE: 5.2981\n",
                        "Test R2 Score: -0.0000\n"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "[I 2024-08-24 22:55:53,529] Trial 37 finished with value: 4.958982944488525 and parameters: {'hidden_size': 68, 'num_layers': 3, 'fc1_size': 91, 'fc2_size': 110, 'bidirectional': True, 'dropout': 0.41577977545160705, 'learning_rate': 0.0013599246750959234, 'batch_size': 32}. Best is trial 33 with value: 4.8187947273254395.\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Early stopping triggered after 109 epochs\n",
                        "Test MSE: 46.3411\n",
                        "Test RMSE: 6.8074\n",
                        "Test MAE: 4.9590\n",
                        "Test R2 Score: 0.0614\n"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "/home/marek/miniforge3/envs/mgr/lib/python3.11/site-packages/torch/nn/modules/rnn.py:83: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.4965248906442205 and num_layers=1\n",
                        "  warnings.warn(\"dropout option adds dropout after all but last \"\n",
                        "[I 2024-08-24 22:56:23,198] Trial 38 finished with value: 4.868798732757568 and parameters: {'hidden_size': 111, 'num_layers': 1, 'fc1_size': 48, 'fc2_size': 120, 'bidirectional': True, 'dropout': 0.4965248906442205, 'learning_rate': 0.0034784387466132165, 'batch_size': 32}. Best is trial 33 with value: 4.8187947273254395.\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Early stopping triggered after 122 epochs\n",
                        "Test MSE: 49.6860\n",
                        "Test RMSE: 7.0488\n",
                        "Test MAE: 4.8688\n",
                        "Test R2 Score: -0.0064\n"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "/home/marek/miniforge3/envs/mgr/lib/python3.11/site-packages/torch/nn/modules/rnn.py:83: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.4780293834518442 and num_layers=1\n",
                        "  warnings.warn(\"dropout option adds dropout after all but last \"\n",
                        "[I 2024-08-24 22:57:33,949] Trial 39 finished with value: 5.298882484436035 and parameters: {'hidden_size': 109, 'num_layers': 1, 'fc1_size': 73, 'fc2_size': 123, 'bidirectional': False, 'dropout': 0.4780293834518442, 'learning_rate': 0.03478614765818605, 'batch_size': 16}. Best is trial 33 with value: 4.8187947273254395.\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Test MSE: 49.3707\n",
                        "Test RMSE: 7.0264\n",
                        "Test MAE: 5.2989\n",
                        "Test R2 Score: 0.0000\n"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "/home/marek/miniforge3/envs/mgr/lib/python3.11/site-packages/torch/nn/modules/rnn.py:83: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.44081454488345834 and num_layers=1\n",
                        "  warnings.warn(\"dropout option adds dropout after all but last \"\n",
                        "[I 2024-08-24 22:57:48,280] Trial 40 finished with value: 5.19559383392334 and parameters: {'hidden_size': 126, 'num_layers': 1, 'fc1_size': 98, 'fc2_size': 68, 'bidirectional': True, 'dropout': 0.44081454488345834, 'learning_rate': 0.009026126903079097, 'batch_size': 64}. Best is trial 33 with value: 4.8187947273254395.\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Early stopping triggered after 107 epochs\n",
                        "Test MSE: 47.3371\n",
                        "Test RMSE: 6.8802\n",
                        "Test MAE: 5.1956\n",
                        "Test R2 Score: 0.0412\n"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "/home/marek/miniforge3/envs/mgr/lib/python3.11/site-packages/torch/nn/modules/rnn.py:83: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.49518405896804574 and num_layers=1\n",
                        "  warnings.warn(\"dropout option adds dropout after all but last \"\n",
                        "[I 2024-08-24 22:58:12,086] Trial 41 finished with value: 5.026761531829834 and parameters: {'hidden_size': 84, 'num_layers': 1, 'fc1_size': 48, 'fc2_size': 118, 'bidirectional': True, 'dropout': 0.49518405896804574, 'learning_rate': 0.003952364150684674, 'batch_size': 32}. Best is trial 33 with value: 4.8187947273254395.\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Early stopping triggered after 106 epochs\n",
                        "Test MSE: 47.1159\n",
                        "Test RMSE: 6.8641\n",
                        "Test MAE: 5.0268\n",
                        "Test R2 Score: 0.0457\n"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "[I 2024-08-24 22:58:47,549] Trial 42 finished with value: 4.964754581451416 and parameters: {'hidden_size': 59, 'num_layers': 2, 'fc1_size': 61, 'fc2_size': 111, 'bidirectional': True, 'dropout': 0.3780551145733402, 'learning_rate': 0.0017584791698839343, 'batch_size': 32}. Best is trial 33 with value: 4.8187947273254395.\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Early stopping triggered after 114 epochs\n",
                        "Test MSE: 46.1951\n",
                        "Test RMSE: 6.7967\n",
                        "Test MAE: 4.9648\n",
                        "Test R2 Score: 0.0643\n"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "/home/marek/miniforge3/envs/mgr/lib/python3.11/site-packages/torch/nn/modules/rnn.py:83: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.4630816776201721 and num_layers=1\n",
                        "  warnings.warn(\"dropout option adds dropout after all but last \"\n",
                        "[I 2024-08-24 22:59:16,005] Trial 43 finished with value: 5.050201892852783 and parameters: {'hidden_size': 106, 'num_layers': 1, 'fc1_size': 43, 'fc2_size': 91, 'bidirectional': True, 'dropout': 0.4630816776201721, 'learning_rate': 0.0009992504641250055, 'batch_size': 32}. Best is trial 33 with value: 4.8187947273254395.\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Early stopping triggered after 105 epochs\n",
                        "Test MSE: 47.1935\n",
                        "Test RMSE: 6.8698\n",
                        "Test MAE: 5.0502\n",
                        "Test R2 Score: 0.0441\n"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "[I 2024-08-24 22:59:50,805] Trial 44 finished with value: 4.926350116729736 and parameters: {'hidden_size': 85, 'num_layers': 2, 'fc1_size': 256, 'fc2_size': 121, 'bidirectional': True, 'dropout': 0.4111180859179116, 'learning_rate': 0.0021384397651676946, 'batch_size': 32}. Best is trial 33 with value: 4.8187947273254395.\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Early stopping triggered after 105 epochs\n",
                        "Test MSE: 46.7546\n",
                        "Test RMSE: 6.8377\n",
                        "Test MAE: 4.9264\n",
                        "Test R2 Score: 0.0530\n"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "/home/marek/miniforge3/envs/mgr/lib/python3.11/site-packages/torch/nn/modules/rnn.py:83: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.32197440474481076 and num_layers=1\n",
                        "  warnings.warn(\"dropout option adds dropout after all but last \"\n",
                        "[I 2024-08-24 23:00:35,038] Trial 45 finished with value: 4.977888584136963 and parameters: {'hidden_size': 213, 'num_layers': 1, 'fc1_size': 70, 'fc2_size': 109, 'bidirectional': True, 'dropout': 0.32197440474481076, 'learning_rate': 0.003901279369049625, 'batch_size': 32}. Best is trial 33 with value: 4.8187947273254395.\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Early stopping triggered after 105 epochs\n",
                        "Test MSE: 47.6172\n",
                        "Test RMSE: 6.9005\n",
                        "Test MAE: 4.9779\n",
                        "Test R2 Score: 0.0355\n"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "[I 2024-08-24 23:00:58,202] Trial 46 finished with value: 5.031637668609619 and parameters: {'hidden_size': 118, 'num_layers': 2, 'fc1_size': 84, 'fc2_size': 128, 'bidirectional': True, 'dropout': 0.428671175669335, 'learning_rate': 0.01801396493853277, 'batch_size': 128}. Best is trial 33 with value: 4.8187947273254395.\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Test MSE: 46.4305\n",
                        "Test RMSE: 6.8140\n",
                        "Test MAE: 5.0316\n",
                        "Test R2 Score: 0.0596\n"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "[I 2024-08-24 23:01:25,270] Trial 47 finished with value: 5.059025287628174 and parameters: {'hidden_size': 73, 'num_layers': 2, 'fc1_size': 55, 'fc2_size': 116, 'bidirectional': False, 'dropout': 0.34911214571690086, 'learning_rate': 0.005831829196195321, 'batch_size': 32}. Best is trial 33 with value: 4.8187947273254395.\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Early stopping triggered after 119 epochs\n",
                        "Test MSE: 46.4023\n",
                        "Test RMSE: 6.8119\n",
                        "Test MAE: 5.0590\n",
                        "Test R2 Score: 0.0601\n"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "[I 2024-08-24 23:03:22,184] Trial 48 finished with value: 4.908918380737305 and parameters: {'hidden_size': 99, 'num_layers': 3, 'fc1_size': 81, 'fc2_size': 92, 'bidirectional': True, 'dropout': 0.3845908919607479, 'learning_rate': 0.0008259636604444714, 'batch_size': 16}. Best is trial 33 with value: 4.8187947273254395.\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Early stopping triggered after 115 epochs\n",
                        "Test MSE: 45.9344\n",
                        "Test RMSE: 6.7775\n",
                        "Test MAE: 4.9089\n",
                        "Test R2 Score: 0.0696\n"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "[I 2024-08-24 23:04:00,902] Trial 49 finished with value: 4.9875807762146 and parameters: {'hidden_size': 46, 'num_layers': 2, 'fc1_size': 41, 'fc2_size': 86, 'bidirectional': True, 'dropout': 0.49717684721285904, 'learning_rate': 0.0004496832386312383, 'batch_size': 32}. Best is trial 33 with value: 4.8187947273254395.\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Early stopping triggered after 128 epochs\n",
                        "Test MSE: 46.0619\n",
                        "Test RMSE: 6.7869\n",
                        "Test MAE: 4.9876\n",
                        "Test R2 Score: 0.0670\n"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "/home/marek/miniforge3/envs/mgr/lib/python3.11/site-packages/torch/nn/modules/rnn.py:83: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.45492246270888415 and num_layers=1\n",
                        "  warnings.warn(\"dropout option adds dropout after all but last \"\n",
                        "[I 2024-08-24 23:04:27,212] Trial 50 finished with value: 4.921656608581543 and parameters: {'hidden_size': 60, 'num_layers': 1, 'fc1_size': 65, 'fc2_size': 105, 'bidirectional': True, 'dropout': 0.45492246270888415, 'learning_rate': 0.0026022324341889607, 'batch_size': 32}. Best is trial 33 with value: 4.8187947273254395.\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Early stopping triggered after 108 epochs\n",
                        "Test MSE: 46.9664\n",
                        "Test RMSE: 6.8532\n",
                        "Test MAE: 4.9217\n",
                        "Test R2 Score: 0.0487\n"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "[W 2024-08-24 23:04:29,863] Trial 51 failed with parameters: {'hidden_size': 92, 'num_layers': 2, 'fc1_size': 34, 'fc2_size': 101, 'bidirectional': True, 'dropout': 0.3491065863430623, 'learning_rate': 0.0027444066519700903, 'batch_size': 32} because of the following error: KeyboardInterrupt().\n",
                        "Traceback (most recent call last):\n",
                        "  File \"/home/marek/miniforge3/envs/mgr/lib/python3.11/site-packages/optuna/study/_optimize.py\", line 196, in _run_trial\n",
                        "    value_or_values = func(trial)\n",
                        "                      ^^^^^^^^^^^\n",
                        "  File \"/tmp/ipykernel_54390/1207432482.py\", line 20, in objective\n",
                        "    best_model = train_model(model, X_train, y_train, X_val, y_val, batch_size, num_epochs=200, learning_rate=learning_rate)\n",
                        "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
                        "  File \"/tmp/ipykernel_54390/70497110.py\", line 54, in train_model\n",
                        "    optimizer.step()\n",
                        "  File \"/home/marek/miniforge3/envs/mgr/lib/python3.11/site-packages/torch/optim/optimizer.py\", line 391, in wrapper\n",
                        "    out = func(*args, **kwargs)\n",
                        "          ^^^^^^^^^^^^^^^^^^^^^\n",
                        "  File \"/home/marek/miniforge3/envs/mgr/lib/python3.11/site-packages/torch/optim/optimizer.py\", line 76, in _use_grad\n",
                        "    ret = func(self, *args, **kwargs)\n",
                        "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
                        "  File \"/home/marek/miniforge3/envs/mgr/lib/python3.11/site-packages/torch/optim/adam.py\", line 168, in step\n",
                        "    adam(\n",
                        "  File \"/home/marek/miniforge3/envs/mgr/lib/python3.11/site-packages/torch/optim/adam.py\", line 318, in adam\n",
                        "    func(params,\n",
                        "  File \"/home/marek/miniforge3/envs/mgr/lib/python3.11/site-packages/torch/optim/adam.py\", line 581, in _multi_tensor_adam\n",
                        "    exp_avg_sq_sqrt = torch._foreach_sqrt(device_exp_avg_sqs)\n",
                        "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
                        "KeyboardInterrupt\n",
                        "[W 2024-08-24 23:04:29,865] Trial 51 failed with value None.\n"
                    ]
                },
                {
                    "ename": "KeyboardInterrupt",
                    "evalue": "",
                    "output_type": "error",
                    "traceback": [
                        "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
                        "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
                        "Cell \u001b[0;32mIn[60], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m study \u001b[38;5;241m=\u001b[39m optuna\u001b[38;5;241m.\u001b[39mcreate_study(direction\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mminimize\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m----> 2\u001b[0m \u001b[43mstudy\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptimize\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobjective\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m100\u001b[39;49m\u001b[43m)\u001b[49m\n",
                        "File \u001b[0;32m~/miniforge3/envs/mgr/lib/python3.11/site-packages/optuna/study/study.py:451\u001b[0m, in \u001b[0;36mStudy.optimize\u001b[0;34m(self, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[1;32m    348\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21moptimize\u001b[39m(\n\u001b[1;32m    349\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    350\u001b[0m     func: ObjectiveFuncType,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    357\u001b[0m     show_progress_bar: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m    358\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    359\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Optimize an objective function.\u001b[39;00m\n\u001b[1;32m    360\u001b[0m \n\u001b[1;32m    361\u001b[0m \u001b[38;5;124;03m    Optimization is done by choosing a suitable set of hyperparameter values from a given\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    449\u001b[0m \u001b[38;5;124;03m            If nested invocation of this method occurs.\u001b[39;00m\n\u001b[1;32m    450\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 451\u001b[0m     \u001b[43m_optimize\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    452\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstudy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    453\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfunc\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    454\u001b[0m \u001b[43m        \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_trials\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    455\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    456\u001b[0m \u001b[43m        \u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_jobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    457\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcatch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mtuple\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43misinstance\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mIterable\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    458\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    459\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgc_after_trial\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgc_after_trial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    460\u001b[0m \u001b[43m        \u001b[49m\u001b[43mshow_progress_bar\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mshow_progress_bar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    461\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
                        "File \u001b[0;32m~/miniforge3/envs/mgr/lib/python3.11/site-packages/optuna/study/_optimize.py:62\u001b[0m, in \u001b[0;36m_optimize\u001b[0;34m(study, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[1;32m     60\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     61\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m n_jobs \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m---> 62\u001b[0m         \u001b[43m_optimize_sequential\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     63\u001b[0m \u001b[43m            \u001b[49m\u001b[43mstudy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     64\u001b[0m \u001b[43m            \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     65\u001b[0m \u001b[43m            \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     66\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     67\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     68\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     69\u001b[0m \u001b[43m            \u001b[49m\u001b[43mgc_after_trial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     70\u001b[0m \u001b[43m            \u001b[49m\u001b[43mreseed_sampler_rng\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     71\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtime_start\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     72\u001b[0m \u001b[43m            \u001b[49m\u001b[43mprogress_bar\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprogress_bar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     73\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     74\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     75\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m n_jobs \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m:\n",
                        "File \u001b[0;32m~/miniforge3/envs/mgr/lib/python3.11/site-packages/optuna/study/_optimize.py:159\u001b[0m, in \u001b[0;36m_optimize_sequential\u001b[0;34m(study, func, n_trials, timeout, catch, callbacks, gc_after_trial, reseed_sampler_rng, time_start, progress_bar)\u001b[0m\n\u001b[1;32m    156\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[1;32m    158\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 159\u001b[0m     frozen_trial \u001b[38;5;241m=\u001b[39m \u001b[43m_run_trial\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstudy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    160\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    161\u001b[0m     \u001b[38;5;66;03m# The following line mitigates memory problems that can be occurred in some\u001b[39;00m\n\u001b[1;32m    162\u001b[0m     \u001b[38;5;66;03m# environments (e.g., services that use computing containers such as GitHub Actions).\u001b[39;00m\n\u001b[1;32m    163\u001b[0m     \u001b[38;5;66;03m# Please refer to the following PR for further details:\u001b[39;00m\n\u001b[1;32m    164\u001b[0m     \u001b[38;5;66;03m# https://github.com/optuna/optuna/pull/325.\u001b[39;00m\n\u001b[1;32m    165\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m gc_after_trial:\n",
                        "File \u001b[0;32m~/miniforge3/envs/mgr/lib/python3.11/site-packages/optuna/study/_optimize.py:247\u001b[0m, in \u001b[0;36m_run_trial\u001b[0;34m(study, func, catch)\u001b[0m\n\u001b[1;32m    240\u001b[0m         \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mShould not reach.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    242\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m    243\u001b[0m     frozen_trial\u001b[38;5;241m.\u001b[39mstate \u001b[38;5;241m==\u001b[39m TrialState\u001b[38;5;241m.\u001b[39mFAIL\n\u001b[1;32m    244\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m func_err \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    245\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(func_err, catch)\n\u001b[1;32m    246\u001b[0m ):\n\u001b[0;32m--> 247\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m func_err\n\u001b[1;32m    248\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m frozen_trial\n",
                        "File \u001b[0;32m~/miniforge3/envs/mgr/lib/python3.11/site-packages/optuna/study/_optimize.py:196\u001b[0m, in \u001b[0;36m_run_trial\u001b[0;34m(study, func, catch)\u001b[0m\n\u001b[1;32m    194\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m get_heartbeat_thread(trial\u001b[38;5;241m.\u001b[39m_trial_id, study\u001b[38;5;241m.\u001b[39m_storage):\n\u001b[1;32m    195\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 196\u001b[0m         value_or_values \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    197\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m exceptions\u001b[38;5;241m.\u001b[39mTrialPruned \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    198\u001b[0m         \u001b[38;5;66;03m# TODO(mamu): Handle multi-objective cases.\u001b[39;00m\n\u001b[1;32m    199\u001b[0m         state \u001b[38;5;241m=\u001b[39m TrialState\u001b[38;5;241m.\u001b[39mPRUNED\n",
                        "Cell \u001b[0;32mIn[59], line 20\u001b[0m, in \u001b[0;36mobjective\u001b[0;34m(trial)\u001b[0m\n\u001b[1;32m     17\u001b[0m model \u001b[38;5;241m=\u001b[39m AsteroidLSTM(config)\n\u001b[1;32m     19\u001b[0m \u001b[38;5;66;03m# Train the model\u001b[39;00m\n\u001b[0;32m---> 20\u001b[0m best_model \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX_val\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_val\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_epochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m200\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlearning_rate\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlearning_rate\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     22\u001b[0m \u001b[38;5;66;03m# Evaluate the model\u001b[39;00m\n\u001b[1;32m     23\u001b[0m _, _, mae, _, _, _ \u001b[38;5;241m=\u001b[39m evaluate_model(best_model, X_val, y_val, batch_size)\n",
                        "Cell \u001b[0;32mIn[49], line 54\u001b[0m, in \u001b[0;36mtrain_model\u001b[0;34m(model, X_train, y_train, X_val, y_val, batch_size, num_epochs, learning_rate, model_suffix, patience)\u001b[0m\n\u001b[1;32m     52\u001b[0m     loss \u001b[38;5;241m=\u001b[39m criterion(outputs\u001b[38;5;241m.\u001b[39msqueeze(), y_batch)\n\u001b[1;32m     53\u001b[0m     loss\u001b[38;5;241m.\u001b[39mbackward()\n\u001b[0;32m---> 54\u001b[0m     \u001b[43moptimizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     56\u001b[0m     train_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m loss\u001b[38;5;241m.\u001b[39mitem() \u001b[38;5;241m*\u001b[39m y_batch\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m     58\u001b[0m train_loss \u001b[38;5;241m/\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(train_loader\u001b[38;5;241m.\u001b[39mdataset)\n",
                        "File \u001b[0;32m~/miniforge3/envs/mgr/lib/python3.11/site-packages/torch/optim/optimizer.py:391\u001b[0m, in \u001b[0;36mOptimizer.profile_hook_step.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    386\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    387\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[1;32m    388\u001b[0m                 \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must return None or a tuple of (new_args, new_kwargs), but got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresult\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    389\u001b[0m             )\n\u001b[0;32m--> 391\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    392\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_optimizer_step_code()\n\u001b[1;32m    394\u001b[0m \u001b[38;5;66;03m# call optimizer step post hooks\u001b[39;00m\n",
                        "File \u001b[0;32m~/miniforge3/envs/mgr/lib/python3.11/site-packages/torch/optim/optimizer.py:76\u001b[0m, in \u001b[0;36m_use_grad_for_differentiable.<locals>._use_grad\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     74\u001b[0m     torch\u001b[38;5;241m.\u001b[39mset_grad_enabled(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdefaults[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdifferentiable\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[1;32m     75\u001b[0m     torch\u001b[38;5;241m.\u001b[39m_dynamo\u001b[38;5;241m.\u001b[39mgraph_break()\n\u001b[0;32m---> 76\u001b[0m     ret \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     77\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m     78\u001b[0m     torch\u001b[38;5;241m.\u001b[39m_dynamo\u001b[38;5;241m.\u001b[39mgraph_break()\n",
                        "File \u001b[0;32m~/miniforge3/envs/mgr/lib/python3.11/site-packages/torch/optim/adam.py:168\u001b[0m, in \u001b[0;36mAdam.step\u001b[0;34m(self, closure)\u001b[0m\n\u001b[1;32m    157\u001b[0m     beta1, beta2 \u001b[38;5;241m=\u001b[39m group[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbetas\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m    159\u001b[0m     has_complex \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_init_group(\n\u001b[1;32m    160\u001b[0m         group,\n\u001b[1;32m    161\u001b[0m         params_with_grad,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    165\u001b[0m         max_exp_avg_sqs,\n\u001b[1;32m    166\u001b[0m         state_steps)\n\u001b[0;32m--> 168\u001b[0m     \u001b[43madam\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    169\u001b[0m \u001b[43m        \u001b[49m\u001b[43mparams_with_grad\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    170\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgrads\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    171\u001b[0m \u001b[43m        \u001b[49m\u001b[43mexp_avgs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    172\u001b[0m \u001b[43m        \u001b[49m\u001b[43mexp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    173\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmax_exp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    174\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstate_steps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    175\u001b[0m \u001b[43m        \u001b[49m\u001b[43mamsgrad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mamsgrad\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    176\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhas_complex\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhas_complex\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    177\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbeta1\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbeta1\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    178\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbeta2\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbeta2\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    179\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mlr\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    180\u001b[0m \u001b[43m        \u001b[49m\u001b[43mweight_decay\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mweight_decay\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    181\u001b[0m \u001b[43m        \u001b[49m\u001b[43meps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43meps\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    182\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmaximize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mmaximize\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    183\u001b[0m \u001b[43m        \u001b[49m\u001b[43mforeach\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mforeach\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    184\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcapturable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mcapturable\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    185\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdifferentiable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mdifferentiable\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    186\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfused\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mfused\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    187\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgrad_scale\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mgrad_scale\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    188\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfound_inf\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfound_inf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    189\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    191\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m loss\n",
                        "File \u001b[0;32m~/miniforge3/envs/mgr/lib/python3.11/site-packages/torch/optim/adam.py:318\u001b[0m, in \u001b[0;36madam\u001b[0;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, foreach, capturable, differentiable, fused, grad_scale, found_inf, has_complex, amsgrad, beta1, beta2, lr, weight_decay, eps, maximize)\u001b[0m\n\u001b[1;32m    315\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    316\u001b[0m     func \u001b[38;5;241m=\u001b[39m _single_tensor_adam\n\u001b[0;32m--> 318\u001b[0m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    319\u001b[0m \u001b[43m     \u001b[49m\u001b[43mgrads\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    320\u001b[0m \u001b[43m     \u001b[49m\u001b[43mexp_avgs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    321\u001b[0m \u001b[43m     \u001b[49m\u001b[43mexp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    322\u001b[0m \u001b[43m     \u001b[49m\u001b[43mmax_exp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    323\u001b[0m \u001b[43m     \u001b[49m\u001b[43mstate_steps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    324\u001b[0m \u001b[43m     \u001b[49m\u001b[43mamsgrad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mamsgrad\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    325\u001b[0m \u001b[43m     \u001b[49m\u001b[43mhas_complex\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhas_complex\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    326\u001b[0m \u001b[43m     \u001b[49m\u001b[43mbeta1\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbeta1\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    327\u001b[0m \u001b[43m     \u001b[49m\u001b[43mbeta2\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbeta2\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    328\u001b[0m \u001b[43m     \u001b[49m\u001b[43mlr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlr\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    329\u001b[0m \u001b[43m     \u001b[49m\u001b[43mweight_decay\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mweight_decay\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    330\u001b[0m \u001b[43m     \u001b[49m\u001b[43meps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43meps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    331\u001b[0m \u001b[43m     \u001b[49m\u001b[43mmaximize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmaximize\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    332\u001b[0m \u001b[43m     \u001b[49m\u001b[43mcapturable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcapturable\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    333\u001b[0m \u001b[43m     \u001b[49m\u001b[43mdifferentiable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdifferentiable\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    334\u001b[0m \u001b[43m     \u001b[49m\u001b[43mgrad_scale\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgrad_scale\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    335\u001b[0m \u001b[43m     \u001b[49m\u001b[43mfound_inf\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfound_inf\u001b[49m\u001b[43m)\u001b[49m\n",
                        "File \u001b[0;32m~/miniforge3/envs/mgr/lib/python3.11/site-packages/torch/optim/adam.py:581\u001b[0m, in \u001b[0;36m_multi_tensor_adam\u001b[0;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, grad_scale, found_inf, amsgrad, has_complex, beta1, beta2, lr, weight_decay, eps, maximize, capturable, differentiable)\u001b[0m\n\u001b[1;32m    579\u001b[0m     exp_avg_sq_sqrt \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39m_foreach_sqrt(device_max_exp_avg_sqs)\n\u001b[1;32m    580\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 581\u001b[0m     exp_avg_sq_sqrt \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_foreach_sqrt\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice_exp_avg_sqs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    583\u001b[0m torch\u001b[38;5;241m.\u001b[39m_foreach_div_(exp_avg_sq_sqrt, bias_correction2_sqrt)\n\u001b[1;32m    584\u001b[0m torch\u001b[38;5;241m.\u001b[39m_foreach_add_(exp_avg_sq_sqrt, eps)\n",
                        "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
                    ]
                }
            ],
            "source": [
                "study = optuna.create_study(direction='minimize')\n",
                "study.optimize(objective, n_trials=100)\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 25,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Number of finished trials: 100\n",
                        "Best trial:\n",
                        "  Value: 1.4034918546676636\n",
                        "  Params: \n",
                        "    hidden_size: 244\n",
                        "    num_layers: 3\n",
                        "    fc1_size: 56\n",
                        "    fc2_size: 66\n",
                        "    bidirectional: True\n",
                        "    dropout: 0.2897216770797896\n",
                        "    learning_rate: 0.0007513939934499025\n",
                        "    batch_size: 32\n"
                    ]
                }
            ],
            "source": [
                "print(f\"Number of finished trials: {len(study.trials)}\")\n",
                "print(\"Best trial:\")\n",
                "trial = study.best_trial\n",
                "print(f\"  Value: {trial.value}\")\n",
                "print(f\"  Params: \")\n",
                "for key, value in trial.params.items():\n",
                "    print(f\"    {key}: {value}\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 32,
            "metadata": {},
            "outputs": [],
            "source": [
                "# best_params = study.best_params\n",
                "best_params = {\n",
                "    \"hidden_size\": 244,\n",
                "    \"num_layers\": 3,\n",
                "    \"fc1_size\": 56,\n",
                "    \"fc2_size\": 66,\n",
                "    \"bidirectional\": True,\n",
                "    \"dropout\": 0.2897216770797896,\n",
                "    \"learning_rate\": 0.0007513939934499025,\n",
                "    \"batch_size\": 32,\n",
                "}\n",
                "\n",
                "final_config = ModelConfig(\n",
                "    input_size=50,  # Assuming this is fixed\n",
                "    hidden_size=best_params[\"hidden_size\"],\n",
                "    num_layers=best_params[\"num_layers\"],\n",
                "    fc1_size=best_params[\"fc1_size\"],\n",
                "    fc2_size=best_params[\"fc2_size\"],\n",
                "    bidirectional=best_params[\"bidirectional\"],\n",
                "    dropout=best_params[\"dropout\"],\n",
                ")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 33,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Training model with suffix: 20240824_213120\n",
                        "Epoch 1/1000, Train Loss: 80.3617, Val Loss: 49.6755\n",
                        "New best model saved with validation loss: 49.6755\n",
                        "Epoch 2/1000, Train Loss: 53.0394, Val Loss: 49.5337\n",
                        "New best model saved with validation loss: 49.5337\n",
                        "Epoch 30/1000, Train Loss: 48.6473, Val Loss: 48.2407\n",
                        "New best model saved with validation loss: 48.2407\n",
                        "Epoch 31/1000, Train Loss: 47.0576, Val Loss: 47.9092\n",
                        "New best model saved with validation loss: 47.9092\n",
                        "Epoch 34/1000, Train Loss: 45.0096, Val Loss: 47.3889\n",
                        "New best model saved with validation loss: 47.3889\n",
                        "Epoch 39/1000, Train Loss: 42.0234, Val Loss: 46.5634\n",
                        "New best model saved with validation loss: 46.5634\n",
                        "Epoch 139/1000, Train Loss: 4.8286, Val Loss: 56.6521Early stopping triggered after 139 epochs\n"
                    ]
                }
            ],
            "source": [
                "final_model = AsteroidLSTM(final_config)\n",
                "\n",
                "best_model = train_model(\n",
                "    final_model,\n",
                "    X_train,\n",
                "    y_train,\n",
                "    X_val,\n",
                "    y_val,\n",
                "    batch_size=best_params[\"batch_size\"],\n",
                "    num_epochs=1000,\n",
                "    learning_rate=best_params[\"learning_rate\"],\n",
                "    model_suffix=datetime.now().strftime(\"%Y%m%d_%H%M%S\"),\n",
                ")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 34,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Test MSE: 62.0943\n",
                        "Test RMSE: 7.8800\n",
                        "Test MAE: 5.4855\n",
                        "Test R2 Score: 0.0184\n",
                        "Test MSE: 62.0943\n",
                        "Test RMSE: 7.8800\n",
                        "Test MAE: 5.4855\n",
                        "Test R2 Score: 0.0184\n"
                    ]
                }
            ],
            "source": [
                "mse, rmse, mae, r2, predictions, true_values = evaluate_model(best_model, X_test, y_test, best_params[\"batch_size\"])\n",
                "print(f\"Test MSE: {mse:.4f}\")\n",
                "print(f\"Test RMSE: {rmse:.4f}\")\n",
                "print(f\"Test MAE: {mae:.4f}\")\n",
                "print(f\"Test R2 Score: {r2:.4f}\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 36,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "True:  17.5418, Predicted:  13.9660\n",
                        "True:  13.8256, Predicted:  13.8937\n",
                        "True:  16.2058, Predicted:   7.8610\n",
                        "True:  20.6520, Predicted:  14.3501\n",
                        "True:   4.6544, Predicted:   7.2590\n",
                        "True:   5.5296, Predicted:  10.8575\n",
                        "True:   6.0483, Predicted:  16.1846\n",
                        "True:   8.8422, Predicted:   9.1639\n",
                        "True:   9.7250, Predicted:  12.8877\n",
                        "True:   3.8382, Predicted:  13.8438\n",
                        "True:  13.4842, Predicted:   7.7136\n",
                        "True:   7.6203, Predicted:   7.3665\n",
                        "True:   3.2556, Predicted:   7.8465\n",
                        "True:  12.7301, Predicted:   7.8382\n",
                        "True:  15.1533, Predicted:  10.0186\n",
                        "True:  18.1482, Predicted:  16.2663\n",
                        "True:   4.0120, Predicted:   8.0478\n",
                        "True:   3.5740, Predicted:  11.5704\n",
                        "True:  16.4461, Predicted:  14.1071\n",
                        "True:  19.9941, Predicted:   8.1373\n",
                        "True:  14.7956, Predicted:  15.9068\n",
                        "True:   3.7788, Predicted:  11.9235\n",
                        "True:  11.4065, Predicted:  11.2736\n",
                        "True:  39.0847, Predicted:   9.5157\n",
                        "True:   6.4109, Predicted:  12.4735\n",
                        "True:   3.5646, Predicted:   9.3334\n",
                        "True:   5.8869, Predicted:   8.2802\n",
                        "True:  12.1657, Predicted:   9.1392\n",
                        "True:  32.8430, Predicted:  10.9093\n",
                        "True:   8.0173, Predicted:   7.5467\n"
                    ]
                }
            ],
            "source": [
                "for i in range(30):\n",
                "    print(f\"True: {true_values[i]:8.4f}, Predicted: {predictions[i]:8.4f}\")\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": []
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "mgr",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.11.9"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 2
}
