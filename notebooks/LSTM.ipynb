{
    "cells": [
        {
            "cell_type": "code",
            "execution_count": 1,
            "metadata": {},
            "outputs": [],
            "source": [
                "from datetime import datetime\n",
                "from pathlib import Path\n",
                "\n",
                "import matplotlib.pyplot as plt\n",
                "import seaborn as sns\n",
                "import torch\n",
                "import torch.nn as nn\n",
                "from constants import DATA_DIR\n",
                "from torch.utils.data import DataLoader, Dataset\n",
                "\n",
                "from astrofit.model import Asteroid\n",
                "from astrofit.utils import AsteroidLoader, LightcurveBinner\n",
                "from astrofit.utils.enums import BinningMethod\n",
                "\n",
                "sns.set_theme(style=\"darkgrid\")\n",
                "plt.rcParams[\"figure.figsize\"] = (14, 6)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 2,
            "metadata": {},
            "outputs": [
                {
                    "ename": "AssertionError",
                    "evalue": "CUDA is not available",
                    "output_type": "error",
                    "traceback": [
                        "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
                        "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
                        "Cell \u001b[0;32mIn[2], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mcuda\u001b[38;5;241m.\u001b[39mis_available(), \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCUDA is not available\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
                        "\u001b[0;31mAssertionError\u001b[0m: CUDA is not available"
                    ]
                }
            ],
            "source": [
                "assert torch.cuda.is_available(), \"CUDA is not available\""
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 4,
            "metadata": {},
            "outputs": [],
            "source": [
                "PERIOD_FILE = \"period.txt\"\n",
                "C_G_S = \"\\033[1;32m\"\n",
                "C_Y_S = \"\\033[1;33m\"\n",
                "C_E = \"\\033[0m\"\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 3,
            "metadata": {},
            "outputs": [],
            "source": [
                "asteroid_loader = AsteroidLoader(DATA_DIR)\n",
                "lightcurve_binner = LightcurveBinner()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 5,
            "metadata": {},
            "outputs": [],
            "source": [
                "asteroid_name = \"Eunomia\"  # Interamnia, Eros, Ceres, Eunomia\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 6,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/plain": [
                            "Asteroid(id=15, name=Eunomia, period=6.082754, lightcurves=109)"
                        ]
                    },
                    "execution_count": 6,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "asteroid = asteroid_loader.load_asteroid(asteroid_name)\n",
                "asteroid"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 8,
            "metadata": {},
            "outputs": [],
            "source": [
                "bins = lightcurve_binner.bin_lightcurves_from_asteroid(\n",
                "    asteroid,\n",
                "    max_time_diff=30,\n",
                "    binning_method=BinningMethod.FIRST_TO_FIRST_DIFF,\n",
                "    min_bin_size=3,\n",
                ")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 9,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        " 0 - \u001b[1;33m 3\u001b[0m lcs from 2435462.58 to 2435468.70 \u001b[1;32m( 6.12 days)\u001b[0m\n",
                        " 1 - \u001b[1;33m 3\u001b[0m lcs from 2442103.37 to 2442130.40 \u001b[1;32m(27.04 days)\u001b[0m\n",
                        " 2 - \u001b[1;33m 5\u001b[0m lcs from 2442149.30 to 2442158.36 \u001b[1;32m( 9.06 days)\u001b[0m\n",
                        " 3 - \u001b[1;33m 6\u001b[0m lcs from 2444912.26 to 2444941.00 \u001b[1;32m(28.74 days)\u001b[0m\n",
                        " 4 - \u001b[1;33m 3\u001b[0m lcs from 2445363.86 to 2445388.76 \u001b[1;32m(24.89 days)\u001b[0m\n",
                        " 5 - \u001b[1;33m 3\u001b[0m lcs from 2445831.84 to 2445858.85 \u001b[1;32m(27.01 days)\u001b[0m\n",
                        " 6 - \u001b[1;33m 4\u001b[0m lcs from 2446345.58 to 2446363.77 \u001b[1;32m(18.19 days)\u001b[0m\n",
                        " 7 - \u001b[1;33m 9\u001b[0m lcs from 2453886.48 to 2453897.63 \u001b[1;32m(11.15 days)\u001b[0m\n",
                        " 8 - \u001b[1;33m 9\u001b[0m lcs from 2454934.46 to 2454964.42 \u001b[1;32m(29.95 days)\u001b[0m\n",
                        " 9 - \u001b[1;33m 9\u001b[0m lcs from 2454965.20 to 2454995.33 \u001b[1;32m(30.13 days)\u001b[0m\n",
                        "10 - \u001b[1;33m15\u001b[0m lcs from 2455936.37 to 2455953.49 \u001b[1;32m(17.12 days)\u001b[0m\n",
                        "11 - \u001b[1;33m13\u001b[0m lcs from 2456303.62 to 2456327.77 \u001b[1;32m(24.15 days)\u001b[0m\n",
                        "12 - \u001b[1;33m 4\u001b[0m lcs from 2458284.58 to 2458295.67 \u001b[1;32m(11.09 days)\u001b[0m\n"
                    ]
                }
            ],
            "source": [
                "for ind, _bin in enumerate(bins):\n",
                "    first_JD = _bin[0].first_JD\n",
                "    last_JD = _bin[-1].last_JD\n",
                "\n",
                "    duration = last_JD - first_JD\n",
                "    lc_range = f\"{duration:5.2f} days\"\n",
                "    if duration < 1:\n",
                "        lc_range += f\" - {duration * 24:.2f} hours\"\n",
                "\n",
                "    print(\n",
                "        f\"{ind:2} - {C_Y_S}{len(_bin):2}{C_E} lcs from {first_JD:.2f} to {last_JD:.2f} {C_G_S}({lc_range}){C_E}\"\n",
                "    )"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# TODO:\n",
                "# - sprawdzić jak działa LSTM dokładniej i co jest outputem :v\n",
                "# - poddać krzywe do analizy Fourierowskiej (każda krzywa osobno i dostaję X elementów), może być zrobione w binach\n",
                "# - przerzucić przez LSTMa i z każdego bina zagregować te wyjścia - na przykład średnią\n",
                "# - przerzucić to nam sam koniec przez jaką warstwę FC i zwrócić wynik"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 10,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "- 3 lightcurves\n",
                        "  - 66 points\n",
                        "  - 90 points\n",
                        "  - 24 points\n",
                        "- 3 lightcurves\n",
                        "  - 70 points\n",
                        "  - 55 points\n",
                        "  - 29 points\n",
                        "- 5 lightcurves\n",
                        "  - 46 points\n",
                        "  - 20 points\n",
                        "  - 30 points\n",
                        "  - 29 points\n",
                        "  - 21 points\n",
                        "- 6 lightcurves\n",
                        "  - 64 points\n",
                        "  - 44 points\n",
                        "  - 7 points\n",
                        "  - 14 points\n",
                        "  - 33 points\n",
                        "  - 19 points\n",
                        "- 3 lightcurves\n",
                        "  - 6 points\n",
                        "  - 25 points\n",
                        "  - 18 points\n",
                        "- 3 lightcurves\n",
                        "  - 13 points\n",
                        "  - 42 points\n",
                        "  - 11 points\n",
                        "- 4 lightcurves\n",
                        "  - 36 points\n",
                        "  - 37 points\n",
                        "  - 29 points\n",
                        "  - 14 points\n",
                        "- 9 lightcurves\n",
                        "  - 37 points\n",
                        "  - 36 points\n",
                        "  - 45 points\n",
                        "  - 29 points\n",
                        "  - 49 points\n",
                        "  - 54 points\n",
                        "  - 62 points\n",
                        "  - 61 points\n",
                        "  - 113 points\n",
                        "- 9 lightcurves\n",
                        "  - 78 points\n",
                        "  - 116 points\n",
                        "  - 50 points\n",
                        "  - 39 points\n",
                        "  - 46 points\n",
                        "  - 16 points\n",
                        "  - 51 points\n",
                        "  - 57 points\n",
                        "  - 71 points\n",
                        "- 9 lightcurves\n",
                        "  - 48 points\n",
                        "  - 76 points\n",
                        "  - 75 points\n",
                        "  - 61 points\n",
                        "  - 50 points\n",
                        "  - 57 points\n",
                        "  - 67 points\n",
                        "  - 44 points\n",
                        "  - 52 points\n",
                        "- 15 lightcurves\n",
                        "  - 226 points\n",
                        "  - 143 points\n",
                        "  - 228 points\n",
                        "  - 193 points\n",
                        "  - 201 points\n",
                        "  - 169 points\n",
                        "  - 212 points\n",
                        "  - 207 points\n",
                        "  - 194 points\n",
                        "  - 145 points\n",
                        "  - 79 points\n",
                        "  - 141 points\n",
                        "  - 183 points\n",
                        "  - 123 points\n",
                        "  - 163 points\n",
                        "- 13 lightcurves\n",
                        "  - 243 points\n",
                        "  - 214 points\n",
                        "  - 259 points\n",
                        "  - 159 points\n",
                        "  - 267 points\n",
                        "  - 192 points\n",
                        "  - 279 points\n",
                        "  - 33 points\n",
                        "  - 315 points\n",
                        "  - 434 points\n",
                        "  - 447 points\n",
                        "  - 356 points\n",
                        "  - 355 points\n",
                        "- 4 lightcurves\n",
                        "  - 70 points\n",
                        "  - 62 points\n",
                        "  - 89 points\n",
                        "  - 121 points\n"
                    ]
                }
            ],
            "source": [
                "for lc in bins:\n",
                "    print(f\"- {len(lc)} lightcurves\")\n",
                "    for points in lc:\n",
                "        print(f\"  - {len(points)} points\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 11,
            "metadata": {},
            "outputs": [],
            "source": [
                "class AsteroidDataset(Dataset):\n",
                "    \"\"\"\n",
                "    Dataset containing asteroids, each composed of Lightcurve sessions\n",
                "    \"\"\"\n",
                "\n",
                "    def __init__(self, asteroids: list[Asteroid]):\n",
                "        self.asteroids = self._extract_points(asteroids)\n",
                "        self.periods = self._extract_periods(asteroids)\n",
                "\n",
                "    def __len__(self):\n",
                "        return len(self.asteroids)\n",
                "\n",
                "    def __getitem__(self, idx):\n",
                "        return self.asteroids[idx], self.periods[idx]\n",
                "\n",
                "    def _extract_points(self, asteroids: list[Asteroid]) -> list[list[list[torch.Tensor]]]:\n",
                "        parsed_asteroids = []\n",
                "        for asteroid in asteroids:\n",
                "            bins = lightcurve_binner.bin_lightcurves_from_asteroid(\n",
                "                asteroid,\n",
                "                max_time_diff=30,\n",
                "                binning_method=BinningMethod.FIRST_TO_FIRST_DIFF,\n",
                "                min_bin_size=3,\n",
                "            )\n",
                "            sessions = []\n",
                "            for session in bins:\n",
                "                session_points = []\n",
                "                for lightcurve in session:\n",
                "                    data_points = [(point.JD, point.brightness) for point in lightcurve.points]\n",
                "                    session_points.append(torch.tensor(data_points, dtype=torch.float32))\n",
                "\n",
                "                sessions.append(session_points)\n",
                "\n",
                "            parsed_asteroids.append(sessions)\n",
                "\n",
                "        return parsed_asteroids\n",
                "\n",
                "    def _extract_periods(self, asteroids: list[Asteroid]) -> list[float]:\n",
                "        return [asteroid.period for asteroid in asteroids]\n",
                "\n",
                "\n",
                "def collate_fn(asteroid_batch):\n",
                "    assert len(asteroid_batch) == 1, \"Batch size must be 1\"\n",
                "\n",
                "    asteroid, period = asteroid_batch[0]\n",
                "\n",
                "    max_lightcurves = max(len(session) for session in asteroid)\n",
                "    max_points = max(max(lightcurve.size(0) for lightcurve in session) for session in asteroid)\n",
                "\n",
                "    padded_sessions = []\n",
                "    for session in asteroid:\n",
                "        padded_lightcurves = [\n",
                "            (\n",
                "                torch.cat([lightcurve, torch.zeros((max_points - lightcurve.size(0), 2))])\n",
                "                if lightcurve.size(0) < max_points\n",
                "                else lightcurve\n",
                "            )\n",
                "            for lightcurve in session\n",
                "        ]\n",
                "        padded_lightcurves = torch.stack(padded_lightcurves)\n",
                "        num_padding_lightcurves = max_lightcurves - padded_lightcurves.size(0)\n",
                "        if num_padding_lightcurves > 0:\n",
                "            padding = torch.zeros((num_padding_lightcurves, max_points, 2))\n",
                "            padded_lightcurves = torch.cat((padded_lightcurves, padding), dim=0)\n",
                "\n",
                "        padded_sessions.append(padded_lightcurves)\n",
                "\n",
                "    padded_asteroid = torch.stack(padded_sessions)\n",
                "    period_tensor = torch.tensor([period], dtype=torch.float32)\n",
                "\n",
                "    padded_asteroid = padded_asteroid.unsqueeze(0)  # Add batch dimension\n",
                "\n",
                "    return padded_asteroid, period_tensor"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 12,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/plain": [
                            "[Asteroid(id=54, name=Alexandra, period=7.02264, lightcurves=38),\n",
                            " Asteroid(id=82, name=Alkmene, period=13.00079, lightcurves=16),\n",
                            " Asteroid(id=29, name=Amphitrite, period=5.39012, lightcurves=66),\n",
                            " Asteroid(id=64, name=Angelina, period=8.75033, lightcurves=22),\n",
                            " Asteroid(id=43, name=Ariadne, period=5.761987, lightcurves=43),\n",
                            " Asteroid(id=5, name=Astraea, period=16.80059, lightcurves=25),\n",
                            " Asteroid(id=36, name=Atalante, period=9.92692, lightcurves=31),\n",
                            " Asteroid(id=94, name=Aurora, period=7.226189, lightcurves=22),\n",
                            " Asteroid(id=63, name=Ausonia, period=9.29759, lightcurves=16),\n",
                            " Asteroid(id=28, name=Bellona, period=15.70785, lightcurves=24),\n",
                            " Asteroid(id=1, name=Ceres, period=9.074173, lightcurves=46),\n",
                            " Asteroid(id=34, name=Circe, period=12.17458, lightcurves=17),\n",
                            " Asteroid(id=65, name=Cybele, period=6.081435, lightcurves=62),\n",
                            " Asteroid(id=41, name=Daphne, period=5.987981, lightcurves=49),\n",
                            " Asteroid(id=99, name=Dike, period=18.11914, lightcurves=30),\n",
                            " Asteroid(id=48, name=Doris, period=11.8901, lightcurves=32),\n",
                            " Asteroid(id=13, name=Egeria, period=7.046665, lightcurves=38),\n",
                            " Asteroid(id=45, name=Eugenia, period=5.699152, lightcurves=101),\n",
                            " Asteroid(id=15, name=Eunomia, period=6.082754, lightcurves=109),\n",
                            " Asteroid(id=31, name=Euphrosyne, period=5.529594, lightcurves=64),\n",
                            " Asteroid(id=52, name=Europa, period=5.629959, lightcurves=49),\n",
                            " Asteroid(id=79, name=Eurynome, period=5.977722, lightcurves=39),\n",
                            " Asteroid(id=27, name=Euterpe, period=10.40828, lightcurves=55),\n",
                            " Asteroid(id=72, name=Feronia, period=8.09068, lightcurves=23),\n",
                            " Asteroid(id=37, name=Fides, period=7.332527, lightcurves=27),\n",
                            " Asteroid(id=8, name=Flora, period=12.86667, lightcurves=54),\n",
                            " Asteroid(id=19, name=Fortuna, period=7.443224, lightcurves=48),\n",
                            " Asteroid(id=76, name=Freia, period=9.97306, lightcurves=38),\n",
                            " Asteroid(id=40, name=Harmonia, period=8.908485, lightcurves=23),\n",
                            " Asteroid(id=6, name=Hebe, period=7.274467, lightcurves=142),\n",
                            " Asteroid(id=69, name=Hesperia, period=5.65534, lightcurves=38),\n",
                            " Asteroid(id=46, name=Hestia, period=21.0401, lightcurves=33),\n",
                            " Asteroid(id=10, name=Hygiea, period=13.82559, lightcurves=166),\n",
                            " Asteroid(id=98, name=Ianthe, period=16.48013, lightcurves=10),\n",
                            " Asteroid(id=85, name=Io, period=6.874784, lightcurves=29),\n",
                            " Asteroid(id=14, name=Irene, period=15.02987, lightcurves=33),\n",
                            " Asteroid(id=7, name=Iris, period=7.138844, lightcurves=39),\n",
                            " Asteroid(id=42, name=Isis, period=13.58364, lightcurves=37),\n",
                            " Asteroid(id=89, name=Julia, period=11.388336, lightcurves=37),\n",
                            " Asteroid(id=3, name=Juno, period=7.20953, lightcurves=28),\n",
                            " Asteroid(id=22, name=Kalliope, period=4.1482015, lightcurves=155),\n",
                            " Asteroid(id=53, name=Kalypso, period=9.03506, lightcurves=41),\n",
                            " Asteroid(id=97, name=Klotho, period=35.251, lightcurves=28),\n",
                            " Asteroid(id=73, name=Klytia, period=8.28307, lightcurves=26),\n",
                            " Asteroid(id=39, name=Laetitia, period=5.138238, lightcurves=68),\n",
                            " Asteroid(id=38, name=Leda, period=12.83613, lightcurves=30),\n",
                            " Asteroid(id=68, name=Leto, period=14.84547, lightcurves=16),\n",
                            " Asteroid(id=35, name=Leukothea, period=31.9009, lightcurves=53),\n",
                            " Asteroid(id=21, name=Lutetia, period=8.168271, lightcurves=50),\n",
                            " Asteroid(id=66, name=Maja, period=9.73572, lightcurves=17),\n",
                            " Asteroid(id=20, name=Massalia, period=8.09902, lightcurves=18),\n",
                            " Asteroid(id=56, name=Melete, period=18.14818, lightcurves=38),\n",
                            " Asteroid(id=18, name=Melpomene, period=11.57031, lightcurves=176),\n",
                            " Asteroid(id=9, name=Metis, period=5.079177, lightcurves=38),\n",
                            " Asteroid(id=93, name=Minerva, period=5.981768, lightcurves=34),\n",
                            " Asteroid(id=51, name=Nemausa, period=7.78484, lightcurves=135),\n",
                            " Asteroid(id=71, name=Niobe, period=35.8521, lightcurves=50),\n",
                            " Asteroid(id=44, name=Nysa, period=6.421417, lightcurves=72),\n",
                            " Asteroid(id=2, name=Pallas, period=7.81322, lightcurves=61),\n",
                            " Asteroid(id=55, name=Pandora, period=4.804043, lightcurves=36),\n",
                            " Asteroid(id=70, name=Panopaea, period=15.80439, lightcurves=122),\n",
                            " Asteroid(id=11, name=Parthenope, period=13.72205, lightcurves=138),\n",
                            " Asteroid(id=25, name=Phocaea, period=9.935397, lightcurves=29),\n",
                            " Asteroid(id=33, name=Polyhymnia, period=18.60888, lightcurves=49),\n",
                            " Asteroid(id=32, name=Pomona, period=9.44767, lightcurves=18),\n",
                            " Asteroid(id=26, name=Proserpina, period=13.10977, lightcurves=30),\n",
                            " Asteroid(id=16, name=Psyche, period=4.195948, lightcurves=209),\n",
                            " Asteroid(id=80, name=Sappho, period=14.03086, lightcurves=16),\n",
                            " Asteroid(id=87, name=Sylvia, period=5.183641, lightcurves=41),\n",
                            " Asteroid(id=23, name=Thalia, period=12.31241, lightcurves=50),\n",
                            " Asteroid(id=24, name=Themis, period=8.37419, lightcurves=112),\n",
                            " Asteroid(id=17, name=Thetis, period=12.26603, lightcurves=53),\n",
                            " Asteroid(id=88, name=Thisbe, period=6.041319, lightcurves=188),\n",
                            " Asteroid(id=30, name=Urania, period=13.68717, lightcurves=18),\n",
                            " Asteroid(id=4, name=Vesta, period=5.342124, lightcurves=169),\n",
                            " Asteroid(id=12, name=Victoria, period=8.66034, lightcurves=54),\n",
                            " Asteroid(id=50, name=Virginia, period=14.31233, lightcurves=45)]"
                        ]
                    },
                    "execution_count": 12,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "asteroids = []\n",
                "for key in asteroid_loader.available_asteroids:\n",
                "    if key in (\"Interamnia\", \"Eros\"):\n",
                "        continue\n",
                "\n",
                "    asteroid = asteroid_loader.load_asteroid(key)\n",
                "    if len(asteroid.lightcurves) < 10:\n",
                "        continue\n",
                "\n",
                "    asteroids.append(asteroid)\n",
                "\n",
                "asteroids"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 13,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/plain": [
                            "[Asteroid(id=704, name=Interamnia, period=8.712337, lightcurves=188),\n",
                            " Asteroid(id=433, name=Eros, period=5.27025528, lightcurves=118)]"
                        ]
                    },
                    "execution_count": 13,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "test_asteroids = [asteroid_loader.load_asteroid(\"Interamnia\"), asteroid_loader.load_asteroid(\"Eros\")]\n",
                "test_asteroids"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 14,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "tensor([7.0226])\n",
                        "torch.Size([1, 8, 5, 345, 2]) torch.Size([1])\n",
                        "tensor([13.0008])\n",
                        "torch.Size([1, 2, 6, 15, 2]) torch.Size([1])\n",
                        "tensor([5.3901])\n",
                        "torch.Size([1, 9, 9, 174, 2]) torch.Size([1])\n",
                        "tensor([8.7503])\n",
                        "torch.Size([1, 4, 6, 74, 2]) torch.Size([1])\n",
                        "tensor([5.7620])\n",
                        "torch.Size([1, 8, 9, 149, 2]) torch.Size([1])\n",
                        "tensor([16.8006])\n",
                        "torch.Size([1, 3, 7, 44, 2]) torch.Size([1])\n",
                        "tensor([9.9269])\n",
                        "torch.Size([1, 4, 11, 369, 2]) torch.Size([1])\n",
                        "tensor([7.2262])\n",
                        "torch.Size([1, 3, 4, 42, 2]) torch.Size([1])\n",
                        "tensor([9.2976])\n",
                        "torch.Size([1, 2, 5, 331, 2]) torch.Size([1])\n",
                        "tensor([15.7079])\n",
                        "torch.Size([1, 4, 7, 381, 2]) torch.Size([1])\n",
                        "tensor([9.0742])\n",
                        "torch.Size([1, 7, 8, 465, 2]) torch.Size([1])\n",
                        "tensor([12.1746])\n",
                        "torch.Size([1, 3, 8, 220, 2]) torch.Size([1])\n",
                        "tensor([6.0814])\n",
                        "torch.Size([1, 10, 6, 467, 2]) torch.Size([1])\n",
                        "tensor([5.9880])\n",
                        "torch.Size([1, 7, 7, 651, 2]) torch.Size([1])\n",
                        "tensor([18.1191])\n",
                        "torch.Size([1, 4, 10, 402, 2]) torch.Size([1])\n",
                        "tensor([11.8901])\n",
                        "torch.Size([1, 2, 18, 591, 2]) torch.Size([1])\n",
                        "tensor([7.0467])\n",
                        "torch.Size([1, 4, 10, 469, 2]) torch.Size([1])\n",
                        "tensor([5.6992])\n",
                        "torch.Size([1, 17, 9, 416, 2]) torch.Size([1])\n",
                        "tensor([6.0828])\n",
                        "torch.Size([1, 13, 15, 447, 2]) torch.Size([1])\n",
                        "tensor([5.5296])\n",
                        "torch.Size([1, 5, 35, 864, 2]) torch.Size([1])\n",
                        "tensor([5.6300])\n",
                        "torch.Size([1, 6, 10, 298, 2]) torch.Size([1])\n",
                        "tensor([5.9777])\n",
                        "torch.Size([1, 5, 8, 196, 2]) torch.Size([1])\n",
                        "tensor([10.4083])\n",
                        "torch.Size([1, 7, 14, 270, 2]) torch.Size([1])\n",
                        "tensor([8.0907])\n",
                        "torch.Size([1, 4, 8, 196, 2]) torch.Size([1])\n",
                        "tensor([7.3325])\n",
                        "torch.Size([1, 5, 7, 135, 2]) torch.Size([1])\n",
                        "tensor([12.8667])\n",
                        "torch.Size([1, 9, 6, 318, 2]) torch.Size([1])\n",
                        "tensor([7.4432])\n",
                        "torch.Size([1, 10, 6, 196, 2]) torch.Size([1])\n",
                        "tensor([9.9731])\n",
                        "torch.Size([1, 7, 5, 121, 2]) torch.Size([1])\n",
                        "tensor([8.9085])\n",
                        "torch.Size([1, 5, 5, 436, 2]) torch.Size([1])\n",
                        "tensor([7.2745])\n",
                        "torch.Size([1, 13, 27, 200, 2]) torch.Size([1])\n",
                        "tensor([5.6553])\n",
                        "torch.Size([1, 3, 20, 45, 2]) torch.Size([1])\n",
                        "tensor([21.0401])\n",
                        "torch.Size([1, 6, 7, 481, 2]) torch.Size([1])\n",
                        "tensor([13.8256])\n",
                        "torch.Size([1, 19, 15, 1549, 2]) torch.Size([1])\n",
                        "tensor([16.4801])\n",
                        "torch.Size([1, 2, 6, 382, 2]) torch.Size([1])\n",
                        "tensor([6.8748])\n",
                        "torch.Size([1, 5, 7, 102, 2]) torch.Size([1])\n",
                        "tensor([15.0299])\n",
                        "torch.Size([1, 5, 7, 411, 2]) torch.Size([1])\n",
                        "tensor([7.1388])\n",
                        "torch.Size([1, 3, 4, 75, 2]) torch.Size([1])\n",
                        "tensor([13.5836])\n",
                        "torch.Size([1, 7, 9, 210, 2]) torch.Size([1])\n",
                        "tensor([11.3883])\n",
                        "torch.Size([1, 6, 9, 726, 2]) torch.Size([1])\n",
                        "tensor([7.2095])\n",
                        "torch.Size([1, 4, 6, 85, 2]) torch.Size([1])\n",
                        "tensor([4.1482])\n",
                        "torch.Size([1, 20, 16, 510, 2]) torch.Size([1])\n",
                        "tensor([9.0351])\n",
                        "torch.Size([1, 7, 8, 295, 2]) torch.Size([1])\n",
                        "tensor([35.2510])\n",
                        "torch.Size([1, 3, 11, 47, 2]) torch.Size([1])\n",
                        "tensor([8.2831])\n",
                        "torch.Size([1, 4, 8, 131, 2]) torch.Size([1])\n",
                        "tensor([5.1382])\n",
                        "torch.Size([1, 8, 6, 132, 2]) torch.Size([1])\n",
                        "tensor([12.8361])\n",
                        "torch.Size([1, 5, 8, 247, 2]) torch.Size([1])\n",
                        "tensor([14.8455])\n",
                        "torch.Size([1, 2, 9, 174, 2]) torch.Size([1])\n",
                        "tensor([31.9009])\n",
                        "torch.Size([1, 8, 13, 417, 2]) torch.Size([1])\n",
                        "tensor([8.1683])\n",
                        "torch.Size([1, 10, 6, 304, 2]) torch.Size([1])\n",
                        "tensor([9.7357])\n",
                        "torch.Size([1, 2, 5, 59, 2]) torch.Size([1])\n",
                        "tensor([8.0990])\n",
                        "torch.Size([1, 2, 4, 74, 2]) torch.Size([1])\n",
                        "tensor([18.1482])\n",
                        "torch.Size([1, 1, 37, 617, 2]) torch.Size([1])\n",
                        "tensor([11.5703])\n",
                        "torch.Size([1, 20, 18, 831, 2]) torch.Size([1])\n",
                        "tensor([5.0792])\n",
                        "torch.Size([1, 6, 6, 188, 2]) torch.Size([1])\n",
                        "tensor([5.9818])\n",
                        "torch.Size([1, 4, 6, 478, 2]) torch.Size([1])\n",
                        "tensor([7.7848])\n",
                        "torch.Size([1, 11, 25, 682, 2]) torch.Size([1])\n",
                        "tensor([35.8521])\n",
                        "torch.Size([1, 5, 24, 569, 2]) torch.Size([1])\n",
                        "tensor([6.4214])\n",
                        "torch.Size([1, 10, 10, 207, 2]) torch.Size([1])\n",
                        "tensor([7.8132])\n",
                        "torch.Size([1, 14, 5, 106, 2]) torch.Size([1])\n",
                        "tensor([4.8040])\n",
                        "torch.Size([1, 4, 8, 120, 2]) torch.Size([1])\n",
                        "tensor([15.8044])\n",
                        "torch.Size([1, 17, 23, 103, 2]) torch.Size([1])\n",
                        "tensor([13.7220])\n",
                        "torch.Size([1, 11, 30, 463, 2]) torch.Size([1])\n",
                        "tensor([9.9354])\n",
                        "torch.Size([1, 6, 5, 299, 2]) torch.Size([1])\n",
                        "tensor([18.6089])\n",
                        "torch.Size([1, 3, 31, 436, 2]) torch.Size([1])\n",
                        "tensor([9.4477])\n",
                        "torch.Size([1, 4, 4, 298, 2]) torch.Size([1])\n",
                        "tensor([13.1098])\n",
                        "torch.Size([1, 5, 12, 563, 2]) torch.Size([1])\n",
                        "tensor([4.1959])\n",
                        "torch.Size([1, 28, 24, 457, 2]) torch.Size([1])\n",
                        "tensor([14.0309])\n",
                        "torch.Size([1, 3, 4, 300, 2]) torch.Size([1])\n",
                        "tensor([5.1836])\n",
                        "torch.Size([1, 8, 7, 59, 2]) torch.Size([1])\n",
                        "tensor([12.3124])\n",
                        "torch.Size([1, 7, 7, 239, 2]) torch.Size([1])\n",
                        "tensor([8.3742])\n",
                        "torch.Size([1, 17, 11, 714, 2]) torch.Size([1])\n",
                        "tensor([12.2660])\n",
                        "torch.Size([1, 7, 14, 121, 2]) torch.Size([1])\n",
                        "tensor([6.0413])\n",
                        "torch.Size([1, 14, 60, 606, 2]) torch.Size([1])\n",
                        "tensor([13.6872])\n",
                        "torch.Size([1, 3, 7, 179, 2]) torch.Size([1])\n",
                        "tensor([5.3421])\n",
                        "torch.Size([1, 24, 17, 357, 2]) torch.Size([1])\n",
                        "tensor([8.6603])\n",
                        "torch.Size([1, 3, 45, 369, 2]) torch.Size([1])\n",
                        "tensor([14.3123])\n",
                        "torch.Size([1, 8, 8, 240, 2]) torch.Size([1])\n"
                    ]
                }
            ],
            "source": [
                "dataset = AsteroidDataset(asteroids)\n",
                "data_loader = DataLoader(dataset, batch_size=1, collate_fn=collate_fn)\n",
                "\n",
                "for batch in data_loader:\n",
                "    inputs, targets = batch\n",
                "    print(targets)\n",
                "    print(inputs.size(), targets.size())"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 15,
            "metadata": {},
            "outputs": [],
            "source": [
                "class AsteroidLSTM(nn.Module):\n",
                "    def __init__(self, input_size, hidden_size, num_layers, dropout=0.2):\n",
                "        super(AsteroidLSTM, self).__init__()\n",
                "        self.hidden_size = hidden_size\n",
                "        self.num_layers = num_layers\n",
                "        self.lstm = nn.LSTM(input_size, hidden_size, num_layers, batch_first=True, dropout=dropout)\n",
                "        self.fc = nn.Linear(hidden_size, 1)\n",
                "\n",
                "    def forward(self, x: torch.Tensor):\n",
                "        # Reshape x to (batch_size * num_sessions, num_lightcurves, input_size)\n",
                "        batch_size, num_sessions, num_lightcurves, num_points, num_features = x.size()\n",
                "        \n",
                "        # Flatten the num_points dimension while keeping the last dimension as input_size\n",
                "        x = x.view(batch_size * num_sessions, num_lightcurves * num_points, num_features)\n",
                "\n",
                "        # Pass through LSTM\n",
                "        h0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(x.device)\n",
                "        c0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(x.device)\n",
                " \n",
                "        out, _ = self.lstm(x, (h0, c0))\n",
                "\n",
                "        # Take the output from the last time step\n",
                "        out = out[:, -1, :]\n",
                "\n",
                "        # Reshape to (batch_size, num_sessions, hidden_size)\n",
                "        out = out.view(batch_size, num_sessions, -1)\n",
                "\n",
                "        # Aggregate the session outputs (e.g., mean)\n",
                "        out = torch.mean(out, dim=1)\n",
                "\n",
                "        # Pass through the fully connected layer\n",
                "        out = self.fc(out)\n",
                "\n",
                "        return out"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 16,
            "metadata": {},
            "outputs": [],
            "source": [
                "input_size = 2  # JD and brightness\n",
                "hidden_size = 32\n",
                "num_layers = 2\n",
                "dropout = 0.15"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 17,
            "metadata": {},
            "outputs": [
                {
                    "ename": "RuntimeError",
                    "evalue": "No CUDA GPUs are available",
                    "output_type": "error",
                    "traceback": [
                        "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
                        "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
                        "Cell \u001b[0;32mIn[17], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mAsteroidLSTM\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhidden_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_layers\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcuda\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      2\u001b[0m model\n",
                        "File \u001b[0;32m~/mambaforge/envs/mgr/lib/python3.11/site-packages/torch/nn/modules/module.py:915\u001b[0m, in \u001b[0;36mModule.cuda\u001b[0;34m(self, device)\u001b[0m\n\u001b[1;32m    898\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcuda\u001b[39m(\u001b[38;5;28mself\u001b[39m: T, device: Optional[Union[\u001b[38;5;28mint\u001b[39m, device]] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m T:\n\u001b[1;32m    899\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"Move all model parameters and buffers to the GPU.\u001b[39;00m\n\u001b[1;32m    900\u001b[0m \n\u001b[1;32m    901\u001b[0m \u001b[38;5;124;03m    This also makes associated parameters and buffers different objects. So\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    913\u001b[0m \u001b[38;5;124;03m        Module: self\u001b[39;00m\n\u001b[1;32m    914\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 915\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcuda\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
                        "File \u001b[0;32m~/mambaforge/envs/mgr/lib/python3.11/site-packages/torch/nn/modules/module.py:779\u001b[0m, in \u001b[0;36mModule._apply\u001b[0;34m(self, fn, recurse)\u001b[0m\n\u001b[1;32m    777\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m recurse:\n\u001b[1;32m    778\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchildren():\n\u001b[0;32m--> 779\u001b[0m         \u001b[43mmodule\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    781\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcompute_should_use_set_data\u001b[39m(tensor, tensor_applied):\n\u001b[1;32m    782\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39m_has_compatible_shallow_copy_type(tensor, tensor_applied):\n\u001b[1;32m    783\u001b[0m         \u001b[38;5;66;03m# If the new tensor has compatible tensor type as the existing tensor,\u001b[39;00m\n\u001b[1;32m    784\u001b[0m         \u001b[38;5;66;03m# the current behavior is to change the tensor in-place using `.data =`,\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    789\u001b[0m         \u001b[38;5;66;03m# global flag to let the user control whether they want the future\u001b[39;00m\n\u001b[1;32m    790\u001b[0m         \u001b[38;5;66;03m# behavior of overwriting the existing tensor or not.\u001b[39;00m\n",
                        "File \u001b[0;32m~/mambaforge/envs/mgr/lib/python3.11/site-packages/torch/nn/modules/rnn.py:217\u001b[0m, in \u001b[0;36mRNNBase._apply\u001b[0;34m(self, fn, recurse)\u001b[0m\n\u001b[1;32m    215\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_apply\u001b[39m(\u001b[38;5;28mself\u001b[39m, fn, recurse\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[1;32m    216\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_flat_weight_refs \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m--> 217\u001b[0m     ret \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrecurse\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    219\u001b[0m     \u001b[38;5;66;03m# Resets _flat_weights\u001b[39;00m\n\u001b[1;32m    220\u001b[0m     \u001b[38;5;66;03m# Note: be v. careful before removing this, as 3rd party device types\u001b[39;00m\n\u001b[1;32m    221\u001b[0m     \u001b[38;5;66;03m# likely rely on this behavior to properly .to() modules like LSTM.\u001b[39;00m\n\u001b[1;32m    222\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_init_flat_weights()\n",
                        "File \u001b[0;32m~/mambaforge/envs/mgr/lib/python3.11/site-packages/torch/nn/modules/module.py:804\u001b[0m, in \u001b[0;36mModule._apply\u001b[0;34m(self, fn, recurse)\u001b[0m\n\u001b[1;32m    800\u001b[0m \u001b[38;5;66;03m# Tensors stored in modules are graph leaves, and we don't want to\u001b[39;00m\n\u001b[1;32m    801\u001b[0m \u001b[38;5;66;03m# track autograd history of `param_applied`, so we have to use\u001b[39;00m\n\u001b[1;32m    802\u001b[0m \u001b[38;5;66;03m# `with torch.no_grad():`\u001b[39;00m\n\u001b[1;32m    803\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[0;32m--> 804\u001b[0m     param_applied \u001b[38;5;241m=\u001b[39m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparam\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    805\u001b[0m p_should_use_set_data \u001b[38;5;241m=\u001b[39m compute_should_use_set_data(param, param_applied)\n\u001b[1;32m    807\u001b[0m \u001b[38;5;66;03m# subclasses may have multiple child tensors so we need to use swap_tensors\u001b[39;00m\n",
                        "File \u001b[0;32m~/mambaforge/envs/mgr/lib/python3.11/site-packages/torch/nn/modules/module.py:915\u001b[0m, in \u001b[0;36mModule.cuda.<locals>.<lambda>\u001b[0;34m(t)\u001b[0m\n\u001b[1;32m    898\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcuda\u001b[39m(\u001b[38;5;28mself\u001b[39m: T, device: Optional[Union[\u001b[38;5;28mint\u001b[39m, device]] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m T:\n\u001b[1;32m    899\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"Move all model parameters and buffers to the GPU.\u001b[39;00m\n\u001b[1;32m    900\u001b[0m \n\u001b[1;32m    901\u001b[0m \u001b[38;5;124;03m    This also makes associated parameters and buffers different objects. So\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    913\u001b[0m \u001b[38;5;124;03m        Module: self\u001b[39;00m\n\u001b[1;32m    914\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 915\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_apply(\u001b[38;5;28;01mlambda\u001b[39;00m t: \u001b[43mt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcuda\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m)\n",
                        "File \u001b[0;32m~/mambaforge/envs/mgr/lib/python3.11/site-packages/torch/cuda/__init__.py:293\u001b[0m, in \u001b[0;36m_lazy_init\u001b[0;34m()\u001b[0m\n\u001b[1;32m    291\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCUDA_MODULE_LOADING\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m os\u001b[38;5;241m.\u001b[39menviron:\n\u001b[1;32m    292\u001b[0m     os\u001b[38;5;241m.\u001b[39menviron[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCUDA_MODULE_LOADING\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLAZY\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m--> 293\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_C\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_cuda_init\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    294\u001b[0m \u001b[38;5;66;03m# Some of the queued calls may reentrantly call _lazy_init();\u001b[39;00m\n\u001b[1;32m    295\u001b[0m \u001b[38;5;66;03m# we need to just return without initializing in that case.\u001b[39;00m\n\u001b[1;32m    296\u001b[0m \u001b[38;5;66;03m# However, we must not let any *other* threads in!\u001b[39;00m\n\u001b[1;32m    297\u001b[0m _tls\u001b[38;5;241m.\u001b[39mis_initializing \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
                        "\u001b[0;31mRuntimeError\u001b[0m: No CUDA GPUs are available"
                    ]
                }
            ],
            "source": [
                "model = AsteroidLSTM(input_size, hidden_size, num_layers).cuda()\n",
                "model"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 19,
            "metadata": {},
            "outputs": [],
            "source": [
                "criterion = nn.MSELoss()\n",
                "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
                "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=30, gamma=0.1)\n",
                "\n",
                "\n",
                "def train_model(\n",
                "    model: nn.Module,\n",
                "    data_loader: DataLoader,\n",
                "    optimizer: torch.optim.Optimizer,\n",
                "    criterion: nn.MSELoss, \n",
                "    num_epochs: int,\n",
                "    save_path: Path,\n",
                "):\n",
                "    model.train()\n",
                "    best_loss = float(\"inf\")\n",
                "\n",
                "    for epoch in range(num_epochs):\n",
                "        for inputs, targets in data_loader:\n",
                "            #inputs, targets = inputs.cuda(), targets.cuda()\n",
                "\n",
                "            outputs = model(inputs)\n",
                "            loss = criterion(outputs, targets.view(-1, 1))\n",
                "\n",
                "            optimizer.zero_grad()\n",
                "            loss.backward()\n",
                "            optimizer.step()\n",
                "\n",
                "        scheduler.step()\n",
                "        print(f\"Epoch [{epoch+1}/100], Loss: {loss.item():.4f}\")\n",
                "\n",
                "        if loss.item() < best_loss:\n",
                "            best_loss = loss.item()\n",
                "            torch.save(model.state_dict(), save_path)\n",
                "            print(f\"Model saved with loss {best_loss:.4f}\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 20,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Epoch [1/100], Loss: 12.3935\n",
                        "Model saved with loss 12.3935\n",
                        "Epoch [2/100], Loss: 10.5926\n",
                        "Model saved with loss 10.5926\n",
                        "Epoch [3/100], Loss: 10.3596\n",
                        "Model saved with loss 10.3596\n",
                        "Epoch [4/100], Loss: 10.3191\n",
                        "Model saved with loss 10.3191\n",
                        "Epoch [5/100], Loss: 10.3019\n",
                        "Model saved with loss 10.3019\n"
                    ]
                },
                {
                    "ename": "KeyboardInterrupt",
                    "evalue": "",
                    "output_type": "error",
                    "traceback": [
                        "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
                        "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
                        "Cell \u001b[0;32mIn[20], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m save_path \u001b[38;5;241m=\u001b[39m MODELS_DIR \u001b[38;5;241m/\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124masteroid_lstm_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdatetime\u001b[38;5;241m.\u001b[39mnow()\u001b[38;5;241m.\u001b[39mstrftime(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mY\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mm\u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m_\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mH\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mM\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mS\u001b[39m\u001b[38;5;124m'\u001b[39m)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.pt\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m----> 3\u001b[0m \u001b[43mtrain_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcriterion\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_epochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m100\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msave_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msave_path\u001b[49m\u001b[43m)\u001b[49m\n",
                        "Cell \u001b[0;32mIn[19], line 25\u001b[0m, in \u001b[0;36mtrain_model\u001b[0;34m(model, data_loader, optimizer, criterion, num_epochs, save_path)\u001b[0m\n\u001b[1;32m     22\u001b[0m     loss \u001b[38;5;241m=\u001b[39m criterion(outputs, targets\u001b[38;5;241m.\u001b[39mview(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m1\u001b[39m))\n\u001b[1;32m     24\u001b[0m     optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[0;32m---> 25\u001b[0m     \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     26\u001b[0m     optimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[1;32m     28\u001b[0m scheduler\u001b[38;5;241m.\u001b[39mstep()\n",
                        "File \u001b[0;32m~/miniforge3/envs/mgr/lib/python3.11/site-packages/torch/_tensor.py:525\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    515\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    517\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[1;32m    518\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    523\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[1;32m    524\u001b[0m     )\n\u001b[0;32m--> 525\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    526\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[1;32m    527\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
                        "File \u001b[0;32m~/miniforge3/envs/mgr/lib/python3.11/site-packages/torch/autograd/__init__.py:267\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    262\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[1;32m    264\u001b[0m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[1;32m    265\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    266\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 267\u001b[0m \u001b[43m_engine_run_backward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    268\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    269\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    270\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    271\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    272\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    273\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    274\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    275\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
                        "File \u001b[0;32m~/miniforge3/envs/mgr/lib/python3.11/site-packages/torch/autograd/graph.py:744\u001b[0m, in \u001b[0;36m_engine_run_backward\u001b[0;34m(t_outputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    742\u001b[0m     unregister_hooks \u001b[38;5;241m=\u001b[39m _register_logging_hooks_on_whole_graph(t_outputs)\n\u001b[1;32m    743\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 744\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    745\u001b[0m \u001b[43m        \u001b[49m\u001b[43mt_outputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[1;32m    746\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[1;32m    747\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    748\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m attach_logging_hooks:\n",
                        "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
                    ]
                }
            ],
            "source": [
                "save_path = MODELS_DIR / f\"asteroid_lstm_{datetime.now().strftime('%Y%m%d_%H%M%S')}.pt\"\n",
                "\n",
                "train_model(model, data_loader, optimizer, criterion, num_epochs=100, save_path=save_path)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "test_asteroids"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# save_path = MODELS_DIR / \"asteroid_lstm_20240516_005338.pt\""
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "dataset = AsteroidDataset(test_asteroids)\n",
                "test_loader = DataLoader(dataset, batch_size=1, collate_fn=collate_fn)\n",
                "\n",
                "best_model = AsteroidLSTM(input_size, hidden_size, num_layers, dropout)\n",
                "best_model.load_state_dict(torch.load(save_path))\n",
                "\n",
                "for ind, batch in enumerate(test_loader):\n",
                "    inputs, targets = batch\n",
                "\n",
                "    predictions = best_model(inputs)\n",
                "    print(f\"{test_asteroids[ind].name} predicted period: {predictions.item():.4f} - true period: {targets.item():.4f}\")\n",
                "    "
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "raise"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "def predict_model(model, data_loader):\n",
                "    model.eval()  # Set the model to evaluation mode\n",
                "    predictions = []\n",
                "    with torch.no_grad():  # No need to track gradients for predictions\n",
                "        for sessions, _ in data_loader:\n",
                "            outputs = model(sessions)  # Assuming sessions are formatted correctly\n",
                "            predictions.extend(outputs.detach().cpu().numpy())  # Store predictions\n",
                "    \n",
                "\n",
                "    return sum(predictions) / len(predictions)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "data_loader = DataLoader(dataset, batch_size=1, collate_fn=collate_fn, shuffle=False)\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "predicted_period, = predict_model(model, data_loader)\n",
                "true_period = dataset.periods[0]\n",
                "\n",
                "print(f\"True period: {true_period:.2f} hours\")\n",
                "print(f\"Predicted period: {predicted_period:.2f} hours\")\n",
                "\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": []
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "mgr",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.11.9"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 2
}
