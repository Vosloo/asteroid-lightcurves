{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import logging\n",
    "from collections import Counter\n",
    "from itertools import product\n",
    "from random import choice\n",
    "from time import perf_counter\n",
    "from typing import Literal, TypedDict\n",
    "\n",
    "import numpy as np\n",
    "from constants import DATA_DIR\n",
    "from tqdm import tqdm\n",
    "\n",
    "from astrofit.model import Asteroid, Lightcurve, LightcurveBin\n",
    "from astrofit.utils import (\n",
    "    AsteroidLoader,\n",
    "    FrequencyDecomposer,\n",
    "    LightcurveBinner,\n",
    "    LightcurvePlotter,\n",
    "    LightcurveSplitter,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.getLogger('matplotlib').setLevel(logging.WARNING)\n",
    "logger = logging.getLogger(\"freq\")\n",
    "\n",
    "logging.basicConfig(level=logging.DEBUG, format=\"%(asctime)s - %(name)s - %(levelname)s - %(message)s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "asteroid_loader = AsteroidLoader(DATA_DIR)\n",
    "frequency_decomposer = FrequencyDecomposer()\n",
    "lightcurve_binner = LightcurveBinner()\n",
    "lightcurve_plotter = LightcurvePlotter()\n",
    "lightcurve_splitter = LightcurveSplitter()\n",
    "\n",
    "FEATURES_DIR = DATA_DIR / \"features\"\n",
    "ASTEROIDS_JSON_FILE_NAME = \"asteroids_freq_data_{config_no}.json\"\n",
    "\n",
    "\n",
    "FEATURES_DIR.mkdir(exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5057/5057 [00:13<00:00, 380.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 5057 asteroids\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "MAX_PERIOD = 40\n",
    "\n",
    "asteroids: dict[str, Asteroid] = {}\n",
    "for asteroid_name in tqdm(asteroid_loader.available_asteroids):\n",
    "    ast_name = asteroid_loader.load_asteroid(asteroid_name)\n",
    "    # if asteroid.period > MAX_PERIOD:\n",
    "    #     continue\n",
    "\n",
    "    asteroids[ast_name.name] = ast_name\n",
    "\n",
    "print(f\"Loaded {len(asteroids)} asteroids\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  3.422438,   5.48469 ,   8.78678 ,  16.97036 ,  49.0198  ,\n",
       "       108.6936  ])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.percentile([asteroid.period for asteroid in asteroids.values()], [5, 25, 50, 75, 90, 95])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Config(TypedDict):\n",
    "    max_hours_diff: float\n",
    "    min_no_points: int\n",
    "    top_k_bins: int\n",
    "    buffer_bins: int\n",
    "    select_bins_by: Literal[\"lightcurves\", \"points\"]\n",
    "    max_time_diff: float\n",
    "    min_bin_size: int\n",
    "    max_freq: float\n",
    "    top_k_freqs: int\n",
    "    nterms: int\n",
    "    max_debug: bool  # If true, will print and plot everything\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "cached_lightcurves: dict[tuple, dict[str, list[Lightcurve]]] = {}\n",
    "cached_bins: dict[tuple, dict[str, list[LightcurveBin]]] = {}\n",
    "\n",
    "\n",
    "def _split_lightcurves(asteroid: Asteroid, config: Config) -> list[Lightcurve]:\n",
    "    max_hours_diff = config[\"max_hours_diff\"]\n",
    "    min_no_points = config[\"min_no_points\"]\n",
    "\n",
    "    logger.debug(\n",
    "        f\"Splitting lightcurves for {asteroid.name} with max_hours_diff={max_hours_diff} and min_no_points={min_no_points}\"\n",
    "    )\n",
    "    logger.debug(f\"Before splitting: {len(asteroid.lightcurves)} lightcurves\")\n",
    "\n",
    "    key = (max_hours_diff, min_no_points)\n",
    "    if key in cached_lightcurves and asteroid.name in cached_lightcurves[key]:\n",
    "        logger.debug(f\"Using cached lightcurves ({key}) for {asteroid.name}\")\n",
    "        splitted = cached_lightcurves[key][asteroid.name]\n",
    "    else:\n",
    "        splitted = lightcurve_splitter.split_lightcurves(\n",
    "            asteroid.lightcurves,\n",
    "            max_hours_diff=max_hours_diff,\n",
    "            min_no_points=min_no_points,\n",
    "        )\n",
    "\n",
    "        if key not in cached_lightcurves:\n",
    "            cached_lightcurves[key] = {}\n",
    "\n",
    "        cached_lightcurves[key][asteroid.name] = splitted\n",
    "\n",
    "    logger.debug(f\"After splitting: {len(splitted)} lightcurves\")\n",
    "\n",
    "    return splitted\n",
    "\n",
    "\n",
    "def _get_top_k_bins(lightcurves: list[Lightcurve], config: Config, asteroid: Asteroid) -> list[LightcurveBin]:\n",
    "    max_time_diff = config[\"max_time_diff\"]\n",
    "    min_bin_size = config[\"min_bin_size\"]\n",
    "    top_k_bins = config[\"top_k_bins\"]\n",
    "    buffer_bins = config[\"buffer_bins\"]  # In case of too few frequencies for some of selected bins\n",
    "\n",
    "    logger.debug(f\"Getting top {top_k_bins} bins with max_time_diff={max_time_diff} and min_bin_size={min_bin_size}\")\n",
    "\n",
    "    # If using the same lightcurves AND the same binning parameters, we can reuse the bins\n",
    "    composite_key = (config[\"max_hours_diff\"], config[\"min_no_points\"], max_time_diff, min_bin_size)\n",
    "    if composite_key in cached_bins and asteroid.name in cached_bins[composite_key]:\n",
    "        logger.debug(f\"Using cached bins ({composite_key}) for {asteroid.name}\")\n",
    "        bins = cached_bins[composite_key][asteroid.name]\n",
    "    else:\n",
    "        bins = lightcurve_binner.bin_lightcurves(\n",
    "            lightcurves,\n",
    "            max_time_diff=max_time_diff,\n",
    "            min_bin_size=min_bin_size,\n",
    "        )\n",
    "\n",
    "        if composite_key not in cached_bins:\n",
    "            cached_bins[composite_key] = {}\n",
    "\n",
    "        cached_bins[composite_key][asteroid.name] = bins\n",
    "\n",
    "    logger.debug(f\"After binning {len(bins)} bins available\")\n",
    "    if len(bins) < top_k_bins:\n",
    "        logger.debug(f\"Using {len(bins)} bins instead of {top_k_bins}\")\n",
    "\n",
    "    if config[\"select_bins_by\"] == \"lightcurves\":\n",
    "        return sorted(bins, reverse=True)[: top_k_bins + buffer_bins]\n",
    "\n",
    "    elif config[\"select_bins_by\"] == \"points\":\n",
    "        return sorted(bins, key=lambda bin: bin.points_count, reverse=True)[: top_k_bins + buffer_bins]\n",
    "\n",
    "    else:\n",
    "        raise ValueError(\"Invalid value for select_bins_by\")\n",
    "\n",
    "\n",
    "def _get_top_k_freqs(lightcurve_bin: LightcurveBin, config: Config, asteroid: Asteroid) -> np.ndarray:\n",
    "    nterms = config[\"nterms\"]\n",
    "    top_k_freqs = config[\"top_k_freqs\"]\n",
    "\n",
    "    logger.debug(\n",
    "        f\"Getting top {top_k_freqs} frequencies with nterms={nterms} for \"\n",
    "        f\"lightcurves={len(lightcurve_bin)} with total points={len(lightcurve_bin.times)}\"\n",
    "    )\n",
    "\n",
    "    freq_data = frequency_decomposer.decompose_bin(\n",
    "        lightcurve_bin,\n",
    "        fourier_nterms=nterms,\n",
    "        top_k=top_k_freqs,\n",
    "        max_freq=config[\"max_freq\"],\n",
    "        show_plot=config[\"max_debug\"],\n",
    "    )\n",
    "\n",
    "    if config[\"max_debug\"]:\n",
    "        # Return also the ratio of the frequency to the true frequency\n",
    "        true_freq_ratio = freq_data[:, 0] / (24 / asteroid.period)\n",
    "        return np.column_stack((freq_data, true_freq_ratio))\n",
    "    else:\n",
    "        return freq_data\n",
    "\n",
    "\n",
    "def _has_anomalous_series(data: list[list[float]], magnitude_threshold: int = 2):\n",
    "    if not data:\n",
    "        return False\n",
    "\n",
    "    medians = np.array([np.median(series) for series in data])\n",
    "    overall_median = np.median(medians)\n",
    "    ratios = medians / overall_median\n",
    "\n",
    "    anomalous_series_exist = np.any(np.logical_or(ratios > 10**magnitude_threshold, ratios < 10 ** (-magnitude_threshold)))\n",
    "\n",
    "    return anomalous_series_exist\n",
    "\n",
    "\n",
    "def get_freq_features(\n",
    "    asteroid: Asteroid,\n",
    "    config: Config,\n",
    ") -> list[list] | dict:\n",
    "    splitted_lightcurves = _split_lightcurves(asteroid, config)\n",
    "    if _has_anomalous_series([lc.brightness_arr for lc in splitted_lightcurves]):\n",
    "        logger.debug(\"Anomalous series detected\")\n",
    "\n",
    "        return {\"status\": \"failed\", \"reason\": \"anomalous series\"}\n",
    "\n",
    "    # Includes buffer bins\n",
    "    top_k_bins = _get_top_k_bins(splitted_lightcurves, config, asteroid)\n",
    "\n",
    "    if not top_k_bins:\n",
    "        logger.debug(\"No bins available\")\n",
    "\n",
    "        return {\"status\": \"failed\", \"reason\": \"no bins\"}\n",
    "\n",
    "    top_k_bins_no = config[\"top_k_bins\"]\n",
    "    buffer_bins_no = config[\"buffer_bins\"]\n",
    "\n",
    "    freq_data = []\n",
    "    for ind, _bin in enumerate(top_k_bins):\n",
    "        if len(freq_data) == top_k_bins_no:\n",
    "            break\n",
    "\n",
    "        if ind >= top_k_bins_no:\n",
    "            logger.debug(f\"Using buffer bin {ind - top_k_bins_no + 1} / {buffer_bins_no}\")\n",
    "\n",
    "        if config[\"max_debug\"]:\n",
    "            lightcurve_plotter.plot_lightcurves(_bin)\n",
    "\n",
    "        bin_freq = _get_top_k_freqs(_bin, config, asteroid)\n",
    "        if len(bin_freq) < config[\"top_k_freqs\"]:\n",
    "            logger.debug(f\"Bin {ind} has only {len(bin_freq)} frequencies, skipping\")\n",
    "\n",
    "            continue\n",
    "\n",
    "        freq_data.append(bin_freq.tolist())\n",
    "\n",
    "    if not freq_data:\n",
    "        logger.debug(\"No frequencies available\")\n",
    "\n",
    "        return {\"status\": \"failed\", \"reason\": \"no frequencies\"}\n",
    "\n",
    "    logger.debug(f\"{'-'*50}\\n\")\n",
    "\n",
    "    return freq_data, top_k_bins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "options = {\n",
    "    \"max_hours_diff\": [1, 2, 4, 8],\n",
    "    \"min_no_points\": [10, 20],\n",
    "    \"top_k_bins\": [2, 4],\n",
    "    \"buffer_bins\": [3],\n",
    "    \"select_bins_by\": [\"lightcurves\", \"points\"],\n",
    "    \"max_time_diff\": [30, 45, 60],\n",
    "    \"min_bin_size\": [1, 2],\n",
    "    \"max_freq\": [12],\n",
    "    \"top_k_freqs\": [50],\n",
    "    \"nterms\": [3],\n",
    "    \"max_debug\": [False],\n",
    "}\n",
    "\n",
    "configs = []\n",
    "for ind, option_values in enumerate(product(*options.values())):\n",
    "    option = dict(zip(options.keys(), option_values))\n",
    "    configs.append(Config(**option))\n",
    "\n",
    "print(f\"Generated {len(configs)} configurations\")\n",
    "print(f\"Given ~4m per configuration, this will take ~{len(configs) * 4 / 60} hours\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_and_save_features(config: Config, config_no: int):\n",
    "    config[\"max_debug\"] = False\n",
    "\n",
    "    failed_cnt = 0\n",
    "    asteroids_data = {}\n",
    "    for asteroid_name, ast_name in tqdm(asteroids.items()):\n",
    "        start = perf_counter()\n",
    "        features = get_freq_features(ast_name, config)\n",
    "        processing_time = perf_counter() - start\n",
    "\n",
    "        asteroids_data[asteroid_name] = {\n",
    "            \"is_failed\": False,\n",
    "            \"reason\": None,\n",
    "            \"period\": ast_name.period,\n",
    "            \"processing_time\": processing_time,\n",
    "            \"features\": [],\n",
    "        }\n",
    "        if isinstance(features, dict):\n",
    "            failed_cnt += 1\n",
    "            asteroids_data[asteroid_name][\"is_failed\"] = True\n",
    "            asteroids_data[asteroid_name][\"reason\"] = features[\"reason\"]\n",
    "            continue\n",
    "\n",
    "        assert len(features) in (1, 2, 3, 4), f\"Invalid number of sequences: {len(features)} for {asteroid_name}\"\n",
    "\n",
    "        asteroids_data[asteroid_name][\"features\"] = features\n",
    "\n",
    "    print(f\"Failed asteroids: {failed_cnt} ({failed_cnt / len(asteroids) * 100:.2f}%)\")\n",
    "    print(f\"{'-'*50}\")\n",
    "\n",
    "    dump_data = {\n",
    "        \"config\": config,\n",
    "        \"asteroids\": asteroids_data,\n",
    "    }\n",
    "\n",
    "    with open(FEATURES_DIR / (ASTEROIDS_JSON_FILE_NAME.format(config_no=config_no)), \"w\") as f:\n",
    "        json.dump(dump_data, f, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "calculated_configs = []\n",
    "for file in FEATURES_DIR.iterdir():\n",
    "    if file.suffix != \".json\":\n",
    "        continue\n",
    "\n",
    "    with open(file, \"r\") as f:\n",
    "        data = json.load(f)\n",
    "    \n",
    "    calculated_configs.append(data[\"config\"])\n",
    "\n",
    "print(f\"Already calculated {len(calculated_configs)} configurations\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.getLogger().setLevel(logging.INFO)\n",
    "\n",
    "times = []\n",
    "for ind, config in enumerate(configs):\n",
    "    if config in calculated_configs:\n",
    "        continue\n",
    "\n",
    "    print(f\"Config {ind + 1} / {len(configs)}\")\n",
    "    print(f\"{'#'*10}\")\n",
    "    print(config)\n",
    "    print(f\"{'#'*10}\")\n",
    "    start = perf_counter()\n",
    "    calculate_and_save_features(config, config_no=ind + 1)\n",
    "    times.append(perf_counter() - start)\n",
    "\n",
    "    print(f\"Average time per configuration so far: {np.mean(times):.2f} seconds\")\n",
    "    print(f\"{'-'*50}\")\n",
    "\n",
    "logging.getLogger().setLevel(logging.DEBUG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ast_name = asteroids[\"1177 T-3\"]\n",
    "ast_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = configs[0]\n",
    "\n",
    "config['max_debug'] = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = get_freq_features(ast_name, config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(FEATURES_DIR / (ASTEROIDS_JSON_FILE_NAME.format(config_no=1)), \"r\") as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "\n",
    "asteroids_data = data[\"asteroids\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "failed_asteroids = filter(lambda x: x[1][\"is_failed\"], asteroids_data.items())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reasons = Counter([failed_asteroid[\"reason\"] for _, failed_asteroid in failed_asteroids])\n",
    "print(reasons)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "diffs = {}\n",
    "for asteroid_name, asteroid_data in asteroids_data.items():\n",
    "    if asteroid_data[\"is_failed\"]:\n",
    "        continue\n",
    "\n",
    "    target_freq = 24 / asteroid_data[\"period\"]\n",
    "    freqs = np.array(asteroid_data[\"features\"])\n",
    "\n",
    "    top_k_ratio = freqs[:,:,0] / target_freq\n",
    "    min_diff = np.min(np.abs(top_k_ratio - 1))  # Closest to 1\n",
    "\n",
    "    diffs[asteroid_name] = min_diff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "percentiles = np.percentile(list(diffs.values()), [0, 5, 25, 50, 75, 95, 100])\n",
    "percentiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_asteroids = {name: data for name, data in asteroids_data.items() if name in diffs and diffs[name] > percentiles[-2]}\n",
    "len(selected_asteroids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ast_name = choice(list(selected_asteroids.keys()))\n",
    "print(repr(asteroids[ast_name]))\n",
    "print(f\"Target frequency: {24 / asteroids[ast_name].period}\")\n",
    "\n",
    "get_freq_features(asteroids[ast_name], config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mgr",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
